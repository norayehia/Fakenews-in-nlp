{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/norayehia/Fakenewswithbert-in-nlp/blob/main/bert_of_fake2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZH1x6daD5lA",
        "outputId": "ced69c17-f04c-46ce-97f5-96e7a0ec95f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "YuuisFp-G5d4",
        "outputId": "44f04cee-f3d2-4a46-e0f0-e875a7a6d345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 13.8 MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.26.38-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.13.0+cu116)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.38\n",
            "  Downloading botocore-1.29.38-py3-none-any.whl (10.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3 MB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.38->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.38->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 81.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.26.38 botocore-1.29.38 jmespath-1.0.1 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYaODXO2Dd6_"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this analysis, we will discuss how you can use NLP to determine whether the news is real or fake. Nowadays, fake news has become a common problem. Even respected media organizations are known to propagate fake news and are losing credibility. It can be difficult to trust news, because it can be difficult to know whether a news story is real or fake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea-YBYVqDd7L"
      },
      "source": [
        "# Dataset\n",
        "1.train.csv: A full training dataset with the following attributes                                         \n",
        "2.id: unique id for a news article                                                                         \n",
        "3.title: the title of a news article                                                                       \n",
        "4.author: author of the news article                                                                       \n",
        "5.text: the text of the article; could be incomplete                                                       \n",
        "6.label: a label that marks the article as potentially unreliable. Where 0: reliable and 1: unreliable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPBmXOEVDd7N"
      },
      "source": [
        "# Importing important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_jLZb6IDd7O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBzZBaTNGvdb",
        "outputId": "39483938-e150-4f9a-851c-af8441d1f565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxY1sipGDd7S"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xG6AqTSsD-aD",
        "outputId": "2c148494-40af-48ab-f2dc-fa9dc53a1fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, BertModel,BertAdam, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "#from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "6HavPWr270Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkjiHq0eDd7T"
      },
      "source": [
        "# Reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chdv5-qLDd7U"
      },
      "outputs": [],
      "source": [
        "train_df=pd.read_csv('/content/drive/MyDrive/research/aireserchnlp/fakenews/try2/fakdata/train.csv')\n",
        "#test_df=pd.read_csv('/content/drive/MyDrive/research/aireserchnlp/fakenews/try2/fakdata/test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RbRqf1qRDd7V",
        "outputId": "3d15a5d3-e484-4c12-b1ee-ba5c7d17184e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              title              author  \\\n",
              "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
              "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
              "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
              "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
              "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
              "\n",
              "                                                text  label  \n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
              "1  Ever get the feeling your life circles the rou...      0  \n",
              "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
              "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
              "4  Print \\nAn Iranian woman has been sentenced to...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32a92834-e182-4364-93fc-3ac8b660a3ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a92834-e182-4364-93fc-3ac8b660a3ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32a92834-e182-4364-93fc-3ac8b660a3ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32a92834-e182-4364-93fc-3ac8b660a3ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# here we are printing first five lines of our train dataset\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIk6TRdxDd7Y"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QTOJNgfDd7a"
      },
      "outputs": [],
      "source": [
        "#filling nan values with space(' ')\n",
        "train_df.fillna(' ',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "zzDHLRLfDd7b",
        "outputId": "dd0b9b14-ec71-4d19-d807-25aa32216b31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              title              author  \\\n",
              "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
              "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
              "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
              "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
              "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
              "\n",
              "                                                text  label  \\\n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
              "1  Ever get the feeling your life circles the rou...      0   \n",
              "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
              "3  Videos 15 Civilians Killed In Single US Airstr...      1   \n",
              "4  Print \\nAn Iranian woman has been sentenced to...      1   \n",
              "\n",
              "                                             summary  \n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
              "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  \n",
              "2  Why the Truth Might Get You Fired Consortiumne...  \n",
              "3  15 Civilians Killed In Single US Airstrike Hav...  \n",
              "4  Iranian woman jailed for fictional unpublished...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94473b45-11e5-4047-afa4-a5e196157634\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Why the Truth Might Get You Fired Consortiumne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94473b45-11e5-4047-afa4-a5e196157634')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94473b45-11e5-4047-afa4-a5e196157634 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94473b45-11e5-4047-afa4-a5e196157634');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#combining title and author,title and summary is formed\n",
        "train_df['summary']=train_df['title']+' '+train_df['author']+' '+train_df['text']\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "MPkMzxdCDd7c",
        "outputId": "c4270dd0-c01c-4010-a20a-ec53263b6b22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FLYNN: Hillary Clinton, Big Woman on Campus - Breitbart Daniel J. Flynn Ever get the feeling your life circles the roundabout rather than heads in a straight line toward the intended destination? [Hillary Clinton remains the big woman on campus in leafy, liberal Wellesley, Massachusetts. Everywhere else votes her most likely to don her inauguration dress for the remainder of her days the way Miss Havisham forever wore that wedding dress.  Speaking of Great Expectations, Hillary Rodham overflowed with them 48 years ago when she first addressed a Wellesley graduating class. The president of the college informed those gathered in 1969 that the students needed “no debate so far as I could ascertain as to who their spokesman was to be” (kind of the like the Democratic primaries in 2016 minus the   terms unknown then even at a Seven Sisters school). “I am very glad that Miss Adams made it clear that what I am speaking for today is all of us —  the 400 of us,” Miss Rodham told her classmates. After appointing herself Edger Bergen to the Charlie McCarthys and Mortimer Snerds in attendance, the    bespectacled in granny glasses (awarding her matronly wisdom —  or at least John Lennon wisdom) took issue with the previous speaker. Despite becoming the first   to win election to a seat in the U. S. Senate since Reconstruction, Edward Brooke came in for criticism for calling for “empathy” for the goals of protestors as he criticized tactics. Though Clinton in her senior thesis on Saul Alinsky lamented “Black Power demagogues” and “elitist arrogance and repressive intolerance” within the New Left, similar words coming out of a Republican necessitated a brief rebuttal. “Trust,” Rodham ironically observed in 1969, “this is one word that when I asked the class at our rehearsal what it was they wanted me to say for them, everyone came up to me and said ‘Talk about trust, talk about the lack of trust both for us and the way we feel about others. Talk about the trust bust.’ What can you say about it? What can you say about a feeling that permeates a generation and that perhaps is not even understood by those who are distrusted?” The “trust bust” certainly busted Clinton’s 2016 plans. She certainly did not even understand that people distrusted her. After Whitewater, Travelgate, the vast   conspiracy, Benghazi, and the missing emails, Clinton found herself the distrusted voice on Friday. There was a load of compromising on the road to the broadening of her political horizons. And distrust from the American people —  Trump edged her 48 percent to 38 percent on the question immediately prior to November’s election —  stood as a major reason for the closing of those horizons. Clinton described her vanquisher and his supporters as embracing a “lie,” a “con,” “alternative facts,” and “a   assault on truth and reason. ” She failed to explain why the American people chose his lies over her truth. “As the history majors among you here today know all too well, when people in power invent their own facts and attack those who question them, it can mark the beginning of the end of a free society,” she offered. “That is not hyperbole. ” Like so many people to emerge from the 1960s, Hillary Clinton embarked upon a long, strange trip. From high school Goldwater Girl and Wellesley College Republican president to Democratic politician, Clinton drank in the times and the place that gave her a degree. More significantly, she went from idealist to cynic, as a comparison of her two Wellesley commencement addresses show. Way back when, she lamented that “for too long our leaders have viewed politics as the art of the possible, and the challenge now is to practice politics as the art of making what appears to be impossible possible. ” Now, as the big woman on campus but the odd woman out of the White House, she wonders how her current station is even possible. “Why aren’t I 50 points ahead?” she asked in September. In May she asks why she isn’t president. The woman famously dubbed a “congenital liar” by Bill Safire concludes that lies did her in —  theirs, mind you, not hers. Getting stood up on Election Day, like finding yourself the jilted bride on your wedding day, inspires dangerous delusions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_df['summary'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XODFRwRdDd7d",
        "outputId": "ae2e88ec-8767-4f6d-f64f-3d88ecde4ec0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id         0\n",
              "title      0\n",
              "author     0\n",
              "text       0\n",
              "label      0\n",
              "summary    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXDAaJQMDd7e",
        "outputId": "adce6820-3165-4b96-b533-1d56186e0c8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        False\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "20795    False\n",
              "20796    False\n",
              "20797    False\n",
              "20798    False\n",
              "20799    False\n",
              "Name: summary, Length: 20800, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_df['summary']==' '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCv5UEkuDd7f"
      },
      "source": [
        "**Removel of stop words and Stemming the words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9W6DdpLDd7f"
      },
      "outputs": [],
      "source": [
        "# here we are importing nltk,stopwords and porterstemmer we are using stemming on the text \n",
        "# we have and stopwords will help in removing the stopwords in the text\n",
        "\n",
        "#re is regular expressions used for identifying only words in the text and ignoring anything else\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "ps=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGICbD09Dd7g"
      },
      "outputs": [],
      "source": [
        "x=train_df['summary']\n",
        "y=train_df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKaNXV-ADd7h",
        "outputId": "d3d4ad01-3a04-4f12-f27c-e0a2417b8943"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    House Dem Aide: We Didn’t Even See Comey’s Let...\n",
              "1    FLYNN: Hillary Clinton, Big Woman on Campus - ...\n",
              "2    Why the Truth Might Get You Fired Consortiumne...\n",
              "3    15 Civilians Killed In Single US Airstrike Hav...\n",
              "4    Iranian woman jailed for fictional unpublished...\n",
              "Name: summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92xyZAi9Dd7h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "7b7acae7-de5e-486d-ec50-22856683750c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FLYNN: Hillary Clinton, Big Woman on Campus - Breitbart Daniel J. Flynn Ever get the feeling your life circles the roundabout rather than heads in a straight line toward the intended destination? [Hillary Clinton remains the big woman on campus in leafy, liberal Wellesley, Massachusetts. Everywhere else votes her most likely to don her inauguration dress for the remainder of her days the way Miss Havisham forever wore that wedding dress.  Speaking of Great Expectations, Hillary Rodham overflowed with them 48 years ago when she first addressed a Wellesley graduating class. The president of the college informed those gathered in 1969 that the students needed “no debate so far as I could ascertain as to who their spokesman was to be” (kind of the like the Democratic primaries in 2016 minus the   terms unknown then even at a Seven Sisters school). “I am very glad that Miss Adams made it clear that what I am speaking for today is all of us —  the 400 of us,” Miss Rodham told her classmates. After appointing herself Edger Bergen to the Charlie McCarthys and Mortimer Snerds in attendance, the    bespectacled in granny glasses (awarding her matronly wisdom —  or at least John Lennon wisdom) took issue with the previous speaker. Despite becoming the first   to win election to a seat in the U. S. Senate since Reconstruction, Edward Brooke came in for criticism for calling for “empathy” for the goals of protestors as he criticized tactics. Though Clinton in her senior thesis on Saul Alinsky lamented “Black Power demagogues” and “elitist arrogance and repressive intolerance” within the New Left, similar words coming out of a Republican necessitated a brief rebuttal. “Trust,” Rodham ironically observed in 1969, “this is one word that when I asked the class at our rehearsal what it was they wanted me to say for them, everyone came up to me and said ‘Talk about trust, talk about the lack of trust both for us and the way we feel about others. Talk about the trust bust.’ What can you say about it? What can you say about a feeling that permeates a generation and that perhaps is not even understood by those who are distrusted?” The “trust bust” certainly busted Clinton’s 2016 plans. She certainly did not even understand that people distrusted her. After Whitewater, Travelgate, the vast   conspiracy, Benghazi, and the missing emails, Clinton found herself the distrusted voice on Friday. There was a load of compromising on the road to the broadening of her political horizons. And distrust from the American people —  Trump edged her 48 percent to 38 percent on the question immediately prior to November’s election —  stood as a major reason for the closing of those horizons. Clinton described her vanquisher and his supporters as embracing a “lie,” a “con,” “alternative facts,” and “a   assault on truth and reason. ” She failed to explain why the American people chose his lies over her truth. “As the history majors among you here today know all too well, when people in power invent their own facts and attack those who question them, it can mark the beginning of the end of a free society,” she offered. “That is not hyperbole. ” Like so many people to emerge from the 1960s, Hillary Clinton embarked upon a long, strange trip. From high school Goldwater Girl and Wellesley College Republican president to Democratic politician, Clinton drank in the times and the place that gave her a degree. More significantly, she went from idealist to cynic, as a comparison of her two Wellesley commencement addresses show. Way back when, she lamented that “for too long our leaders have viewed politics as the art of the possible, and the challenge now is to practice politics as the art of making what appears to be impossible possible. ” Now, as the big woman on campus but the odd woman out of the White House, she wonders how her current station is even possible. “Why aren’t I 50 points ahead?” she asked in September. In May she asks why she isn’t president. The woman famously dubbed a “congenital liar” by Bill Safire concludes that lies did her in —  theirs, mind you, not hers. Getting stood up on Election Day, like finding yourself the jilted bride on your wedding day, inspires dangerous delusions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRIwG3TqE553"
      },
      "source": [
        "#preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GpHPOi1EuQJ",
        "outputId": "96fd05c2-4f4d-4f4c-9736-76263b2b975b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trb-9zE9Dd7i"
      },
      "outputs": [],
      "source": [
        "# here we are creating corpus for the test dataset exactly the same as we created for the \n",
        "# training dataset\n",
        "corpus=[]\n",
        "for i in range(0,len(train_df)):\n",
        "    review=re.sub('[^a-zA-Z]',' ',x[i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review=' '.join(review)\n",
        "    corpus.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "sQ71psKYDd7j",
        "outputId": "de2763a3-79f8-40d6-d9d0-f742a2b95bbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'flynn hillari clinton big woman campu breitbart daniel j flynn ever get feel life circl roundabout rather head straight line toward intend destin hillari clinton remain big woman campu leafi liber wellesley massachusett everywher els vote like inaugur dress remaind day way miss havisham forev wore wed dress speak great expect hillari rodham overflow year ago first address wellesley graduat class presid colleg inform gather student need debat far could ascertain spokesman kind like democrat primari minu term unknown even seven sister school glad miss adam made clear speak today us us miss rodham told classmat appoint edger bergen charli mccarthi mortim snerd attend bespectacl granni glass award matronli wisdom least john lennon wisdom took issu previou speaker despit becom first win elect seat u senat sinc reconstruct edward brook came critic call empathi goal protestor critic tactic though clinton senior thesi saul alinski lament black power demagogu elitist arrog repress intoler within new left similar word come republican necessit brief rebutt trust rodham iron observ one word ask class rehears want say everyon came said talk trust talk lack trust us way feel other talk trust bust say say feel permeat gener perhap even understood distrust trust bust certainli bust clinton plan certainli even understand peopl distrust whitewat travelg vast conspiraci benghazi miss email clinton found distrust voic friday load compromis road broaden polit horizon distrust american peopl trump edg percent percent question immedi prior novemb elect stood major reason close horizon clinton describ vanquish support embrac lie con altern fact assault truth reason fail explain american peopl chose lie truth histori major among today know well peopl power invent fact attack question mark begin end free societi offer hyperbol like mani peopl emerg hillari clinton embark upon long strang trip high school goldwat girl wellesley colleg republican presid democrat politician clinton drank time place gave degre significantli went idealist cynic comparison two wellesley commenc address show way back lament long leader view polit art possibl challeng practic polit art make appear imposs possibl big woman campu odd woman white hous wonder current station even possibl point ahead ask septemb may ask presid woman famous dub congenit liar bill safir conclud lie mind get stood elect day like find jilt bride wed day inspir danger delus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "corpus[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in corpus]\n",
        "labels = train_df['label']"
      ],
      "metadata": {
        "id": "nMg2f4KIudJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "metadata": {
        "id": "TuSlzoRdudZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de67fc5-6127-42dd-bca0-3bf1a4dd2c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 906937.95B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'ho', '##us', 'dem', 'aid', 'even', 'see', 'come', '##y', 'letter', 'jason', 'cha', '##ffe', '##tz', 't', '##wee', '##t', 'dar', '##rel', 'luc', '##u', 'ho', '##us', 'dem', 'aid', 'even', 'see', 'come', '##y', 'letter', 'jason', 'cha', '##ffe', '##tz', 't', '##wee', '##t', 'dar', '##rel', 'luc', '##u', 'oct', '##ob', 'sub', '##sc', '##ri', '##b', 'jason', 'cha', '##ffe', '##tz', 'stump', 'american', 'fork', 'utah', 'im', '##ag', 'court', '##es', '##i', 'michael', 'jo', '##lley', 'avail', 'cr', '##ea', '##tiv', 'common', 'li', '##cens', 'ap', '##olo', '##g', 'keith', 'ol', '##berman', '##n', 'doubt', 'worst', 'person', 'world', 'week', 'fbi', 'director', 'jam', '##e', 'come', '##y', 'accord', 'ho', '##us', 'democrat', 'aid', 'look', 'like', 'also', 'know', 'second', 'worst', 'person', 'well', 'turn', 'come', '##y', 'sent', 'in', '##fa', '##m', 'letter', 'ann', '##oun', '##c', 'fbi', 'look', 'email', 'may', 're', '##lat', 'hill', '##ari', 'clinton', 'email', 'server', 'rank', 'democrat', 're', '##lev', 'commit', '##te', 'hear', 'come', '##y', 'found', 'via', 't', '##wee', '##t', 'one', 'republican', 'commit', '##te', 'chair', '##men', 'know', 'come', '##y', 'not', '##if', '##i', 'republican', 'chair', '##men', 'democrat', 'rank', 'member', 'ho', '##us', 'intel', '##li', '##g', 'ju', '##dic', '##ia', '##ri', 'oversight', 'commit', '##te', 'age', '##nc', 'review', 'email', 'recent', 'disco', '##v', 'order', 'see', 'contain', 'class', '##if', '##i', 'inform', 'long', 'letter', 'went', 'oversight', 'commit', '##te', 'chairman', 'jason', 'cha', '##ffe', '##tz', 'set', 'pol', '##it', 'world', 'ab', '##la', '##z', 't', '##wee', '##t', 'fbi', 'dir', 'inform', 'fbi', 'learn', 'exist', 'email', 'appear', 'per', '##tin', 'invest', '##ig', 'case', 're', '##open', 'jason', 'cha', '##ffe', '##tz', 'jason', '##int', '##he', '##ho', '##us', 'oct', '##ob', 'co', '##urs', 'know', 'case', 'come', '##y', 'actual', 'say', 'review', 'email', 'light', 'un', '##rel', 'case', 'know', 'ant', '##hon', '##i', 'wei', '##ner', 'sex', '##t', 'teen', '##ag', 'app', '##ar', 'lit', '##tl', 'thing', 'fact', 'matter', 'cha', '##ffe', '##tz', 'utah', 'republican', 'al', '##rea', '##di', 'vow', 'in', '##iti', 'raft', 'invest', '##ig', 'hill', '##ari', 'win', 'least', 'two', 'year', 'worth', 'po', '##ssi', '##bl', 'en', '##ti', '##r', 'term', 'worth', 'app', '##ar', 'cha', '##ffe', '##tz', 'thought', 'fbi', 'al', '##rea', '##di', 'work', 'result', 't', '##wee', '##t', 'brief', '##li', 'roi', '##l', 'nation', 'cooler', 'head', 'real', '##iz', 'du', '##d', 'accord', 'senior', 'ho', '##us', 'democrat', 'aid', 'mis', '##rea', '##d', 'letter', 'may', 'least', 'cha', '##ffe', '##tz', 'sin', 'aid', 'told', 'share', '##bl', '##u', 'boss', 'democrat', 'even', 'know', 'come', '##y', 'letter', 'time', 'found', 'check', 'twitter', 'democrat', 'rank', 'member', 're', '##lev', 'commit', '##te', 'rec', '##ei', '##v', 'come', '##y', 'letter', 'republican', 'chair', '##men', 'fact', 'democrat', 'rank', 'member', 'rec', '##ei', '##v', 'chairman', 'oversight', 'govern', 'reform', 'commit', '##te', 'jason', 'cha', '##ffe', '##tz', 't', '##wee', '##t', 'made', 'public', 'let', 'see', 'got', 'right', 'fbi', 'director', 'tell', 'cha', '##ffe', '##tz', 'go', '##p', 'commit', '##te', 'chair', '##men', 'major', 'develop', 'potent', '##i', 'pol', '##it', 'ex', '##pl', '##os', 'invest', '##ig', 'neither', 'cha', '##ffe', '##tz', 'col', '##lea', '##gu', 'court', '##es', '##i', 'let', 'democrat', 'counterpart', 'know', 'instead', 'accord', 'aid', 'made', 'find', 'twitter', 'al', '##rea', '##di', 'talk', 'dail', '##i', 'ko', 'come', '##y', 'pro', '##vid', 'ad', '##van', '##c', 'not', '##ic', 'letter', 'cha', '##ffe', '##tz', 'republican', 'give', 'time', 'turn', 'spin', 'mach', '##in', 'may', 'make', 'good', 'theater', 'not', '##h', 'far', 'even', 'suggest', 'case', 'not', '##h', 'far', 'suggest', 'come', '##y', 'any', '##th', 'gross', '##li', 'inc', '##omp', '##et', 'tone', 'deaf', 'suggest', 'howe', '##v', 'cha', '##ffe', '##tz', 'act', 'way', 'make', 'dan', 'burton', 'dar', '##rel', 'iss', '##a', 'look', 'like', 'model', 'res', '##pon', '##s', 'bi', '##partisan', '##ship', 'even', 'dec', '##en', '##c', 'not', '##if', '##i', 'rank', 'member', 'elijah', 'cum', 'some', '##th', 'ex', '##pl', '##os', 'tram', '##pl', 'basic', 'standard', 'fair', 'know', 'grant', 'like', 'cha', '##ffe', '##tz', 'answer', 'sit', 'rid', '##ic', '##ul', 'republican', 'district', 'anchor', 'pro', '##vo', 'ore', '##m', 'cook', 'partisan', 'vote', 'index', 'r', 'gave', 'mit', '##t', 'romney', 'punish', 'percent', 'vote', 'more', '##ov', 'republican', 'ho', '##us', 'leadership', 'given', 'full', 'support', 'cha', '##ffe', '##tz', 'plan', 'fish', 'ex', '##ped', '##it', 'mean', 'turn', 'hot', 'light', 'textbook', 'exam', '##pl', 'ho', '##us', 'be', '##com', 'republican', 'control', 'also', 'second', 'worst', 'person', 'world', 'dar', '##rel', 'luc', '##u', 'dar', '##rel', 'some', '##th', 'gr', '##ad', '##ua', '##t', 'un', '##iver', '##s', 'north', 'carolina', 'con', '##si', '##d', 'journalist', 'old', 'school', 'attempt', 'turn', 'member', 're', '##li', '##gi', 'right', 'col', '##leg', 'succeed', 'turn', 're', '##li', '##gi', 'right', 'worst', 'night', '##mar', 'char', '##ism', '##at', 'christian', 'una', '##pol', '##oge', '##t', 'li', '##ber', 'des', '##ir', 'stand', 'scare', 'si', '##len', '##c', 'inc', '##rea', '##s', 'sur', '##vi', '##v', 'abu', '##s', 'three', 'year', 'mar', '##ria', '##g', 'may', 'know', 'dail', '##i', 'ko', 'christian', 'dem', 'nc', 'follow', 'twitter', 'darrell', '##lu', '##cu', 'connect', 'facebook', 'click', 'buy', 'dar', '##rel', 'mel', '##lo', 'yell', '##o', 'connect', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4aG78CvIB05",
        "outputId": "06f80a35-f2b2-431f-ff30-72c9c40ccd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 128"
      ],
      "metadata": {
        "id": "plrXGgPsNut0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC0RU60kN0-u",
        "outputId": "348520d5-8870-4fb9-ed73-b3d59b10d409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (689 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (555 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1037 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (711 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (989 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1473 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1339 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4326 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (827 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1044 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1075 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (678 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (612 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5025 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (990 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1306 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (968 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1467 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2768 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2442 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (723 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (834 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (812 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (708 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1197 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1099 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1461 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (985 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1100 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (580 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1353 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1026 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4374 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1235 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1114 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (990 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1733 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (677 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1089 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (804 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (704 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1079 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1183 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1094 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (786 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (694 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (551 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1090 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (897 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1343 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (592 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (755 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (832 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1274 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (652 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (958 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2250 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1252 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1388 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (531 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (780 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1008 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1047 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (925 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1118 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1163 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3520 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1063 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (915 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (709 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (894 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (879 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1778 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1210 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1077 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (711 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (747 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (927 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5210 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (571 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1314 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (970 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (984 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (760 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (814 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (814 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1395 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1034 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (573 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (851 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1125 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (795 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1491 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1157 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1131 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (901 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (680 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1177 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (568 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (897 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (739 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1063 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (629 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (867 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1007 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1268 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (558 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1236 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (682 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1141 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (911 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1257 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (848 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1169 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (975 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (517 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1144 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (819 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (640 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (733 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (757 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1803 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (538 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (845 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (724 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1422 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5809 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1296 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1203 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (533 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1168 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1024 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1423 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (798 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1361 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1240 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1224 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (974 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (879 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1077 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1510 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (761 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1448 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1129 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (716 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (530 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (547 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (604 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (767 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1268 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (844 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (912 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (846 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (793 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (888 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (801 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (672 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1289 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1136 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (825 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (641 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (985 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (926 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (620 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1690 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (670 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (990 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (879 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (937 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2278 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (960 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (670 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (662 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1431 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (967 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1398 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4389 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (866 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (568 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (690 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (540 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1085 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (12026 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (796 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1022 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2943 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (632 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1229 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (541 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1174 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (695 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3614 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (563 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1023 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (821 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (8319 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1196 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (892 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (678 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1078 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (752 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (971 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (918 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (559 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (910 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (886 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3390 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6511 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1200 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (788 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (605 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (807 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (580 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1097 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (811 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (721 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2854 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (864 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (838 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1432 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2347 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (653 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1413 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1537 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1054 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1084 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1054 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1187 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (795 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (768 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (918 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (838 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2640 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (837 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1284 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (918 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (659 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (802 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (652 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (708 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1077 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (819 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1241 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (854 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1000 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (696 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1228 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (667 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (884 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (650 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1035 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (916 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (901 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (597 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (809 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1242 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (934 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3837 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2004 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1239 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2213 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (877 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (849 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1150 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (702 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (746 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1227 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1130 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1312 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1612 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (541 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (746 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (913 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1243 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (720 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1267 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2019 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (775 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (540 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1197 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (970 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1075 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1005 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1160 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (872 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1055 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1082 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (856 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1054 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1107 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1442 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (771 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (649 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (829 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1046 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1219 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (854 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (728 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1264 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1230 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (548 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (661 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (779 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (863 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (762 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (528 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (812 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (908 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2377 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1115 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1017 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (712 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1353 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (872 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1149 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (785 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (746 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (758 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1212 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1022 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1101 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (734 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1000 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (699 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2006 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (664 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1661 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3169 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2212 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1079 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1800 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1210 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (556 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (915 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (722 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1100 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (820 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (537 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1208 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (910 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (752 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (684 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (648 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (664 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1192 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1196 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (883 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1470 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (760 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (615 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1014 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (694 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3169 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1175 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1391 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (626 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1953 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1053 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (771 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (840 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1059 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (712 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1159 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1019 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1298 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1226 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (941 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (875 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (820 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (531 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (967 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1116 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (707 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1199 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3877 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (982 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1199 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1121 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (693 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (798 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (661 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (576 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (736 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (788 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1421 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1128 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1044 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (788 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1649 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1930 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1076 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (655 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (767 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (881 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (551 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (577 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (737 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1473 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (556 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1118 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1007 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (579 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1732 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (608 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (705 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (936 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (829 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (683 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (857 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2767 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (602 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (960 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1319 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (518 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1126 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1077 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (883 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1180 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (733 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (924 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3606 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (828 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (711 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1461 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1689 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (933 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (579 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2559 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1053 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1336 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (569 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (730 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (592 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4477 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (711 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (986 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1147 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1443 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (579 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (909 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1203 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1417 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3186 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1381 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1436 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (878 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (859 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (951 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (921 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1255 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (958 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (786 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1987 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1485 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (647 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (893 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (896 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (776 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (638 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (824 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (624 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1023 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (620 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1107 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (801 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1229 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1206 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (629 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1113 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (615 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2521 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1072 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1471 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (899 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (780 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1133 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3325 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (553 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (803 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1207 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1062 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (838 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (762 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (681 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (628 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1124 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (558 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (688 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1047 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (650 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (672 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (584 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (780 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1012 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (947 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (655 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1185 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (671 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1040 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1928 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (518 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1389 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1125 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1103 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (681 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1253 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6076 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1013 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (756 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (784 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2151 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (891 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (628 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1189 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1209 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1579 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (952 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (659 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (751 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (953 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (640 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1188 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1257 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (748 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1158 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (562 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (924 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1279 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (573 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (774 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (580 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1066 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1595 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (658 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1328 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1485 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (652 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (933 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (785 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (582 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1925 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1095 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (864 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (850 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1216 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (542 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (521 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1049 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (718 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (605 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1662 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (822 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (930 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1960 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (697 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1204 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (538 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (991 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (899 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5010 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1152 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (751 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1014 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1181 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2362 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2135 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1117 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1816 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1195 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (537 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1202 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1326 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1122 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (917 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1379 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (929 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (913 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3368 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1489 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2150 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1142 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (530 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (924 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1123 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1098 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (732 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (984 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1089 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (707 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (928 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (806 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (935 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6718 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4375 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (548 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (728 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (755 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (533 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2232 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (980 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (880 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1989 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (671 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (917 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (908 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (563 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1299 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (718 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1331 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (577 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (782 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (880 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (803 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (559 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (737 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1132 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (595 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (605 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (988 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1060 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1143 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (956 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1155 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (655 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (735 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (821 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (542 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (767 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (541 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3101 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (914 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (687 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (899 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (566 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1231 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1401 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1126 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (777 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (776 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1116 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1256 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (542 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (708 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (541 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1648 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (925 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1109 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1127 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (661 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1310 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1078 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (606 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1208 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (556 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (961 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (983 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (560 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1034 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (907 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (912 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (901 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (615 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (551 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (958 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (984 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (761 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (851 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1023 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1683 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (624 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (587 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (620 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (887 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1128 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (663 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1306 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (916 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (829 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1129 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (694 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1369 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (770 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (801 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (870 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (949 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (578 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1163 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (737 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (941 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1189 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (934 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (647 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (730 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4333 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1049 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1030 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (737 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1293 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (751 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (530 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (782 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (998 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (994 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1036 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1008 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (701 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1576 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (819 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1461 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1192 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (521 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (659 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (675 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1640 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6866 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1168 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (923 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (584 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1296 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (721 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (820 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1092 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1271 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1276 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1253 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1227 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (567 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1132 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (775 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (571 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (845 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (702 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (524 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1092 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (543 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (818 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1035 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2203 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (990 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (633 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (577 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1306 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (826 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2106 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1053 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1471 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (753 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (979 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (932 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1406 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1046 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (751 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (602 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (939 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1687 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (836 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1196 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1236 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1008 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3205 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (809 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (681 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (520 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (987 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (588 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (922 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1080 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (845 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (781 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (578 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1040 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1264 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (567 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2438 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (929 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (797 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1218 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (962 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1200 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (667 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (707 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (901 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (835 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (569 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (818 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1343 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (951 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (747 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4303 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2089 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (717 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (905 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1259 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1171 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2217 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1004 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (534 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (667 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (779 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1444 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (841 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (940 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1177 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2423 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1336 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (905 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (721 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (794 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (671 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1028 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1246 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1139 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1223 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1483 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1324 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (914 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1012 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (722 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (853 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1256 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (943 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (899 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (970 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (915 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1067 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (679 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (671 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1325 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1028 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1437 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (907 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (858 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (713 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (775 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1444 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (934 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (790 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1243 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1566 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1266 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3731 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (950 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1001 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (949 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1053 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (790 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1339 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1367 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (689 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (760 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1285 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (562 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1318 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (952 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (740 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (547 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1778 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (933 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (967 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1029 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1463 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (729 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1040 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (721 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1371 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1100 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (795 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (537 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1070 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1081 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1250 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1173 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (718 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (830 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (951 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1195 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1755 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1084 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1369 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1259 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (782 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (885 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (949 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (792 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (514 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (537 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (695 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (700 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1486 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (846 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1061 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1030 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1676 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (767 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1330 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (770 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (655 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (776 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2583 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (955 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (657 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1283 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1657 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (588 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1819 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1055 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (973 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4404 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1364 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1122 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2121 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1150 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (893 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (989 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3518 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (795 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (637 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (840 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (604 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1989 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (527 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1180 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (623 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (631 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (559 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (894 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1261 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1230 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1114 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (763 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1251 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (623 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1649 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (673 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (689 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2705 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1328 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (958 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (712 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1070 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1595 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1351 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (834 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1416 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1049 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (796 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1298 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (601 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1796 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1107 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2428 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1165 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (573 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1128 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (914 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (521 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (12771 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (7435 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1041 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (967 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2318 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1009 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (819 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1261 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1009 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (802 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (864 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1061 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (709 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1091 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (736 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (771 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1037 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (571 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (810 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (889 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (882 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1205 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1172 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1165 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (753 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (682 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (828 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (793 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (521 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (733 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (931 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1483 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1229 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (527 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (915 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1216 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1129 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (799 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (569 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (775 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (569 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1137 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (587 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (681 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (860 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (942 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (943 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1273 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (642 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1794 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (891 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (987 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (653 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (785 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (871 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (741 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (929 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (815 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1119 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1984 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1415 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (519 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1459 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (613 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1311 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (631 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (835 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1448 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1718 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4306 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (848 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (849 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1124 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1354 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1288 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (604 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (797 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1290 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (809 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1294 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1444 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1093 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (863 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (680 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1215 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (792 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (524 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (837 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1394 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (794 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (566 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (649 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (882 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (602 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1114 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (739 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (892 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (837 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (548 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3230 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1067 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1364 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (905 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1066 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (832 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (592 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (839 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (947 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (784 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1252 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (729 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (807 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1107 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (540 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (761 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (572 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1186 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (819 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1301 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (772 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1050 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (605 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (647 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1194 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1033 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (956 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1010 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (519 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (923 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1419 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1142 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1679 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (762 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (854 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (994 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1079 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (975 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (580 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (582 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (722 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (908 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1226 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4427 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1007 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1078 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (735 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (840 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1490 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1954 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (848 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1265 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1749 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1034 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (786 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1273 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1216 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (964 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2126 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1135 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (531 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1012 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2552 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1020 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (550 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (704 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (777 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (926 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (671 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (694 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1104 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2156 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1265 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (996 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (724 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1117 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (831 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (904 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (709 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1261 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1733 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1063 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (764 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (614 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1272 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (758 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (604 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (580 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1163 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (737 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (556 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (779 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (568 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (539 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1067 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (812 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1111 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (695 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1378 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1729 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1021 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (801 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (563 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1000 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (551 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (540 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (811 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1254 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (789 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (947 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1877 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1103 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (560 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1372 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (702 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1239 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (986 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (518 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1180 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1354 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (723 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (848 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (570 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (985 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1051 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1111 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (555 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1026 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (578 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (663 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2206 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1154 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (834 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2231 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1079 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1358 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (667 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (680 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (530 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1153 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1400 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1333 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (587 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1803 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (991 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (736 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1190 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (684 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (623 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1135 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1442 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1033 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2412 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (588 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (771 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1253 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1056 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (804 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (700 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1079 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (648 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1236 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (659 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (599 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (967 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4685 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (774 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1154 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (550 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1241 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1095 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1168 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (935 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (550 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1125 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1386 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1090 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (713 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (863 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1102 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1212 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (753 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1335 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6242 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (810 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (841 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1211 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (891 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1422 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1155 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (811 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1067 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (943 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (777 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1119 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1444 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (954 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (997 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1057 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (890 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4395 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (632 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (678 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (724 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1055 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (690 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (705 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1258 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1341 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (747 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1055 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1405 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1086 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (518 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1039 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (855 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (675 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1398 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1001 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (888 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1542 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1004 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2151 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1139 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1366 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (987 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (739 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1078 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2277 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (608 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (907 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (851 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (954 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (722 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (521 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (970 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1022 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1019 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1357 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1053 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (951 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (912 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1722 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (542 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (756 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1140 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1123 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (995 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (864 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (720 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (782 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1520 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (658 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (576 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (788 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1233 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (628 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (831 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (761 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (992 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (681 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1213 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1017 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (736 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2130 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1118 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1067 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1184 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (582 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (562 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (761 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (576 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (638 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (629 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1124 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (867 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (740 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (571 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (842 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1032 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (974 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (756 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (827 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (849 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (531 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (808 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (995 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (700 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (929 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1287 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (985 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1084 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (731 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (970 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1824 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (681 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1360 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (629 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1213 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (842 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1533 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (796 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (779 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1145 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (894 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1009 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1288 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (916 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (962 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (905 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (794 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1263 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1091 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (856 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (517 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (696 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (780 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (629 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1120 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1185 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (789 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (881 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (896 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1270 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (653 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (542 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1285 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4821 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (772 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1026 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (871 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (949 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (639 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1828 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1412 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (748 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1081 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1121 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (595 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1220 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (888 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (792 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (568 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (799 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (704 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1073 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2141 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (961 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (985 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (534 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1130 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1007 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1099 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (597 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1410 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (514 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (994 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2270 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1378 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1067 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (851 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (979 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (964 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (658 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (533 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (761 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1983 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1493 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1013 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (679 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1863 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1583 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (717 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2951 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (955 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1169 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (869 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (990 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2702 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (912 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1742 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1066 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1184 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1773 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1240 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (952 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2434 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (922 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1071 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (953 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (765 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (799 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (664 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (760 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1875 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1431 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1467 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1394 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (531 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (591 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1108 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (887 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (846 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (602 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (833 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (649 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4484 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1101 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (772 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (822 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (578 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (638 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (810 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3512 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1315 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (670 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3633 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (740 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1079 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1106 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (543 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (890 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (796 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (788 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1140 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1208 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1051 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1078 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (853 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (970 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5237 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1340 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1810 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1304 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1144 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (556 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (541 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (842 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1781 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (667 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (793 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (909 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (948 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (513 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (675 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (825 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1203 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (910 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (895 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (896 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3267 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1219 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (541 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1435 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (709 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (915 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (688 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1748 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1155 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1081 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1118 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (798 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1349 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (991 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1047 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (694 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1118 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1091 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (540 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1175 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1304 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (685 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (875 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1102 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (563 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1129 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (766 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1270 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (890 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1848 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (998 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (588 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (654 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (882 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (688 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (517 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1042 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1154 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1140 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (827 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (524 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1404 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1475 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1238 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (707 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (874 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1090 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (582 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1052 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1384 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4892 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (664 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (687 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1028 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (834 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1208 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (923 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1029 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1125 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1246 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (916 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (871 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1841 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2612 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1389 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (834 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1022 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1086 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1426 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (768 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1144 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (527 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (717 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1056 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1062 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (994 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1120 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (976 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (779 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1046 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1193 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (795 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (946 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (790 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3373 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (765 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1028 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (939 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (928 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (568 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (926 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1005 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (528 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1116 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1142 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1151 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (583 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1157 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1337 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1309 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (760 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (764 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (940 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (658 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1208 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (942 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (890 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1198 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (784 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1045 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (656 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (918 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (878 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (858 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1281 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (572 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1275 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1708 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (813 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1577 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (929 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (784 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2336 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1023 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (884 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (650 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1055 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (979 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (624 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (543 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1083 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (742 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (891 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (606 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1193 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (968 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1229 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (984 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (735 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (727 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (860 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (860 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1533 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (572 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1206 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (798 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (783 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (899 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2412 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (683 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (835 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1366 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1232 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (812 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1030 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (901 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (808 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (626 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (785 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (982 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (880 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (550 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1302 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1124 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1198 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (677 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (534 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1120 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1905 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (676 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1254 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (956 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1000 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (860 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2294 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1176 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1502 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (992 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2384 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (628 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (987 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1099 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (664 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (712 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1548 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (742 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (662 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (986 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (608 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (917 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (626 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1753 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (608 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1721 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (779 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1385 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (628 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (937 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (528 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1245 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2763 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1261 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2136 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (957 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1021 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1238 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (989 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1182 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (804 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (922 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1035 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (780 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1385 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1009 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (828 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (745 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (816 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (576 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1642 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (631 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1037 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1989 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1111 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (739 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1255 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (570 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1415 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1146 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (546 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1113 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1365 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (524 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (697 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (729 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (536 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (916 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3049 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (993 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1475 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (754 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2724 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1168 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1197 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1092 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1071 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1579 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1099 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1210 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (590 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (881 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1072 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (770 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (716 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1134 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3066 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2065 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (788 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2149 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (810 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (971 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2257 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1093 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (713 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (548 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1263 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1387 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (680 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (678 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (930 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (913 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1867 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (672 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (554 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (921 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1060 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (539 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (606 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3427 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2039 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1194 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (850 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (958 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (931 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1140 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1410 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (12718 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (931 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (528 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1013 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (871 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (758 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1082 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (672 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (886 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1007 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1100 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (707 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1145 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (582 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (829 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (820 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (704 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (954 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (918 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (999 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1153 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1062 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (707 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1018 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1034 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (800 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1029 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1043 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (862 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (748 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (784 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (975 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1039 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (950 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (892 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1147 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1247 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (736 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (623 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1088 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (694 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1061 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (841 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1023 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (787 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1016 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1013 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1623 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1056 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (803 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (606 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (855 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (875 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (976 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1351 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (705 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1373 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1298 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (574 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1304 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1180 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1770 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1228 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (663 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (781 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1944 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (763 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1222 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1179 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (738 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (945 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (812 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (996 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1252 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (969 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1227 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1243 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (836 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (776 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1322 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (653 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2118 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (763 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (943 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (696 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1122 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (846 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (613 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1036 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (845 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (987 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1350 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1257 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (948 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1004 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (832 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (722 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (822 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1252 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1204 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1160 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (643 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1014 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (909 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (673 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (903 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1801 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (777 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1433 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1222 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (601 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (907 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (677 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (757 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1098 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2959 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1043 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1058 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (720 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (693 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1391 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (514 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1036 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1176 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (826 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1046 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (547 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (802 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (514 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1237 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1030 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1108 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (777 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1262 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (658 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (536 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (814 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (822 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2387 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (993 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (778 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (655 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (646 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1044 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (865 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1022 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (747 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (882 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1242 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1173 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (547 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (768 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6820 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3326 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (827 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1178 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (708 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1041 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (780 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1342 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (716 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (727 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (998 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1025 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (765 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (712 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1262 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (547 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (775 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1054 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (756 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (676 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1362 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (601 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2982 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1775 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1078 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (755 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1678 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (929 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2022 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (620 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (522 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (825 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (920 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1110 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (811 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (881 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (653 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (616 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3269 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1142 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1177 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (7394 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1047 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (995 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (993 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (926 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (983 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (835 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1058 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (689 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1390 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (981 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1425 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (926 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1255 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2492 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (670 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1025 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (627 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (538 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2006 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (729 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (740 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1288 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (783 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (696 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (735 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (963 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1251 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1228 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1351 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (951 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (672 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (688 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (606 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1166 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (674 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (799 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1240 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (595 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1189 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (805 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (636 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1365 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (766 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (826 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1003 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1153 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (872 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (843 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1129 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1138 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (629 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1044 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (743 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (870 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (940 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3273 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1190 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (737 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (583 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1328 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1011 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1033 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (712 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1003 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4222 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (631 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1047 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1840 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (662 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (539 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1181 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (726 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2336 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1104 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (941 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1608 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1056 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (962 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (703 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (827 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1135 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (648 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (838 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (690 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (724 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1142 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (736 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1012 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2296 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (594 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (921 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1804 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2161 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1002 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (876 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1044 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1311 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (914 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (644 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (938 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (548 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (925 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1678 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1093 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1092 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1091 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (614 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1062 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1194 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1030 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1092 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1199 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (868 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (858 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (930 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1069 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (735 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (690 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (968 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1106 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (887 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (558 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (855 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1141 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (555 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (930 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (988 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1212 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1225 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (639 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1380 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (600 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1414 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1070 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (768 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (746 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (954 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (899 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (599 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (861 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (713 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (965 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (621 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (847 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1683 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (559 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (933 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (972 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (549 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (924 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1382 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1550 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3469 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (742 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (766 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (921 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2098 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (956 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2426 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (800 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2873 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (797 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (797 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (823 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (814 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1996 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (723 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (838 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (626 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (991 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (935 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (668 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (598 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (952 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (573 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (555 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (845 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (776 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (583 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (774 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (877 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (582 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (902 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (699 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (626 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (806 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (962 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (656 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (822 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (558 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1467 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (772 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (555 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (837 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (920 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2421 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (754 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (783 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (632 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (991 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (516 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (731 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1097 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (944 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (704 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (626 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (637 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (993 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (613 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1115 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1038 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (581 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3449 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (663 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (584 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1622 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (932 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (817 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (885 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2080 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1725 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (739 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1120 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1439 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (778 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (835 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (710 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (739 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (568 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1580 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (772 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (978 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (795 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (816 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (947 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (875 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (569 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (781 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1297 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1535 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (869 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1095 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (808 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1086 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (797 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1151 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (6435 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1191 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1044 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (829 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (709 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1328 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (953 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (908 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (676 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (927 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (555 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (887 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1147 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (569 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3500 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (645 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (638 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1830 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1017 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3344 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (695 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (746 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (613 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (971 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (747 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1001 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (947 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1941 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1048 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1515 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1060 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (998 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1238 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1051 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (927 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1059 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (808 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1060 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (848 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2020 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1501 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1234 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1081 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1368 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1400 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1151 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (919 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1125 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (692 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (523 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (975 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1639 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (853 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1776 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (530 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (603 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (563 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (781 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (862 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (633 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (830 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (809 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1215 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (901 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1312 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (972 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (534 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1050 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (745 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (658 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1248 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (628 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (976 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (931 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (986 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1033 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1110 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (810 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1113 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (911 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (583 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (957 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (543 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3570 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (800 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2753 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (623 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (625 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (992 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1404 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4247 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (911 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1133 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1876 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (817 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1979 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1252 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (638 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (632 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (684 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (584 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (993 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (696 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (764 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (988 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (878 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1537 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2095 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (723 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1033 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (882 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (814 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (605 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3750 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (892 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (995 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (682 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1042 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (715 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (932 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (588 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1503 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (539 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (921 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1051 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (592 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (730 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1562 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1285 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (952 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1382 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (871 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (790 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1093 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2444 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1370 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (543 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1043 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1268 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (826 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (586 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (539 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1006 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1300 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (649 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (666 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1220 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (811 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1363 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1315 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (596 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (756 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4565 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (728 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (972 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (641 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (900 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1394 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (604 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (769 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (619 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (561 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (618 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1855 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (609 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (526 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1024 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1387 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1519 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1147 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1161 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (691 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1016 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1238 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (660 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (669 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1033 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1171 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (564 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (632 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1348 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (525 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (719 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1293 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (682 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1018 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (765 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (595 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (974 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1316 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1109 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (940 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (617 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1068 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1010 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1711 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (601 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (852 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (855 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3593 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (533 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1289 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (4230 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (557 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (607 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (905 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (988 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2192 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (874 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (589 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (967 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1138 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1387 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (746 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (931 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2246 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (941 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1318 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1134 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (907 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1171 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1417 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1496 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1086 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (662 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2173 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1107 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (651 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (528 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (855 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (791 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1153 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (572 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (576 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (640 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1648 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (896 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1575 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1133 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (806 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (613 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (932 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2251 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (579 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1486 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1231 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2027 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (865 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (809 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (539 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (3026 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (875 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1784 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1609 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1259 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1030 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (744 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (735 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (659 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1015 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (531 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (602 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (982 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2273 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (634 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (730 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (706 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1202 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (529 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (713 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (812 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1265 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (895 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1254 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1804 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (783 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (665 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1471 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1168 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (827 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (608 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1159 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (610 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1080 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (532 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (609 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1334 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (545 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (611 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (857 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (830 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (886 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (930 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1361 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2014 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (938 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1171 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (650 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (585 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (777 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1157 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (5457 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1101 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (727 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1984 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1132 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2081 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (985 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1172 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1185 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1190 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1367 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (768 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1012 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1368 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1248 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1084 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1007 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (519 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1221 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (563 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1143 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (822 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (977 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1134 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (935 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (547 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (836 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (999 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (698 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (754 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2161 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1803 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1166 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (2686 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (836 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (648 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (751 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (925 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1371 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (742 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (759 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (883 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (850 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (799 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (898 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1150 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1012 > 512). Running this sequence through BERT will result in indexing errors\n",
            "WARNING:pytorch_pretrained_bert.tokenization:Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "PYohHqO2N7P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "9ZnVO3jZICIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "sF0IJZE3OCEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o_Njl_yOFP8",
        "outputId": "2825fc8a-5059-4f59-f192-ac0249247d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-26ef1eedc5bd>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_inputs = torch.tensor(train_inputs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_inputs = torch.tensor(validation_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGPuD_IBQsd-",
        "outputId": "7e64349c-5440-4797-80c9-3bb6258b24ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-08e540e74da3>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  validation_inputs = torch.tensor(validation_inputs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks = torch.tensor(train_masks)"
      ],
      "metadata": {
        "id": "lscb9nk0Qyfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "0cn4aDOtRWUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_labels = torch.tensor(validation_labels.to_numpy())"
      ],
      "metadata": {
        "id": "UOA45KW7RaZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = torch.tensor(train_labels.to_numpy())"
      ],
      "metadata": {
        "id": "hi2KylPSRang"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "mgV7eyH_ICSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H5BeFAKICWs",
        "outputId": "4ca324ed-8f96-46fa-ab5a-79cf94712e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:13<00:00, 29426275.85B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "metadata": {
        "id": "ZhULUacLICcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This variable contains all of the hyperparemeter information our training loop needs\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GCYSrRYICf0",
        "outputId": "6725320a-ba80-448d-abd3-185924eb3647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "BN4sPoPn71Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = [] \n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aczAZ-mW71JY",
        "outputId": "045338b7-62bb-49cd-a16c-8d665f455156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.26752843900114043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [08:01<24:05, 481.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9360576923076923\n",
            "Train loss: 0.21939350126518142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [16:02<16:02, 481.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9370192307692308\n",
            "Train loss: 0.207763537665845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [24:02<08:00, 480.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9668269230769231\n",
            "Train loss: 0.08604565399189472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 4/4 [32:02<00:00, 480.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9884615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "BxhD9pGb71Nf",
        "outputId": "7c5f318d-d7cb-47d9-86b5-72f6c11fad40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAHwCAYAAAD0Es3SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdebxdVX03/s+69wbCqEWwg6LRVmx5qnZAkNZaxyrYYvv4WLX+1GqrtX2s+rNqo1VAEURFBWSQSUBEZgQkgYSEkITMCSHzfJOb+ebmJrlj7nDuXc8f5+xz9tln7b3X2nvt4ezzeb9ekHvO2cPa8/ruNQkpJYiIiIiIiKj5tWWdACIiIiIiIrKDAR4REREREVFBMMAjIiIiIiIqCAZ4REREREREBcEAj4iIiIiIqCAY4BERERERERUEAzwiImoJQoinhBCftD2tYRreLoTYa3u5REREjo6sE0BERORHCDHo+ngygFEAE5XP/yalvFd3WVLKi5KYloiIKE8Y4BERUW5JKU91/hZC7ALwr1LKOd7phBAdUspSmmkjIiLKI1bRJCKipuNUdRRC/LcQ4iCAO4UQvyWEeFII0SOEOFr5+5WueZ4TQvxr5e9/FkI8L4S4pjLtTiHERRGnfY0QYoEQYkAIMUcIcaMQ4pea2/FHlXUdE0JsEEJc4vrtYiHExspy9wkhvlL5/szKth0TQhwRQiwUQvB5TkREABjgERFR8/odAGcAeDWAz6L8TLuz8vlVAI4DuCFg/gsAbAFwJoAfALhDCCEiTPsrAMsBvAzA5QA+rpN4IcQUAL8BMBvAywH8J4B7hRCvr0xyB8rVUE8D8McAnq18/18A9gI4C8BvA/gGAKmzTiIiKj4GeERE1KwmAVwmpRyVUh6XUvZKKR+RUg5LKQcAXAngrwPm75JS3ialnABwN4DfRTlg0p5WCPEqAG8GcKmUckxK+TyAJzTT/xYApwK4ujLvswCeBPDRyu/jAM4VQpwupTwqpXzB9f3vAni1lHJcSrlQSskAj4iIADDAIyKi5tUjpRxxPgghThZC3CKE6BJC9ANYAOClQoh2n/kPOn9IKYcrf55qOO3vATji+g4A9mim//cA7JFSTrq+6wLwisrfHwRwMYAuIcR8IcSFle9/CGA7gNlCiE4hxHTN9RERUQtggEdERM3KW2r1XwBeD+ACKeXpAN5W+d6v2qUNBwCcIYQ42fXd2Zrz7gdwtqf93KsA7AMAKeUKKeUHUK6++RiAByvfD0gp/0tK+VoAlwD4shDiXTG3g4iICoIBHhERFcVpKLe7OyaEOAPAZUmvUErZBWAlgMuFECdUStn+TnP2ZQCGAXxNCDFFCPH2yrz3V5b1MSHES6SU4wD6Ua6SCiHE3woh/qDSBrAP5WEjJtWrICKiVsMAj4iIiuJaACcBOAxgKYCnU1rvxwBcCKAXwHcBPIDyeH2BpJRjKAd0F6Gc5psAfEJKubkyyccB7KpUN/1cZT0A8DoAcwAMAlgC4CYp5TxrW0NERE1NsF02ERGRPUKIBwBsllImXoJIRETkxRI8IiKiGIQQbxZC/L4Qok0I8T4AH0C5zRwREVHqOrJOABERUZP7HQCPojwO3l4A/y6lXJ1tkoiIqFWxiiYREREREVFBsIomERERERFRQTDAIyIiIiIiKoima4N35plnymnTpmWdDCIiIiIiokysWrXqsJTyLNVvTRfgTZs2DStXrsw6GURERERERJkQQnT5/cYqmkRERERERAXBAI+IiIiIiKggGOAREREREREVBAM8IiIiIiKigmCAR0REREREVBAM8IiIiIiIiAqCAR4REREREVFBMMAjIiIiIiIqCAZ4REREREREBcEAj4iIiIiIqCAY4BERERERERUEAzwiIiIiIqKCYIBHRERERERUEAzwiIiIiIiICoIBHhERERERUUEwwCMiIiIiIioIBnhEREREREQFwQAvAyt2HcG06TOwfl9f1kkhIiIiIqICYYCXgWc2dgMAFm0/nHFKiIiIiIioSBjgERERERERFQQDPCIiIiIiooJggJchmXUCiIiIiIioUBjgERERERERFQQDvAyJrBNARERERESFwgAvQ6yiSURERERENjHAywBL7oiIiIiIKAkM8IiIiIiIiAqCAV4GWDWTiIiIiIiSwACPiIiIiIioIBjgZYBt8IiIiIiIKAkM8IiIiIiIiAqCAR4REREREVFBMMAjIiIiIiIqCAZ4REREREREBcEAL0OS4yUQEREREZFFDPCIiIiIiIgKItEATwjxPiHEFiHEdiHEdMXvrxJCzBNCrBZCrBVCXJxkevJGcLwEIiIiIiKyKLEATwjRDuBGABcBOBfAR4UQ53om+yaAB6WUfwrgIwBuSio9ecQqmkREREREZFOSJXjnA9gupeyUUo4BuB/ABzzTSACnV/5+CYD9CaYnP1hyR0RERERECehIcNmvALDH9XkvgAs801wOYLYQ4j8BnALg3QmmJz9YckdERERERAnIupOVjwK4S0r5SgAXA7hHCNGQJiHEZ4UQK4UQK3t6elJPJBERERERUTNIMsDbB+Bs1+dXVr5z+xcADwKAlHIJgKkAzvQuSEp5q5TyPCnleWeddVZCybVn9oaDeHJtQG1TVtEkIiIiIqIEJBngrQDwOiHEa4QQJ6DcicoTnml2A3gXAAgh/gjlAK/pi+g+e88qfP5Xq7NOBhERERERtZjEAjwpZQnA5wHMArAJ5d4yNwghviOEuKQy2X8B+IwQYg2A+wD8s5TsW5KIiIiIiCiKJDtZgZRyJoCZnu8udf29EcBfJpkGIiIiIiKiVpF1JytERERERERkCQO8DEmOl0BERERERBYxwCMiIiIiIioIBngZEhwvgYiIiIiILGKAR0REREREVBAM8DLENnhERERERGQTAzwiIiIiIqKCYICXIbbBIyIiIiIimxId6LzVPL3+AHoGRrWnZxVNIiIiIiKyiQGeRZ/75Qta07HkjoiIiIiIksAqmhlgyR0RERERESWBAR4REREREVFBMMDLAKtoEhERERFREhjgERERERERFQQ7WbGgZ2AUV87YmHUyiIiIiIioxbEEz4Ib523HYy/uzzoZRERERETU4hjgWXDa1PCC0Gc3d2N8YjKF1BARERERUatigGfBS06aEvj7ou2H8em7VuLaOVvrvpccLYGIiIiIiCxigGfB6SEBXu/QGACgq3c4jeQQEREREVGLYoBnQUeb3rAH3gI7wdESiIiIiIjIIgZ4FkxMRqtrySqaRERERERkEwM8CyZDIjVvQR1L7oiIiIiIKAkM8CzQ7hyzEgey5I6IiIiIiJLAAM+CiZCIbXC0lFJKiIiIiIiolTHAs2AyoA1eZ88gvv7oOgCArBThsYomERERERElgQGeBUGdrOzoGUoxJURERERE1MoY4FkQ1MmK+ze2vSMiIiIioiQxwLMgqASPQR0REREREaWFAZ4FwZ2ssASPiKjIegdHMWvDwayTQUREBIABnhVBnawwqCMiKrZP370S/3bPKvQNj2edFCIiIgZ4NgSNg+eO/SQY7RERFc2eI8MAgNKk7qCoREREyWGAZ0FQFU0GdeS1evdRHB+byDoZRGSJZFUNIiLKEQZ4FgRV0awrwWMeoOUdGhjBP9y0GF99eE3WSSEiIiKiAmKAZ0FgCR6jOnIZGi2X3K3f15dxSojIFiFE1kkgIiKqYoBnQVAJnhtDPXLwXCAqDr7IIyKiPGGAZwHHwSMiIiIiojxggGeBbicrDPaIiIqHVTSJiChPGOBZYDoOHrMCrYvHnqh4WEWTiIjyhAGeBSXNXjSdllfMChARERERURIY4FkwyV40iYiIiIgoBxjgWRDYyYr778oHVtMjIioetsUjIqI8YIBnwcRkwI8swCMFFuwSERERURIY4FkwdYr/bnRX32SenoiIiIiIksQAz4Ir/+EN+NCfv1L5G4M6IiIiIiJKCwM8S9rb1G0v3FXx2OEKsYkOUfHwzk5ERHnCAM8Sv8b17GGT3HjIiYiIiChJDPAsaVfsyfGJSZRcPbAwb09EVDwsmCciojzpyDoBRdGuKMH7X5fOwlhAF5vsUrv18JATFQ9f3hERUZ6wBM+SNkUbPG9w562exyqaRERERERkEwM8S1QleH5YikNERERERElggGeJqgTPyymvu3HejmQTQ7knWamLqHD47o6IiPKAAZ4lbRGK5dgGr/UIZgGJCouvbYiIKA8Y4Fmi6kXTy9vmjm3wWg9L7oiIiIgoSQzwLDFpg0dERMXDpwAREeUBAzxLdNrgEbGKJlFxsXyeiIjygAGeJVHa4BEREREREdnEAM+Sdp1eNPl6l4iosPiaj4iI8oABniU6JXgSEsfHJlJIDeUdg32i4uD1TEREecIAzxK9XjSBj9y2NPnEEBFR6hjnERFRHjDAs0S3Dd6aPceqf/OtLxFR82MTbCIiyhMGeJZoVdH0BHSM71oPM4JExcOXdURElCcM8CzR6WTFi5kCIqLikLypExFRDjDAs0RnHDzJMjsiIiIiIkoQAzxL2iPUvWPAR0RERERENjHAs0S3F82gz9Q6eOyJioeXNRER5QEDPEtEpBI8IiIiIiIiexjgWaJTRZMBHRERERERJYkBniVRetFkPT0iouLgLZ2IiPKAAZ4lOr1oeovwmBcgIiIiIiKbGOBZ0sFx8IiIiIiIKGMM8Cw5feqU0Gk4LAIRUXHxHk9ERHnAAM+SM045wXgeZgaIiIiIiMgmBniWvOzU8ACP4+AREREREVGSGOBZ8tKTw6toruw6WveZ8R0RUfOTfFtHREQ5wgDPkhM72vHIv1+YdTIo5zSGSySiZsU4j4iIcoABnkV//uozjKbnS9/Ww2NOREREREligJchdrJCREREREQ2McCz7MvvOUd/YsZ3RESFwVs6ERHlAQM8y77wrtfh8r87N+tkEBERERFRC2KAlwCh2ZNGq73tXbz9MFZ5ehIlIgoyMj6BHT2DWSeDiIioaTDAS4BuT4mt1rX2P92+DB+8eXHWyciFVjv2RFF97eG1eNeP5qN/ZDzrpITiZU1ERHnAAC8BTnx39hknYef3LvadjpkBIqJgSzp7AQAjYxMZp4SIiKg5MMBLQqUI74T2Nu3qmtQaGNQTRcNLh4h0dPYM4rLH12NykncNal0M8BLghHQdbfW7991/9Nt1n4t06xkYGceXH3gRfcfzX42KiCgJHPqGKHuf++Uq3L2kC9sOse0utS4GeAnoaCuHeN7Cu5NPaK/7PFmg4pyfP78Lj67eh9sXdmadlMSNjE9geKyUdTKIiIjIw8lasQIVtbJEAzwhxPuEEFuEENuFENN9pvlHIcRGIcQGIcSvkkxPWjra1bv1t06eUve5NFGcAM95c90K99O3/WAezr10VqR5+YafyEwr3FOIyB4+ZYmAjqQWLIRoB3AjgPcA2AtghRDiCSnlRtc0rwPwdQB/KaU8KoR4eVLpSdOU9nKWxFtAd87vnFb3eXxiMq0kJa72xqz42bFDA6NZJ4GIcqhAlTKIiKiJJVmCdz6A7VLKTinlGID7AXzAM81nANwopTwKAFLKQwmmJzVTfErwXnPmKXWfxwoV4FVK8Iof31lRlHxgaWIS06bPwI3ztmedFCIiIpb6EyHZAO8VAPa4Pu+tfOd2DoBzhBCLhBBLhRDvSzA9qXHa4Hm97JQT6z6PF6qKZlkbI7xARXvD77ykuOFZBniUrDxfOzlOGlHL4fVIlGAVTYP1vw7A2wG8EsACIcQbpJTH3BMJIT4L4LMA8KpXvSrtNBpzSvC87a1+65T6NnjjpeKU4DkdxjC8ay15znQTERERtaIkS/D2ATjb9fmVle/c9gJ4Qko5LqXcCWArygFfHSnlrVLK86SU55111lmJJdiWaoDnyfyeckJ9PF2aLE6Ax16riChJzXBv4fsOouw1wa2CKHFJBngrALxOCPEaIcQJAD4C4AnPNI+hXHoHIcSZKFfZbPp+9jva1bcXbwZlrIBVNFuhkxUiSh9Li4lIB28VRAkGeFLKEoDPA5gFYBOAB6WUG4QQ3xFCXFKZbBaAXiHERgDzAHxVStmbVJrSUu1F0/O9gMBn/uo11c8LtvYUpifNSXayooUPHiIzvKcQERGZSbQNnpRyJoCZnu8udf0tAXy58l9hdLSp42YhgJM81TTvW74bn7hwWgqpSlglcmEnK0TUqmSBixm7+0ew5eAA3nZO/ptJUGtjLoQo4YHOW1VHdRy88Id9V+9w0slJBTtZMVPgfCARFdAlNzyPT/x8edbJIArFxysRA7xE+I2DpyrcGhotJZyadLCTFT1FfsNPlCRvr8SUru7+0ayTQEREmhjgJcAZBk/VBs9r6pT25BOUAo6D19p42IlYMp9XR4fG0N0/knUyiIhSk/U4eAWl14smUJwSncmCbAcRERXLn17xDABg19XvzzgllCa+d6RWxhK8JHliHtXNpjRZjMBIspMVLcU42jVF2x7KH1XNByKiMHw+UStjgJeAEzvKu/V3Xzq17nshalmVj55fHgN+ojABHodJoOKb/shaXDtna9bJICIiIvLFKpoJOPuMk3HdR/4Eb3tdfXfS7tjn5adNxSteehLGCzLYeXWg80xTQZSs+1fsAQB86d3nZJwSIiIKwvwItTIGeAn5wJ+8ouE7b+lWe5vAxGQxBjqvVtFs4y1VB3sEJDKT62a+eU4bUYviZUmtjFU0UyRcEZ5Eeby8orTB4zh4enKdSY2gKJ0EEdnAy4GoNe0/dhyH2FMr5QgDvJS5S/E62gRKRauiGbER3vGxCdy+sLMwbRKJqIXwzRZR7qR5Wf7F1c/i/KvmprhGomAM8DLU0dZWmBK8uJ2s/GTOVnx3xib8Zs1+i6mipBXj7KU8a4qOm3ghEOUOL0tqZQzwMlSuolmwNngRc2P9x8cBAMfHJ2wlKaeK+chphjw4NSdWeyQiIjLDAC8rUlY6WSlG7oVt8FoTM99ENew8iSg/mB+hVsYAL0NT2tqK0wavshlRq1MxUGhSPG6UsKaooklEucPHE7UyBngZam8rUBXNyr9RO1lpFQxkiYiIiChJDPBSJlyVBjhMAjU7VkkjquELHKL8YH6EWhkDvAx1FKgNHmJ2stJqmBEkMsNLhoiISA8DvAy1t7VhPIdt8FZ1HcVdi3YazTMZc5gEak4MVClPFm0/jDdePguDo6Wsk0JERJQZBngZkQCmtAtM5LAN3gdvXozLf7PRaJ5aG7x46y56fFjUeIhtLykPrpm9Bf0jJWw52J/J+ot6fRMRUXNhgJcydz643MmKvSzBqq4jGCtlEzDGHQePmlMzZ2g/dvtSXPr4+qyTQSFM7ii8+yRPstieiCj3GOCl7NQTO6r/drQJa8MkbO0ewAdvXoIrZ5iVvNky2WQP/ee2HMIvl3ZlnQzK0KLtvfjFEp4DzSLPgUV+U0ZERK2IAV7KPn7hq/Gtvz0Xn37ra9DR3matk5UjQ2MAgE0HB6wsz5SzFc1SgvfPd67ANx9Lv/Qmx3nUSPKc6abmsKNnENOmz8DOw0NZJyU2Xg/FI6Vkm04iajoM8FLwipeehLe//iwAwJT2NvzLW1+DKe1t6GgTGJ/IXxu8KCQ7WSGiCB5bvQ8A8MSL+zNOSXStdNtrtRj2lgWd+OPLZuFQ/0jWScmVo0NjmLOxO+tkEJGPjqwT0AoWTX+n8vt2i8MkZP3QzXr9zaYou6so20Fqz27uxjm/fRpe+VsnJ7aOsOAoSgc+ad+PeB0U18x1BwAAB/pG8PLTp2acmvz47D0rsWLXUbzwrffgjFNOyDo5ROTBErwMTWlvsz7QeVZvkv0yVAMj4+gbHk83MTnGgcGpmXz6rpV4708WZJ0MbVn35toKV3crbCOF29U7DAAoFaQWElHRsAQvQ+1tojA3R6eTFW+g96Zvz8akBHZd/f4MUkVJY8lt8Q2NTWSdBGM8LYmIqJWxBC9DHZaHSciS31YUZPPIh1Mi2UptkCi/eB6SbXyJRUTNiAFehjraa23w+obHqz1h5omUEl97eA2W7OgNnQ7gm3MiMqN7z2BGOx/YUyjlHc9RIgZ4mWpvK7fBk1LiTd+ZjT+74hntecdKkxgZr1WdSrJt14Mr9+Kjty0NnKbZ76cTkxJffWgNth8aTHQ9uvvp+NgE7nh+JybzXgSa8+TlwT/esgRfun911sloKVndj5r9Pkiki+c6Ub4xwMvQlLZyhaIoPWm+5yfz8Yfferrh+6z6GKi1wYt210+z85Efzd7S8N2mA/14aNVefOG+fGTEr5m9BVc8uREzKj24UfNavvMIHmviIQCSZvOWxWFaksd8PeVd1p0tEeUBA7wMtbeXb0JR2uF1VXqwSppuvGbroZ/Gffmnz25PfiUhwvbrsUrPo8fH893BBTN7lEesokWUrDzHULz+iRjgZaqjLXqAlze8n+ox3U85foYSpUrn2hGZXzG8ERIRUfYY4GWoo628+ycm8psp0O4Awfk3v5tCCSjC8d7aPYCHVu7JOhlETaEI1zwVG6toEnEcvEx1VKpojk8WYyy8IshL3oUDoqfnbyoDeX/ovLMzTgkFMbkm0r56WCWMKD94PRKxBC9T7TE6WWmQ0P3M9EbJwCSY6f7J+5tIHm+ypQjnUivkK4twnIiIio4BXoamVKpo2myDl3UblFbI4KSC+5FaheZLjDzfW/L+Iobi4yFuHrweiRjgZcopwStN1KpoHhoYQc/AaFZJaqA/CHGOc18a+DyIRvewP7l2PzYf7E82MUQZXcfNfv8z0UKbSk2qla5HIj8M8DLUoRgm4fwr5+LNV87JKkmx8b6qqxg7qroVIRnrz/9qNd537cKkk0MF1gxXTDOksVkcGhjByl1Hsk4Gq6QSUVNigJehai+aOR4mgQGbXRwmgbK2/dAA1u49lnUytEUpXW+1+9bavccwbfoMrNvbl3VSrLn4uufxf362JOtkUBNiFU0iBniZcqpojk8UpxfNZs9X5aVqRz5SES4v+4v0vfvHC3DJDYtCp8vbsdVJT6tm6+ZsOgQAmLu5O+OU2HN4MD9NFai55O3eRZQFBngZcl4y5fleZFo9JeqNNc/7IEt8EUlZSfuatLm+rKrVJbHP1uw5hv6RcfsLDjEwMo7JHNcuISIifwzwMtRmMffOx7Adeana0SxvIJskmRRBWodW94rTSU9OLl9rRksT+MCNi/Bvv1gVPKHlC/HI0BjecPlsXDd3W9KrIiKiBDDAy5CTF5m0+MS0ncExTVqzP/vzFlgVLcNKzSMv10IrXwPHxyYAABv2B7etc46UrWFynOqRM9YdsLI8Kp6c3B4CtfK9g4gBXoYqfaw0xY0yTBG2IU+4O4nKIt1bCnIBjYyX22dPndKecUqImg/zJdTKGOBlyHnbarMEL3MJbkoW7VBsK9KhpmLL26mqc+3YKsGKynbbv5HxcgleVgGeam+26rABWZ9becPSMaJ8Y4CXoWonKyHT7e4dxrHhscTTk2dbuwfwxstn46GVexJZPh/e0TBgLS73se3uH0FX75ByuhW7jiQ61EukYRLsJyMTIyUnwNN7VDPTTWlphns/rwdqZQzwMuR0shLW1uVtP5yHd1zzXOA0ebnZJvV2d8vBAQDAc1t7Ell+2nSPV7MEns2RSjLhvpYvuGou/vqHzzVMs6yzFx/62RLcOG+7hfXFnyKrDF1St1/dKppp3v/z8qyJq+/4ON72g3lYv684YwdSvaKcq0RRMMDLkJMZ0Xn5fXRYr3pi5p2sxLyhNktAk7SsH0zPbOzWqhKrE9DnpbMOMqNz2A72jwAAth0ajLwem/esrE812+uvVtHsYBs825Z29mL3kWFcO6exp1AKx9IxonxjgJehWglexgmxoFXbZZgy3U9ZPET3HBnGZ36xEl9+4MXQaXXO3SKc35S9PJ9HSV2mToB3omYVTTLHQCWaPF+PDh5bamV8amQoiWESbDMe6DyhdKS3gnzIcjOPVzKVXb3DVpaX5/M7j1Z1HcWLe44lvp7RSvuuIslLFc2t3QOYNn0G1sQ8jqadrNjefNWVm9TVvLSzt7q9RDbw0UOtjAFehkSBSvCoOEzOR51JE+x/I1Ufv2NZKuv54M2L8fc3Lkp8Pa//5tOBv+ftvmSSnKzS7qx37qZDAICZ6+ONIzc+UV5gR1tw6NZMNSgmJiUWbz9c911nzyA+cutSXPr4+tTSkbfzu9mwdIwo3xjgZajai6aFJ01SD/i02uBl/axN62HVTJkKW/ukKCV4C7cdDp+oQPISNJi0yy1aprM6gHlG26UcJiHm9fyz+TvwT7cvw8JttQ6zjh0vt/fd0t3YljO5Nrzl5Ybt2ma5ffUMjOK+5btTW1+z7BeiVtWRdQJaWbUNXsbpsCkvmUJdUspqSSqZ08l8MSPQnEyOm5UrKGSFrXgeOddXVp1PJbHLt3WXe0Q+PDja8JtqKycl0J7g5hfl9v+5X67Cqq6jeOsfnImzzzg56+TkQgveMoiqWIKXoVovmvm9DemmLMebECizqlzZrDYxQUFyns9vN/b2mY0kgpesXjRltt7KatMIVuJuYWnSqXZay34EXXq8LvX0VgLm8YnJVNZXlMCYqKgY4GWorRrg2Vtm1sMMJPUsTuphknbWQT9gzi5TY5JJ1WuDxwxaM8rbUdM5L7O+/2XNdm2EJPbmROWB165oV6hKft7OQyqLelt/Ys1+DI6W7CaGiBowwMuQ0BzoPEu6acvxJgTKe/CRZfVRW5nlyXReKMeW81MhdXm+L4XJOum2SvKy3o4klJQBnv+GJrUPqqWeLf5SQMehgRF8/dG1GCvFu5lv3N+PL9y3GtMfWWspZcGKeP0Q6WKAlyHnsWLjJpSXG1lOkqEtL/vNK6fJaqCz//IeRDuaI5Xpydv+0DmNsq42FvdUv21BJ9537QI7ibFAOUxCzG2cqFbRVJTgKdOQUAdizjoLEt8l+TLw209sxH3L9+CZjd2xljM8Vi65O9A3YiNZRBSAnaxkqNbJSt6yUjXGKUsoM5/YW1zPFuYtFski72F7HzRLgEf18jKIfTNmwKOWCl05c1PdZ91nQzNdYU4bMVUVTRXePrIXeA9vwuuTqBWwBC9D1U5WmqQKWxGlnXnQrjq6JQcAACAASURBVPaWYabGrMOG8IQ2yzh4zVwlsQj89n6Uw5L1kbReRTNHwyTE3TSnBG9Ku14nK0nh5W5Jjvdjnl+eEyWNAV6GkhgmwfbbbuNx8OyuPnF5f8g3Y+mFFwOn5G060I9NB/rtLjRnhy3Pp1HS7cQyW38Cy1S3wStTVTNM+rgX4R7rluPLpIrPBKLkMcDLgSJUYWvWN2VOutN+yIc94Jplf+q1wUs+HTY0STKVLrpuIS66bqHVZaZ9DvpdglGuzawzkM3ecUeSqVe1wQs6Wsm1wfNf7ob9ffjzK55B7+BoqkNQxKGbvMlJiQu/Nxe/Xr3XfB0xeznN+z4kKhIGeBmqluDZ6GQl/iKsLLjphklIu4pmyO/Ldx7BHc/vTCUtfqIMkxB0fJrlBUaTJDM1edsfJuflFU9uxK7DQwmmpp73/DdJa9/wOFZ1HVX+ltUhSDLgCizBU60v6RI8xVpvXdCJ3qExLNx2ONmVZ2BsYhIH+kYw/ZF1sZbTDMFa3u5hRGligJchZ5zXrN8222BtE9IuSUt3daH+8ZYluOLJjVknA4C9XtmaJcCjes38Zn5HzxA+98tVqa0vzin+iTuX44M3L66WbNUvt1LDQHNZWRyHh1buwe7eYe3pJxSNzoP2X1L3j6LeltLarqLuP6KiYICXIefNYbNUYdORZbC69+gwdhq+tfdmHvJWNTLvVb20qmg2SSdCeTv2ce3uHca06TPst81LSNjeN24PnGHHHSbX7bq9x+Kv1/K5G5R673796sNr8fc3LdJedmmivABVijMZ6Dwnt9iP3LoEb7lqbvQFBGzHtOkz8LWH10RfdgAGekT5xAAvQ04NlTxnLHXTJqrbEnE9FnbBW78/D++45rnU15vE+rJ8aLbqMAlNkkxtszceBAA8tNK8rQ2Qn5oFJvnvJMcC89p+aBAb96uD5yj3dNX+Nl2KrRdCuut10nxkaEx72UEllep1aC/aSD7O7pqlnUdwsD+58eEejHgf8BPnUktr3+fkFkaUCQZ4GaoOk9CkN6HJSYmxUrl4pmlvpDlPd5ZV33RWrZORbZYAr2jidg5h46j95JmtoSUHeaveqevdP56Pi6+317GNcn/n/NKJcmk7AZ5qXmWAmngbPAqjOla8rRPlGwO8DIlqJyv5vVMGJe2yJzbgnG8+VZf+pDfFdmlnXktPc3xKGGvWFxhFETUDa+McvG7uNuslB0GyzqxXe+WNkJJY+9vyNRZYRTPmasdVbfAC15dUG7yi3piS2y5lJzg5fIbmL0VE6WOAlyHnZtmsz5l7lnZV/27STaju+7z1punIOsMaRme/VTuKyPnGNOt1mBSdjFuambuiHx/VvjTdv3kb7kVlYsKZR1mEp1iH8SqMpFmtt0iaYbflMfgkSotWgCeEOEUI0Vb5+xwhxCVCiCnJJq34agOdx78JRX0bueXgADp7Bv2Xq7Vus+nzJP3qg3rrK9KDySnBa4L8QKFkNcYjmQksvapWs033IAanSWpN56ekbIMXLS2UnTy/cOEtj0i/BG8BgKlCiFcAmA3g4wDuSipRraLaBi/hXgZHxieUDdsB4L3XLsA7fzTf2rp0As09R/S71E5a9V1yTh9W6/b1YdH2bMZi0slT6g10Xp6oLeeRRhpB9bbuATy8Kp0qi7GDg5x1QKRzfLI+xao1AiJ1sqL4LmZ6khblvuncD+pfDDpVW1XryPteyAfdGkG2d6fZ8tK5QHnGEOkHeEJKOQzgfwO4SUr5IQD/K7lktYZaCV6y/vBbT+PfXWNCbdzfj+NjE1rz6jxcTdP/Vz+YZzhHcvKad3Da8Nz03A587PZlodPvOTKMv/nJfBwaSK4Xtqgmm6SKZhre85MF+MpDyXRXbpvJpRHn0IbNyyp04WzfxnT3eJyXIlLxIc1hEmpDWlAY1XFuhssyr893ojRoB3hCiAsBfAzAjMp37ckkqXXUetG0dxfyywzN3tgNABgcLeHi6xfiwqvnYmi0ZGWdzfyG1XlwpVUlUnuYBMP03L14F7Z2D+Kx1fsipMqzboNVa/WiWSmhzntG3WS7TbqFz0rcMzpvl3VYejbs78NzW3rSSUwIW52smB4DW1dYcKcnrr+td+7SuAXJt8FLbtmPv7gPx4bzda+w9azL2/3BLd9PGqJ06AZ4XwLwdQC/llJuEEK8FkB+imGaVBa9aI6Ol0vujg2P40sPvBg6vXbKImzCDc9uw3nfnWM+o0XeXR/1UBwaGMG06TOwOMfVKZNYps5b8FoVzfhpSpLJof+zK57BZM67B41bQtEM7UC/8tAaPL3+AADgu09uqvsti/TXug+JUEXTQicrzUS37XazvkDcc2QYX7z/RfznfatTWV9WL9DyeHTymCaitGkFeFLK+VLKS6SU3690tnJYSvmFhNNWeNWBzi3cjXQX4Z5u0wH1IL1x1m2yLdfM3orDg6N13/k9oqIO4Lvr8BAOBQwea6sXzRe6jgIA7lq8K96CKqKmJ495oWZpg2fq1oWdWSchUDU4KMhuV53aD6/ai8/98gUA6gG0m0mca9d2EBTY6YnUmy7KstOsoqkjToB9vPIy9UBfvqrN5/EZQUT26fai+SshxOlCiFMArAewUQjx1WSTVnxO0JJmvsT05q4z/dxNh7B815Hy9Dl7d/b2a57D+VfN9f097fQmtbY8V39sll40TTPJ2w/59z5rw8x1B6wsJ+rLEb0hMCItOhElT29VUbfbhqB1D4+VMG36DDzi6WxHtSuNq2ha2mTd+2KsNnia46cmdY4FdexiZflNct/LQuLVbpNdPFFT0K2iea6Ush/A3wN4CsBrUO5Jk2KoluBlFBTZusl+ztWBi/+6cpQTdMlpsiKfETY2x/pg8pWdPDQ2gf6RcavLtilvp8IvXeNMRhH33DbqZMVCZBH3vMuyBM+b9qBt6e4v11r46bPb6udRHDDnm7C9m+Z9LMnnlboEL5n16fQyG+clgZPutGsuhO2tKHuztq9Uv+Xtzpm/ezlRFnQDvCmVce/+HsATUspx8BqKr9rJSrbJ8COlNH645vBeH8j2OHhCADsPD4V2wmG/cwL7dDI3esMk1P6+Z0m8oKWVnDTFTj9WkUdJSOli1k1fWHrGJ7K/+cTZZ8o5M7qhancGFadaqe502R9WANFrv+StckUeA7KktNCmEjXQDfBuAbALwCkAFgghXg3ATgOuFlZ9s+dzF7ptQSde8/UZyt+iavbSQttstcFze8c1z+FtPkNBpJFxyptmyVDkLZlTT7AU4EWcL2/7I0ye2uDZ6kUzK/q9/dpZR9BzKUe7xUiejmdeVLM8Sa8n4eUTNYMOnYmklNcDuN71VZcQ4h3JJKl1OAGeX77kypmb1D+4SCnLVUx06/snfGf1W3yzPOsiV430zDgYcwgK46DIZoc9BsvIW5vLIjnZUgleUYSdad42eFkyuS4C258ZrjeVdod1naxYrgGhHCbBfpXxXy7twmhpsrLOkOmjrsdp45dSEZ72QOdW1uJaXg4fATlMElHqtAI8IcRLAFwG4G2Vr+YD+A6AvoTS1RKcW2WcaoJS2qsCsqrrSN04UlKi8HfKagmepQ21lcEKOydGSxPoOz6Ol582tW69Nraj2u7HWocNTSJnCZ0aM8BzMsZ5qyJmSjf5eSjB00mBb8Ci+Fq3mp/tLdfvZMXOOoJud19/dB2WdR7B1isvirG2mo0H+vGtxzfUvtCtIhyxuUKTX35NjS8gqZXpVtH8OYABAP9Y+a8fwJ1JJapVtFXHwWv87dYFO7SWYfP29cGbl+Cnz26PtQzfvItmEHv1U5tRmvB/E2/7baETSOXtYRyWV/3Cfatx/pX+vYPGYfLGvNl6WgximhmIc67o7OPfOnlKjDW4z+li9KIZtq48tMEz4S3ZyVNmVLdU0XpbYsWpunDbYYwFPBNMOSV3SctvG7ysU0BEadAN8H5fSnmZlLKz8t+3Abw2yYS1hGonK4133KtmbtZahGn1FdN7u/n06jnCe/YqT9E7NIan1h80XGt03nQl/ezTPV5hJXizNnT7LN84SY3LiL8Iz/KYo/AKCuBPPbFcseLM006MtY64ez31IURiri4PJXheJsG1avtz3341XhFe4GKSCozSGmO0VkUz2vpM5S2QJKJs6QZ4x4UQb3U+CCH+EsDxZJLUOtos3JCTfPxnlbWw3bNlECcDFT8zbFdW41+Zrjvn2U9fqjHm0i2N8l/ZyZXOVWylJ3ovmnbWH0a/jVJwgko5CPC8+yyw8xDPxKopjdvgpZzJT3TIhMSW7F1PMmuKW4KemAwvk7T3RN7fjxAlSasNHoDPAfhFpS0eABwF8MlkktQ6RLWTlXht8AD9t4VJDHSuM71R0JBmRtvy8mx1+Z5mkNuoci4ZzBGYSZfu6aKlyKZ1e/vwH/e+0PB9mns8Vlst3XUUJXOjec5MeDpZyWvJsd+1Ena8j49NQELi5BMaH9u2j7XuwOO2hklQbXu587AkjmG0ZUat/ZKHe15c+byS1EoTk9h1eCjrZBBlTqsET0q5Rkr5JgBvBPBGKeWfAnhn2HxCiPcJIbYIIbYLIaYHTPdBIYQUQpynnfICqA50Hush2Uy33vj8HpZRM8PVErwYB6Hv+LgyYFCuT3OZugFetSMNzeXqLdNk2vCJk2yzE0UeBlsPOr62uhKXEQL1+vnzJezcyUMJnpdRFU3Vd64v3/Sd2Tj30lnxExVgclLiEz9fjkU7DmtNH2WPB82TVo+T9etMZrlJ3Ju11htyVOLkGdQDnUdeXCJ+OGtLbscWJkqTbhVNAICUsl9K6Yx/9+WgaYUQ7QBuBHARgHMBfFQIca5iutMAfBHAMpO0FIHz8I9zM4raLkBv2eYDnVtZr2fajfv7cVVlyAi/7f3Z/M5o6bKweev22u9MNuo5YaPNjskSTNdWmpB4/MV9VtI5OFqKtJy4HQHZELSqao+otpITMQdrsj/yUEhRykUnK95qlyb3W/ff9VXHBYCxFDoH6Ts+jgVbe3D1U5vr0uEmITFvyyF09Q7FG9g9rA1e5CUnI2p79yyC1iB5C8hsW9rZW/274JtKFMgowPMIu2udD2B7pVOWMQD3A/iAYrorAHwfwEiMtDSl2pv6fGQs7SxfvYI4VTQ/fMsS7DsW3ORzseYb54Z1ef6Ntgz7O1U3M+HtqU1KYP7WHjy8am+MdaN+oTG5N+WGedvwxftf9O0kRlfv4Cj++LJZkXp9jdoRUNpsp2dyUpr1kGp5/XGFpSePnayo+N4jFVuofR9I+Wh96s4V+OsfPhdprdXx2hRzZxEKJbXOvPaiSUStIU6AF3ZvfwWAPa7PeyvfVQkh/gzA2VLKGTHS0bSChknQZTqvaduuor/ts9HWLYn2hcadrLiyKZ/8+XJ85aE1ZguoW3e0UgffaVy3Cqcr+yNDY8bpcnPmf/zFfcbz5uGc1qqiKSU2HejHz+brDZni5ayid3AUAPDab8zE1x9dZzx/WuKuzjvQeR46twhKQ0PJjoW2bVFLi/YeHVbWRAhbXpR0KmdRfJmXXjSjl1Kqq2g+uGIPlrlKmWzRPd9tX9aRXi7k4SZMVHCBAZ4QYkAI0a/4bwDA78VZsRCiDcCPAfyXxrSfFUKsFEKs7OnpCZu8aTgPsMkYb56jDr5a/jusrn69lbuOGC0/qizu/bY6C7CVKdFugxfyOQrrGQDFAr0dYpg6oaN864oyPpbfvs3LmG7CNc37r19YrS5nvI7Kv/cu21397v4Ve9QTBy4hzhT2hB2fPBTgmfSiGbgcC2kx8dbvz8Pf3fB8YzpUVTTrqlbaqaLpyHNpl+mW1krw6jfqa4+sxYdvXWonUSlJ8t64qutI5JdYKu6k5n6YEaIEBQZ4UsrTpJSnK/47TUoZ1gPnPgBnuz6/svKd4zQAfwzgOSHELgBvAfCEqqMVKeWtUsrzpJTnnXXWWTrb1RSqJXgxlpF4lUvX34OjpWRXplhn4uvyZsgi7FCdYGz17qN4w+WztEuuTDOrWQ2T4He0JiYlrpm1BceG1dsbt0OMKe3lW9d4KUIbvFhrromzz4PSIKr3BRkvaClI5ibHeX6rVEfLL0goGnV1zYSGL/CuJ7AD4DgvXyvLj7yEYK/9+gzc/FxjYBR22ect6PngzUsiv8QiIn9xqmiGWQHgdUKI1wghTgDwEQBPOD9KKfuklGdKKadJKacBWArgEinlygTTlCvOjT/WMAnOv5U/ntvSg/GAUo041QnbNQbu81t8zp4pVbV0WSrC83HH8zsxMFLC89sPa82i3wYvgfZ/UYZJ8Hyes6kbN8zbjm//ZqNyW+O2l3IyZSYleN39I7hx3najNlBB4ux6nWs+7qGNe2akdc2a1iTII79NiDrQecMYeWH7KKGdpAospe8HM6pZhe+H6BZuC671o1210bQ5ROUeFyc2X7T9MP7j3lXK4z8pge8/XQuMsnoHkLdne7FfhRDp0x0Hz5iUsiSE+DyAWQDaAfxcSrlBCPEdACullE8EL6H43B1jRKW68Y+MT1RLOLy/m7fBq03frvEE8e2hMOfZNCfdO3rKPcOZvDF371O/zMJLTpoCAOg7nkwJnsPKwzbGSwCH06PhaGlCeY7GLcFzFjlu0LPgf/5qNZbvOoKvvvf1PguNlSQjem0X3dObnZM2pLU79Nul5vseYqpxoHNFdUjDo2D7DEkr+HZWM29LD/qOj+MlJ01p2Jawa2CsNIk2AXS017+3/vgdyyOnK04pYq0EL/oyPvnz5ShNSpQmJaa02wlEi3UVNZI+fxO1miRL8CClnCmlPEdK+ftSyisr312qCu6klG9vpdI7oPx2VAj7g1rXZwz9fzPVplGCp2vt3mPVv03fVtukykAd7LffoasT4B0b1huDzbQNXlDPdEEuf2IDLvzeXOUybfBuhpM/i1uC58w9alCCNzRWrmJsqzv9WPFWQBJUL36i7K7YJYBpleBV/vXbnc30Rj5sl83bfAiPv7hfPW9d27b67/JaRdP2y0kAmP7IWgCN11fYus755lO45IZFGuvVSl552hjhggw7sWPI08sOk5Tk9TwmKqJEAzwKN6W9rdqzYBShVf28n426SZd1D8M2nRI8vy7oPV+7H8RSoi6haT66nHQl3dTJCfDcg2xLKXH7wk70HW8M+owz9AHHZtOBfmztHlD+dtfiXTjQVx/QmnTv7SRzaKyEadNn4OfP72yY170pTilw3CDLOY+DqiN7VYNL3yqa6dEJxN3TZJGhM3pZYCHfZnova0afumsFrpu7DUBjZjfoxVyeuM9FG23Uysus/d0zMKqcXuel18YD/aHTeCXWW2eEqu5+9h87jmc314aWSaPn7f9+eC2mTXc6OLe3LUnL87VDlCYGeBk7ob3NKJPqpbqZBd3g4tz7dNrgRVlvw29NdoPWyXicOrVcG3pgpNZRzZIdvfjujE345mPrG6Y3HQfP7zMAXHTdQvzNTxZoLQ+IlmkbGS+fw3cv2aVaYJVzDsXtRbMamBvFIOV1+/Vam2bGICiAV5XgRUla3qtFO5La782y/Q71oOJ60yUliWESwjjVt71VG/1ezJjy7r+gTYxavXJiUqKzZyh0+bouvm4hPn1XrYJT8PM0rFqt1ErXAytNetzNpyyCva8/ug6HEqgFRGSKAV7GprSLWAFeWB6msfqj/qJ7BkYx6mrjpNXJSnPlqapsDZPgxym5cgeDzr4dGGkswTNNj803q07wobNMbzpVpbzuDIfTNtRWZs1EdViSHJykQZl0J1PpniZKmoM67TCdP0m6gVgODpvSgyv3VK9lWyUrzj5RLU/VftU5vrZLo8KHSYizcPVy8jCMSXWddaXo+vP9+Jkt1Rd3NnoDHRqbqPuc9vitwcvJ6YWZkfuW78alj2/IOhlEyXWyQnqmxC3BUz1iAx7AJjfjt35/Hs4+46TqZ50CPL+lB61Xp7OBpJiWgIYuw+BZHrSd+m3w6qe7a/Eu/QT4LdOkGq/3bXjD7/WfnXPIVicrJmrtFH2WadyhRTIl2soSvJiXRJT5g+a5+LqFOG1qBz503tn+E1lYTzP42sNrrS+zVnW8sWrc+MRk9UVJ1qK9OAiex2my4A1Wbb2YSeN0W76zNmZsElVAA2vpNEFd5yST0Gwl90RJycdTooVNaW+rKyUzpaqqFvTW0fTWt+fI8erfOm3womgMQgOmTao6V4wFmwVEjX+r9qppZsY5NKr2fKacNUdpEO/M4p7TvSlOD3cTcdvgRXmIO6WolkbEjpOR0BomIfLSG+e3VcVz/tZyL4cbD/RjmSsTG7qsoBc81WnM05Om7z21Ce81qOqsY+a6A9W/dS/5KGM/RrWjZwjvu3YBSq6XkO4xy+LVfFDP7FTf9t59/C7bY8NjyloQ+vzvc+6XOCab6t4vSTw281ALIYr02/A1534isoEleBk7oSPZTlYapo9RvUarDV6EDiyy7NY5y0xjUA95us/vRJ7zBsv0Thq2LR2VcyjLErxcVAELWFe1pDFmCV4SVTQ/+fPluPC1LzNerpQBGd3KMvyuRb8XDSbb9Ktlu3H34l2Y9f+/TXser1vmd4ZOY7qf/+PeF0KW1/hd0NiPSWSgNx8cwDHXi6MZrqDUFvd+8+uAye+6/ZPvPFO9r+itq/5z0h07JjVge8N6NDckzm0udFxEIsoNluBlbEq7MBrLy0tWM0c1C7Ydxsb9/ZXvs6v+WLfeoFK5GGla1XUU06bPaOgJUpeqF03joDnC+twzxS3BO9Q/gnV7+wxSESzO8QjLZ9U6WYlbgmeu1gbPzjLDMm7bDw3isscbO9ABgM7DQ/jzK57B/mPHMXvDQdyzZJcrnZU2eK4UxX1jb6nQEgDQeXjQeB6t1SdYtewbv16HLT49ySbJ5FrSbouomC6rTHYSvTlWO1nx9jIa8JiM+8JIR9RttRlAOs97536gWnaTFu4RkWUM8DJWLsGL0wav0RfuW42Lr19Y/t0zQZzOC3UeHDaeLQ2lQgHT3rusC0A5M52V+oHO1ZQP4sBl6q//PT9ZgLmbD+nPEMJddXR8YhL/8+t16PbpFUyvk5Wads0SvDdfOQf/HdC2KUqJlJOyuMGlrk/ftQJ3L+lS/nbvst3oHRrDb9bsx2fvWYVvKRrl2+xFM+vqjUEBquKdh5awUyCtkpOogtqr5i2T7pceW+eVeykln+ehtV40LV8LQ6MlXPHkRoyM1zpCca/B5thvzi4I6ggrtBfNnJ1bSWqlbSXyYoCXsSntbYFVbsLU2uBFf/ubiqASPBn8OUm67X+U8zqlpzqBr2KaWs93jY9pkxIbG+3u3Nyrfm5LD+5dtls5lIPWsiDrzs1qL5ohbxp6BkYDu+mOVoLX2Dtl3TItn3hjASXzOuuqK1WOmTbbnayYCgzwNO9h3l/zmHdrfDnln7kP2p5aL5qqG0ekpGmJGmR7b2GDoyVIKTE0WkJnj/rlW2gJnuf7rNud+Z2fP312O+54fifuX75b+bvdHo7rz4tJCUybPiPxbvmzaBcfVd7SY+rC783Ft3/DXjgpPgZ4GbPVi6buPS2JRvE6y8+6BMGPuhtws7TqTK2axvkuTjWbJB5myrT6tq2s/94pwfMb6Hzn4fLYUNm2wbO3zCBB17XeSwF3Fc0ICYi5PTavWZ0q2s2eMVMxqqKpvBdV/vC5nrxslhbVpcNnrapv9x87jj++bBbueH4nPnXnCrzzR/ND53VvesmneMpagOdZTNw9dmx4DABwQke78nebh8TZNd77wYb9tQHek+ysyNamFPFat+VA3wjuXLQr62RQATDAy1h5oHO9u93q3Ucb39SF3cwt3kj1qmiar7Cxp0/p+ZycWvUwV3U2w+DKnTHz7xBC77vab9k9AeOsu81zR/FbVPyeLM3nT3scvKCS+eA2NIqAJ0oJXN0yI8xvME9YdUidEoCw1TWW9Bcrl6g6Xmm8uKtfjuHLLcX0+46Ve15+ev1BLN+l29NqbTlOFc2wIVdsiRuADYyWAACnTq31WVf3TIi3+DqTASdG2DAwDr9S1yIq1h2idX3x/tWYNn1G1sloOgzwMmYy0Pk/3LQY7722vpvuaoCiWXKWVTWX8LeK+tO6mbazWbC1JzQByZSK1VetGXUdc3UnK2bLtUlVsui7Txrehuv1CBpzlISIJXjOYPPx1q0rdgmexTZ0WZegB60/7B6Wt3zoOf/zlG+VuIYeGg1Sr9vmMujcueyJbKp2udMU1lttbR71SzW/TlayHgfPb77BkXKAd5o7wHP9nkwbPO9L0Cyv73yFUQV770MAHn9xf9ZJaEoM8DI2pb0tsK2O19Hh+vZWpjezpG9+kUoKQh4QNjN487bUd0by3w+vbdj/+oOMV/7Vqm5X/3msNFmt2qN6/qcdiF983cLq36rMmi5vL5rlbUsuCDXilOD5RHimu3z5riOBJZFBJfOm1Z2jBKVxq3jaPGo66zfNpIaWVCimsPEWeGxiEgu3HY69nMZrvDG96iZ4yd0bfJfs+wKxUa0XWP153N/5Vd9O6sVMcDvJ8JUOVkrwpvpV0YyWLKVqG7yAaUzbshJRMTHAy1jsTlZclQyVv3urNUVeU7zgMGjW2xfuxK9X79OaNi7vNmw7NIgFW3s8HRyYiTpode9QJcBTZAG0S/As7ayNB/pdn/QX2jClt2vzhA5mvDZ4dhK18/AQ7l6yy/f3oN46g9uk1f9bnl7zpYNPqUiUnkP91hll8OeDfcexv1J1r3E99f/6pidHWVNvVeQovMPj1JXgVTPyldKssCqwrn0zWpoImDKYf00Q/elVw5Eo2xf6LGeyWoJXP338at2N67Ixn1OC58fqMAmVfxtK8DRLf+Outxn4nVdErYYBXsba20SsB5dJ1cfy9Mne8fwzAv7r/fEzW70Ta6/P9OGpytw3ZCSM26HoT1RfdSdo8uSO0+aD/Zg2fQaWdvb6rLv8r071ssYqaY1/JVnl1UT4OHjmy4w6PIdWUsoC1wAAIABJREFUiVaETJtvBj3CQbB52N794wX4i6uf9VlPtDVlmXlTDQdiyvtiL+4xdtjuVTd4nYr7qdH8zlJqE/iX4Enf4Vrcjo9NBE7nvb8HHUqde2Cp0iOwfztuexGek3ad55gf28+WoMX9z6/XYZnrOdMK7f6I8oIBXsY62kSs8X2qb/s1M3Zx3m7F6UUzDpuL9N9P7r/NSkt0xsFTrUfV46TDKd0LTYPWVPUWby8/cJ9ef1B7mbrr8VbRlAbzmojTBs9mBifqu5nqEBkBbRYlZPXc0E2y+1yUdd9HSaP5PJFUS/BCqpY11EbILsJr957oFSZpGg0aRsP5V7G4sDX0uwK8xdsPN1RLD2JcTVZZgtd40qruZ/X3XMVyPJ9/tWw3LrhqLtbt7QtM00dvW4oLrprr+7vJFuq0g61tr3oZVkvwnFPGey2E7EvlslK4fO5dthsfvnVp8isiogYM8DLW3iYwEaPHiVpVHrPpo60r8qyGD9XkaFWnNA58o02jyiPm4Q1nXRu8kPT4DZOQtEgBXkgvmlGWGbX0vZqBD+p8RLp6xjNsF+rM78h6DLEg0vNvM7BSghdYRbPyb4Tl9ruqDP7T7cvwqTtXRFiKHid97t2hGo7kL7+vKr1Vv4yoLsezjxfvKL+Y2uEzrp7jxT3HAn9vKMELnDpc2LWZRBu84NuO56WuT3XOoBcMRVG0nnaJTDDAy1h7m8B4gt36eZecdJCWxFt1mw9Iv9S5063fg2XjQv3yfeo31I0leKbbmkTVu6BjOG36DPzbPSt9f9cd0y/2wN0RzjMnU+73PiVKiqKWvgdtv2qQa+/Uh/pHlANI+wVy0QI8vxKLCIvSWVtIEm3ey+KyEeCZlEjWV/9rnC6sBsKSHerq2IoVha7fb72OtmonK7UfwzoS07kfRGlHql6Z/qR1JewG56f7b5svvWqdrHiCtojL6+odipmi5noxQ9RKGOBlrL1NxHpwBXVQcNnj6+uq6wDZ3YxNMmMmHcOo23sElYqEJ2RSSgyPlfB/f/WCb3fo9enTKRVsfDBfOXMTgHImojQxiVsX7EitC39AIxj1+X3Whu7GaavLVA10bn+jYpXgWdzJUa/d2ljOAT34BVS7Ov+qucoBpOvb7bleWkR4WW+yj+PkYVXXho1lmw6hYsKnhqbRDbYhk66KEBRFeaGBsOL3j97WWE1u/7HjDYGf36JN2q3WrrOgVIZvh3cXOx1BxY2XTF522Lh3pTHQudu+YyPa97g9R9QdH3lVq5QbbAtLz4iyxQAvYx1t+uPgmbp7SRduXdBZ912sEjydmQ3fAEdeT8Dqgp5tqkyHEI2Z6d+s2Y8Zaw/gmtlbAtJZ/69pOmsJAB5etRdXzdzsO8nBPp9xt8JX7Z8mg5Is3WPS0AZP2i1pWdrZizdcNqvhxYWJkk/OM0qGJGrVx6C53Hl6J2COW8UyyvxpZc90r6M8ZRgTKcFTBOdJbvG7fjRfGfip+O17W4dE3ZYv7jL10hw2Tl3cNm1W2+A5VTQ9Dzkpa+11v3Dfatw4b7tvuvxeAqUp0aE+Amo+ELUSBngZa29rQylWG7zKvz63shM76g9xfScMZuvVmToPN1Sd6m9BJqU0K3HUSlPw70NjwV2bv+V7/p0G2FItSXF3GhPaBq9e0m3wrpuzDQOjJazbF9zRgoqTkfN7nxLl3I1agqcTrNRnxPTUXd9S/b2utOIp6flXe74MbzZ+nayY8CZfdW+K0hZPd9rj4433HN+XPgbfh/Q5Upu37m/V1PH2cVBvnLp0hgQRiiqpfsuISzfli3bEH6dRl8m5kaN3NESFxwAvYx3twrdEQUetvY7691NPnFI/fVY3WMsBk0NZRTNo2RqlVlLWPusMgmsyDp66LV70rEyc4+mNxbzBivtn3dV4lzk0WkJnT/x2Hl5xTmObHY5ELsHTKvWV5p2sGGbQ80C7BC/5pGjzrd4cY5lBVXL9plOtN4lj7X/fbPwhSm+1SaRZ9fJFSrPXmibV7z1f1v62WkVT/cwJfOY1fFa/BCKiYmGAl7E2IXzfNOoIu0GfcmJ7/fQxsiBamVK/ajEx1mPe8UjAb4rvvEGcex/pFEjpPMuDejsNqyJkS1iGyzkP67dHNHwXtEzvvlzS2YufzPGMc2jBk2v3G8/jpMyv1C1KZid6G7yAUmZXwBNnmATd9fmnI3rp5J4jw/rTRyzDy+MwCSa0SnGVHe4Ezxerp2S/zlRMOllp8//Nb94kAg2/52rQ/tl8sN/3N93tmZiU1faCgO1eNM3SkqyQ89B4DvsYwFIrY4CXsY42Ea9dnOdfr1NP7FDPEGtt4ZZ29mLa9BlxVqZcq9Yb1YBp/LvIl65pzB4McYJXoJwBiHxYDGYMi0WqAZ57oYa5EycgsZWp2bC/D3/yndl4dnN3XdrW7/PPiIWlzVpvfPCv7gkEdMSB2nmoO9i9djsgn/mjbLPWHIqJHnlhH/7qB/OwtFOz50ZnUWErNNyEJAPAsKrIUdrlqqrkRnk22CpFdDM5fZyXPCbDkahffPksX/OFWMnn4mxsg1f+98m1+/G+axdi5roDtd807mS1Kppl187ZinFXswu/9P7fe1/A4y/uC12+m9P2rqEET/qn1W+YBHeadSl7Sc5V2ToRORjgZSzum+CwN/Ntbd7Sqej0SvDK/965aKfxvNVpDdKk2y1/4G+iMWPsPLSCM+AaK2ycq3H1KY19F5bJd8ZjjHOs4rTB+9L9q3FVpWdRx/uvfx7Hhsfx6bv8h2bQ5aTMv0q0+dURdP0FXdumAYBuJkq6Ns09R5pt8FbvPgoA2HYoeLwy73p8O6nwzbgaJ80ak+FQ/DR0flFXdc6TKfeZr6t3CNOmz8ALXUcjpUFXWIcl7t2h3wbPf3uDPLBit1YJsaoEz1393uGcX1sODgAAtnWrz1vVNdjdP4LtnvPcOw6f311gxroD+OL9L/r8qhalTWbw8uIsKewlh/+yWbJGlDwGeBnriBng1TJH6jumt7etPA94bIuziapMgN4wCe4HUPjx0dmjQauNcwaYvD0NC/DGK4FPNdMWIWG686hS8tiL+xt6fbWp2iOlXycrES6NoH0aFOzqnjO10hC99Pi1r4lSaBn1zbwzl3HV6tAqX/5BT9raQ050Wy9tVNvo/m7BtnJnGpsrwUkS6wv6XvV7WLtRVbVjk2O5aHsvPnJreO+fftem6hm4du+x6vcmj+T3Xrug+netk6r6aSzU5q2qjoPXsA0BwVTA53jXUG3u7z21CQ+s2B0+R8r5j6xKF5/ecLD6oosoKwzwMuYtYTMVdsP0PuNsVAeNMk1SwyQErevDtyxp+M03o+vObLjWb9oGLyxNKmm1wQsblHuiWkWzke+cDZmZZLclzqnhXGppdbKi2he1zG3Q223nOOiVcBwZGqv7+wVFxkJ3m4dGS/jCfavROziqNb1j4/5alVnTFwTujHH/yDh6BszWnUeRqlYqAp6w0k3VD8mMO+lTghdQI8H7S//IeGVZygUZ6R0KP0eUJXiK9S/afhiX3LAIdy/uAmBWOntsuHG4Fu+1FnR/P83bhMLDO2utk5XwaW0Jex5LCdwyvxP//ci6+u+TSU7TuGdpV9ZJoBbHAC9jUUrwBkZqD5WwN/MmvW2FMami2VD9KIG7/ZGhMew6rCqlq/w+PNb4m8Zy+0fGsW5veDf88zYfwjMbu+v2sfdhvnr3UUybPiN0QNnoHVroT1sN4HxmcsZjrAtww9bv2aPO9GkFrWZC2gZFWGJwgOc/n8m1BASn7Yv3r67+/bHbl+F/37QYI+MTdcfGKbUMOywPrdyDJ9bsx/Vzt2ntEOelgbtTCce+o5qDKLv+/avvz8Obr5yjnq7hnpJdFtLGi6ygZQZXM3cF/mELMk2DQbu5oO9V6bhuzjbfn5MISv3a4Hmv2d2Vmh6DoyUA0e9d3qDcEbS0l5w8JeBXxTnv870JqXtjCV2XeTvU0JJgKRuqvJrKUyWlkfEJ3/OQKGnBr48ocVHa4H37Nxurf9eqbKinbaie4TNhV6/9ruyT9o5rnkOfYsBr1RbevXgX/uDlpwZk7mvfu9t7BR2df7/3BQDAZX93ru80D6zYAwBYuK2nvB7Vm9eAdVjlWbe3rYi3BC/K+E1JB3Zxnt1hbYOiZAyGA8YvDCqd1ylRm7OpG2MT9dVmVXoHay8yDvSNACiXXtRX0dTbOKfUo61NaO3rHz/j30PqTc/t0Fqn+6WQ6nrOo7Dd6b0MfjZ/BzYrguD6ZfqXxtUHQyFpC/k9OA1my1QWxlW+9J5zOj3HOjbs74udUVe3wWv8znuZRq6F4LPdQbfRE9rN3rFXBzo32Dl+QaL2/CHz2AqopJS4d9lufPOx9Xjgs2/BBa99mYWFxl9EHH/4rafxF7//MvzqM2/JNiHUkhjgZSxKCd7BSiYOCL/RB/Wg5XbJDYtC12vUrXfD9/p0Hxh+mUFVOi97YgMA4OI3/E7Db0G9WDrP+qHREm56bjs+dsGrFeurX5YyTT7fB86kIWi5czZ2419/sdI1bf3Uq3fXB3hOz2/Pb2scJFf3zb726ZzBg9dJmsVONBv2oZuyiiY0MkyVf7v7a9XQTEurvGuu9toZsm5nunah17uvujplOgc3y7xb+FAF9Z+vfmqzxjIVy4+wkUmUYIyV/HqkDAjaQpbp7bnY7f3XPx8yb8jCod8Gz/tSKu4Yh97pgsdSNeM3TELUY246zp/JS78opbJrKi8dd/UORQ7w8tKrp7OvFu8w602YyBYGeBmLUoLnVCUBXG+/fW5q3k5W/Dph0HlzntZtM+4N2tlk1cNIWYImBGRIrv8nz2zF7c/vxI3zGksl3BmGKKVDJg/N7z+9uXHoCx/Xzq0vXQnLBDgZoifW1MaYMy2RE6LcYcHWbjudPtgU1v4t6nn35QdfxJNrDmDrlRfVfa+6tIUQgJTGQWbca2/lLr0G/05tovY2EXl/mGY2ay+FzIKmogmq0uY3ZIbtffJXP5in/P4LrmrAbsoSPOdfg7QlU0VT76WU9zKN2ixeNWYhYLdtnN9A5zrpqn42PH9sHpngqse1v6PUHmlFw2MltLcJnNjRHj4xtRwGeBlrbzNvBjnkCvDCbvTejKS7VEBHm9AfXNU9TabtZQJWZdrBhvOgOT7uXxXPhH9Jod4D7WZPtbc5m7p9p/VmcMK2fDxCW4HGEjyhVRqc5PN7clJCCMWb+Qjjc+l49IXyWFbLOntxaGAUf/em3wMQ8vJGVR1PStw4b3u1mmWctAnP0B/feXKj77Ru1Z4EbXb9F7rOyh+mgWHI9IlmEn3W7aQpWqZeKv/UXnn1V/v32s4edRX+6vaifN1dMWMjzp92BoBa2zYd5i8FwqmGQ5FQlOAL78faFyZDOdSqpgYuXvs3QNHJil8PwCHLiUPKkMDMZ+15eCGTZRLSaIZ+7qWzcPYZJ2Hh196Z/Mqo6bCTlYxFqaJZH+CV//W7mbozsxOTEl9/dJ16Qh/R21TVJ0i3wwUbJCR29w4rgzLTzgKczQ8qcanrZCUgTeX1NC6oXKgT7VE0Z6N/gGfSBkb1e5RDn3QvmmFP7L/96UK89hsz8W/3rPJfREJP/Q/fuhT/eZ+7pMOsatbeo8dxzWx1m7YoPX96S++B8OvZKcXVraJpQ63X0JDpXH8f6Dte19lUlPUBwP5jx/GVh9b4VkHUSYt6HVHS1bj8sH2jbLeXaq62trKuI8O4c9Guatvk0Dl149mIVG3wyuut/957z4p7CzMpwTPd7qASPN9nT8Ok6tLgNEXpgCXOsossrAM3al0swctY3CqaoZ2suL4PGwdNpU0ATphkNtRB/edP3bXCaN65m7oxMj6J97/xd7Xnc8///92xTPmb6S4IG9PJWZ9OmsLWEUXQW3Lv8Q5Lp1+GKEjDHAm3wQs7B9fvK3dkMVsR+DqF5X6bmUbGoNYOsHFlJp1QhJFS73hOTkoMjJSqvflVAzzNTlbc5m/twZIdvcZpdUolwsZNu2/5brzn3N8GAFz4vWdx+tRojy8pa8v8xq/X4bktPbj4Db+Dd/7hbxstQ2VSSty1aCdGIpT4qxapzAiH7N8087cmxzqwRDWBi0/1vAsrjQLqX4LUl+YF8yvBi8OvrZ3N4Y9C02C3kqbFZRFREAZ4GYsS4I263jaHj4PnelsX4eZafrvpFBOGT++XnqDeBhuWAeBf7i53DvL+N75fez7HpoP9dUFwWPrCOp4ozxfwm3dhAfOrFmM6XphbUEayIRMQspXeEp+JSWkcfCZegheDk1lLq7qwaldUS4Srwxbo7S/Ta1dCncH1ru37T2/GLQs6seayv8FLTppSF+A9tHKPctl+Kf7kz5cDAP7xvFcapbX6kipkumc3H8LgaKnaBrV/RH2NO3yrjrn/rnwIq87p7ercb9lPrj2Ah1ftDVyWn8C2UT6lXeqgML1MdJw11VV/TGDFvm3wPDN7H8EiYFod3jlsVhUOqgmivQzDktPQFwqWTjcp7VcuzrI0L79PQmoVrKKZsSgBnjtoq1bR9JlWlZkxETXDHuvBHxRMaSz4n25bFq03S5/pH1yxB+N+jR8002SD8o10wPTeNiimJXjuoFxKdY+JDdWRgleRrZCBztPsfc34PJRAd/9IXfXs4OmlVpvKGesOAAD6KgM2O+PatbcJPLn2gGEqozFp42tjkPrbFnY2fhly4t65aFfdZ79kHFS0n4zCrzdivXnTE60qqrpkzTb1/bKxgyPvSxbvI1n3vuBMlWSA7aRd+fIuwrM6ybRGKX2uyvWDhKg5MMDLWJT4yX1zV7WzqZ/W9ZY0UoBX+7s+WAx/O55H/h1sqL//xZIufO2RtdWONJTzamx10INU9w2vaRVKb0wadvydc2nqlPJt4VUvO7nu/Pzbny4MXafJ+4rdvcN437ULsMRSN9JhmZWwYRLSqaLpX4oY9mLjgqvm4gM3anRgg4ASPM/xcV4wOdeFuwRPNaRIEnTb4JWnjb8+95AFzuLCTtveobG6z37J6K+0CzxpinmvdkHnhF/vx1kzCRC85159iaX9jZKQWtdZQy+arptY3bShJVnlCWy8hPBTW3bwOoJ+Ndik8jTuiRLutyhP5zZRs2OAl7EoJWTujFvt7bdf4ALXtPGqm7hnH/XplGBr9wD6hsfjVSGxECZ6M2TVZftl7mOsSycTELR83VNAdfyCdrN3+rD96gSQf/S7pwMod7ThnlfVA6t3ibrns4TEnE3d2HxwAM8EdBRjYtynSpbDeVOvc26OlSYjtaOqW1/Ab8Zt6ip7evuhQb3ppd4LAed4TXgDPCFw0pTobdxM1NoRa8xoOQPorNO0Mym/tDrDzZx+kvm+U91rVddsaLCXYibZ1qqSSLJq35QmJLYdCh7CxX0u+J2SC7f1YMP+Pu31RtUYFDtBpP46/drx6Yo8XEqMoxonjqx/HPun4YXdRzFt+gzsMejtlaiZsA1exuK+EAttg+d6EkTpRMMvKPTL/C7tPIJ/uGkRXv2yk43X5Ui2wXijJJuNVTNqnn+jrF91/ILmNe1kZUKReXBKnBZtV5ey2ThWRmM6BUw6FlIlsdZhTvh63nvtAuw8PIRdV5u3AdVJhOnLFuP9LP3a4NW3OHUKK6QnwGsLGAcvLBgyTWpYNfP6afPxit8vFU6Ad9rUKcZD0sStml6dNs2qxjFWJSXwzcfW4WDfKP7i980GtdaqNYHG9F3x5Ebcv6K+bWnjcCrh6/z4HcuV6wMUwyQE9i1Tntj9kmv+1h6ceeoJeHbToYb0m1RntkXKiFWFFTMFlizKdM/dByvnwfPbD+Oj57/K+vJz3BydWgQDvIzFvQmEZY7cD5sveQar1ctQuaevfRgZ989Mdx4eihXgJUndyUryXcIHP7j0ToKJkBKqhuk9OY2wzLGzfHeVOeMHboajJIR1dS9Cgiv31zsPq8f9iqsaZBrO506z7vAAOi90nCqaTmzsrKejLfo1EbUEz71T/s/Ni3H3p8/HKSfWP6JsX6a1TlaCNdynfRLidOwRZfgbVacjqhdDYZ1k5CQGbqDaI79cuhsAcKFpgKexjZOKTjuW7zzSmC5Pwtrqai6YpylK7ZUHVuyu/u10VqTivLBtrJ0RkC54pw0pAdamnnl37zD2HhvGm175UsM50+VUxY3y4puoGbCKZsZMqwY1DHyqyBwpfwcwb0uP0bqA+ofV+MQkPvSzxVi+80ho9bW83jKTyPwEtq/zqWIThemDaMKbCdAswXNnVMKTWz9BkoNLSymxquuo7++hAV7lX7/dODxWwg9nbcZoyc6g9jpv7uu+C1iW+7c3XD47dN0SEhMBHQM5qlU0Kzul5C7Bi3iu6payjZYmUJqYVFZHXNl1FMt2NpYa226r5azT9EVbaI+0UdJZF8T5zx/Wdi3V0p26YMGwVNr9dyI3ZsVyVT3bej+7251L9/ZprtagBK9WbVxv2bVOVmztL72S0MDfPRO87Yfz8E+3LTN++SAhrTw/dI+Z8xImrB8DombFAC9jprcz7/RhN/q4D073va+rdxgrdh3F9EfWNgQPzcJ/f9nZHt+lB8ThuplLv3GdTKbXWb6zj55efxCfCHibrJJktZShkKE2wkvw6jsU8bp5/g7cOG8H7l26W/m7qaDMim7JkXd6XVL6dBPvU1pRHUDZ1QYvar5H90XE67/5NP7hpsWhY3m62c6L1Y5D8JFoKMALSUfM+E7xm1T+beLdP56v1bOqkRjHw/1sijJGaxjdNrTee5YA8PiL+yOsUV26pj+nznTqB4mU+kPa+JUG+0/vN5H+zX7mugM4PBheZTnNKprOvS+pErwkX3Y2u8lJdQdIZBcDvIyZdrLinT6oMT4QP0Pk1wtn2MUZr21G9LfCYRZb6rHRlLMVyjZ4msswDaq9byZDS/Am6zPaOg++NEtEwzJOYxPBGbqwNnhOhjCsLV8czuVrutuilI4o22x6PteqaMq6f9vboufddUoOHev29fkGeKoMUlIZwLDbcFAPkCpRUqnKeEe5//nNsf3QII4oOp+K1yFWjWltFLcjw+pOseL493tf0DoO3meqXxVN3aA+/Kpzz2N4XVdL8MzniUrqfVCst/b7f9z7Aj5154qQ6Wt/xzmXdDe3PaQEb2JS4sfPbK22q7Vt04F+a7VFms1rvzET0x9Zl3UyCo8BXsZM72O+VTR9BGWIVOOaNczvznRUE5FeNaC06sfH7Syg9rd6QUEZNu0SPNM2eJ51hbbB82nfoeL3UDQ5nf3WsumAupc7GRI3BLULBVBNXJZvDp2gxbiTFcP1SCm1OuVxmopVh0mo/Lu1exC/WROlFMN/gGk/tXbEPudUXZ25SEnyFVaS+vCqvVi+80hDsBmWjGilOIoSeudfg1KXoPNbNe6qrXuf8byuv4+HlM4HzRs4ncaEDXukfqRzY5GOveY81ZchYQkL+DmsDWfQ9I4P37IEhwfH9NJSsffocPh2xry+b1vQic6eWvvpoMU5VTT9XpzO3nAQ18/dhu8+uTFSWoKe64cGRnDRdQvxP79eH2nZRfDAyj3hE1Es7GQlY6YleN5e8MJ61bJZGOG+OYfFXXHu0+5tCat2Z0PcaoV62ypd/1f8qrEQ78DlYRp60QxdvrokRWX1nqP4g5efhh89s9UoTSre/X/x9erx9sJKMMN70Qx+oKfadslwXcbTQ68krc0zDp4TuN/x/E6zFbroVLfbe7TWNXm1Ux+f2UzuO246VaSqmVOfSb/y0BoAwOff8Qe+aVIuN8K5ZOv8C1pMu+JmF+tebTB3UOl1ElU0y+sKX27jQOfqWjLh6ypfP+4AQ5fu1u85chxLO3uV14Hfcyxo2aptu2fJLrzqZacoF+Dsz2WKzmrC1mtyhKM+kq+cuUl72jZP7QUv53kykkAeZGCkBAB4IaBNOVFcDPCyZqkEzz9wsP/gLIeYyeWG3Uu23mZEY53G82rMXKtao6rAo9mLpqoNXkDKvePC6Q6poXNsR0uT+N7MTdrjsgWRUi+DFxbg6veiGZ6exu/Mz5CgFwfqMQ391xFlWAVVSZr3XGuvtsErf7ZRYh4WiK/f14e//enz1c9JDZOg1ZW+5uIaqmj6TVddbrz9WCvxD16f+lz1X67qhWKsKpomAXfATkwqwIvCXcip6tk0yC0LOiOtU3c/fuPX5Wptd33qzZHmB8Kvi289vsFoeu31yvB9mOZZ4Nz78nTuEdnEKpoZMy7BM+yV0ea4Ue5FhRUO2Aos0yjBiysoE+DdDco3pku7tNYTN/MdNnupWkVTY2ESGFZUq9I9nd374a7Fu3DBVXND5wmr+qfdi2bIBib58qJaiiHrP4eJcjnpZFy8vWjayOwEHaf/+fU6fOYXK+u+8+1kpbJv3IGB7XHwnKXZ7hBh0vD4utNS/53qRUC0NPktLw5bSzM973SfL43tOsPV96JpkiZg3b5jIcuzFyzpT+t90Vf7+/ntPZi/Nbh3bSmD0+1f8h6cDt3lxBG0zrASPB3d/SPYd+x45PmJksQAL2Om2YoT2usPWVgVTZs3TSdzJYRIdMDhukAypZdrSbdDkZ5/vXQ6UImf+fbJSHvSoJMJsX1YdHpYC9r+0dKEMuB0CxsHz3H93G0N39k63aOW8JhmzMvDJChK8Lxt8Cq3k2obPBsBXsDbn3uX7caBvpG672qrtFfipi3i8sKbEgVfa+pl1ibee3QYf3/jIhwdGm9YTniPmmaZ8Ti7VLqeCWHn9K2e0i132vPUK7M72HenKjRAQfRu/k23vnEcvAiRLID7lu+pjrt3eHA0dBs/fdfKyG1zdfZlmv1O1movhAWe/r9fcNVc/OXVzyp/40DnlDVW0cyYaQne1Cnt6K/U3wbCb042A6S0HsHuh1WSgaTfOs3n1ZgmrK6VBne1tijCduVEpTqszi5XDSIMJNs1dFAJ5uu/+XTo/LUOToKnC+2sRVPQnjDLlpsHNtu6B7V6A60Ok+Cc50euAAAgAElEQVQZ6DwOw6aioW3w6pZtvQRPb3mmLddM9wFQX/J58/wdeHHPMby4p7FEKEzQLlKed7FKBIOXHWTMtb2mY5HpTq2zbd4SmFilnCHj7Om0M9VhViUzXFfvEP76h8/hm+//o9D5v/GoZu+HqpcJgedmmoMkAB3trKJJxcYSvIyZvuWZOqW97nNYD3RJVNEUlpcbJI31xF6FawHeNoPejgX8tidqGmw+6J38ls4+96u2k+RbS5Pu91WqJXg+D/TAAMtgPY++sLeyvsadETQWX2Dmx/D8+Njty7D3aGPVIb9hEtIqwVMxefeRVF7MWgbb01OryfXwr56qq541Vv9auO1w4BhvwS8KFOddnGy1u2TRcDEl173SsOPV1NSXnIZPm1ahTUMJXsz95wS5z2zsbvgtvOTS73vp/UJbGqVf3urp/mlhUZxNHP8uPQzwMmZ67zjJE+ClebHUVQ0Kq6IUJ88QI9MQaX2Q1t5iz1x3UD1NSCY2jXeX4cMkVErwNJblux2amxFlf8dtg6hbRVPF5Dr78oNrNJan/NZ3+qRedFQzOU6AZ2E1pkFirQ1e/XyqW6P1ErzqS41yexrftHt7VvRdYP3vSby4+eGsLbj08fW+06Vbgud+JpgtyL2vTV/eSAls61YPp1I3XYT7qjspJvP7xvwJjPKhWo4Im8D5SfHbiR3lfIWq1N9mmoP2Z1hbv6jr9OO0dkmuBM88MGyF4KcFNjE3GOBlLG6VNt8OCips3ryqJXgi3vh7UdaZpLjr0GqDF9K+7QdPb0ls3brTThhU05M+VTSTbEtjOr6aV0elwVmSA5mHqXb0otiUoEs1aL/+P/a+O+6Oour/7L336SXlSe+994SQkITQQwi9iCIgiiLN8gPlxZcmIIjCq76ioti7rwVFjWCh9yK9JEhCIIQkJCGN1Kfs7497Z3d2dsqZ2dlyk/3y0Tx3d8rZ2ZnZc+a0KAfMbLJfXVM5HnQFcVUkYBq2GKAtO/eW83KR37v2woE33gNfWsrPecUOsYqMqIIou7rY5lZt2gkiqJhom9DRcMnqmnynjvz6g1p9YEG/u4f/sxE27wz7QYqg0vaw83fVpp3w95fXadMpC5wSLqtur65U3hv3cMzTbR1S6KzdRDV4CLpkGnObiOvz+fzqLYk9gwpJWX/lyAW81MHJOyvFcubUcvOOdujsEn/S7Zpo+m2ZhJpH90P9nYiJJugzJ8H6CIGo8m+a5v5qAQ/vg/fa+u2w9IW1oetYAcFxop34m6CpruxyzKaPwMDaa6usdxJUBuOfAyAfV51hDOf8Kv9rM4qmvgav/O+/V/FzQjlMWYzmRoVDb7kf5n/lPm8OkgA9dz7HDyARjvAv0vT5dPLqYaF6p4QhZwPWKNu1HUXT5f+NAc1Yx3XmwpKEMbejn+Oul9ahAkCV67nc41rVIe4nf/5v/SBKlrSuBLUl8eGXijZrkUHB4j6LAHu49ZW7l8EX//xyqNxzqzfDuKvuhvuWv6vVflYsO9/dthtO+PYj8F9/eCFtUgAg2Xe8vyMX8FJGVPvu6/76CtwoSe5pNcgKYVqYZOu2ERQks78doEjMwGOoPtTbdnfAb558CyWk/eSRVdzrcb4vXd8uFrqHKVFhM1JmXGZEsaRJMAx5v31Ph6JkeX5hNDcqeFoZhoZtu9pR9b917+vS+zqBY/j1md/M/VJlMv/k0VWhum+9J9buYfrSqhv420xzy/5tEybCRxRaVJ9zUcu6XbJLzAUJLxHSpIWLEGGHm2rGdA7zfiPbshWs68HXNsAuQXRl8szkoOG2+1dw19Pq98r+iQ+9ttEKTTLEsQrIvvri21tjaF0fcbEIezo64XO/ex7Wb9M79NqXkQt4KcMG07n0hbWSVYPXqKgQ1KyhmjXCig1+8mzeh8w2XNeNdApZJfKdcmO9/cGVcPkdL8I7CK2AWGOMp0U/KIP+KP7l+XdgNZbhjWjmhIE0sqZMg2eJAFGQFSKURRWiAcw1eKiyAvLoPUMHZFj95+cTwzKcy9bJtYhxa+priuJPt9Tcm0NXWub09EGS6cFCRwyqPzEp8b3U9xGHGzTi8kXd0xGfGZ/ab98vYGtO/viRVXC9wOy6aCEPnm3sDz54cR3m/P3l9fD7f78N1/2V/773R+QCXsqwocYvOABX3Rk2LQAwC9ctgp8HD7NZm/cTDFSSjIlmpPoJCAY24Ad6iU6UaJPW2bx16TD5EH/q18/Ccd96uNKfOT0mY8arIdPYy55PphWLsocUmKieaQZZiVJ2kaFWj7QW1b+TBRkD2bspSU73wj54wd81JbNPN+8po+xRd73km2mj32OlGC2bmTJ91yuYOZNWTf2IXVcdVkPU9Hs79ur1FWoXv3fxS5av8jR46n1TcJ31E0wklFgY6wQHlmT9Ydd+0iaXW5HWBDmCyIhlbCaQC3gpw0YIXlkbcaRJsN2uDIkcrkXsA+WDlwFJzwUXPv3rZ+FWhXkZBqL3YjPoCwvTKJpbNIIk2IR+4ATxPdGj363hIwQAoa9fgWFybARZsaXBI/taIAqhoGzUCKtR63uoNKMKfkWX4d+Td1Mr0eDJYHsN3PHMGuO2aUHKVMD+ByesPw2T5xXt1b9+cjUMu3ypdrCKYBRNfttbd+ox83F9T7gCnoG1BQ/KQ2Hqb5v5VFvr+emedYKsJAWakqnX/gMeW7EpNVriQlzDnQUeK2vIBbyUEfdpA5Zv0aUjqSiasn5s+VRFphVRPQtbT5cL8Ofn34Htu/XMgXgQvRYsc29ympumKY0RoxjBJ4nF25v5Zqbn/+LfsH6bhoDH4C/Pl4OK2PXB0w15H12DZwyiuVTQrHsOhyFTZ6jZojLtn7ydcKeJrypOPsrYmGym2dffVZvyitbAA69tAACxts0F1/jAVvf5eT6agYBN0kiqnDlQubSHq8FTfOtFh33SWmXcdNcyVFtR0NpQw71OurJxqMUD/T5WIk3I2ed/bvUWbrntu9vhqVXvGVKWLuJWDuR5C33kAl7KsDEZC5K3aPNUI9BWQlzBnvYuoX9C0WLUDFuBBlh4ic4zIOHZPeHit4VlVIx88EQJygUN8UyEkoTu8z0qOa01TaPBQrRiyEfXxsc3DRNNU5DWVJFV0TsNk2vReHtXPKapiSYvkbWN8OmdXRq5RBktJ4A5k600iTRY8ypShLFMMAd9gjK681rLFF7jAJK3x+r4zqn6YIt+94EV3H5s8ugtAg1ekp+Dw/7nAavtXfjLZ+C07z5mtc2kkAFWaL9BLuClDBsySiEpE81Au/KytkwsvnDHi4HfW3b6p6e2Hi1qO5gPXFzChY7QZlW8E53a6nzstX3w+FqWHz78hoAWreatCuGiPIHsUqUPeL5y9zJICzIGTxe6Tego/GwftpN3fvPffQH6rhfXwmH/c39AUNVlOOl9d5OOCS2hK+SDF7xvaqJ5NcdXe9aX/mXUFgvdbw19GPT0m/wUGVFhMl9Uwqbs22Ysz0fcqx5YvgE9hryupH7kBu1x20zJ0qW+ksQ93FfcmiT9OliaXnlnm37jGUFcppSk2Vx/5yMX8FKGDUFILuAh6UDsRv6ptJOYNuSVtcGN7CkqV5YtClw32mb/PCL8cEIWSInRIGoq1iiagsbvfmkd93qI4TR4/t3tnTDs8qVw53Nr1IUpTLzm79znS/vjI1rnrls2+xGFFNeBLW0Ej1LbzAFv3V/2hxdg5YYd2pENadBTdaaBAKWaujVF85lEH5LZQk3R0V5eNl6l6rtlYnJ8gyTtkAwuaydJX8fU1QC7Zpa+GM5J6rWt13S4voI4rPbVTS3Mio+tO9u9PJqeQICUxNLeu/cVxO1pkVto+sgFvJRhYzLKmrCpwQtGPZOXTWKR2Xo2numIDp58Q20LnwWzhNjMdWPqg8VmQSAC0QGHDUpITp1b/vGaVr1y4uwsvPUgROuyy3Vh8hf/AWu27Irch665nc6Usc0c8IJ7kCGi57KuKT0ZA9PloKpWlNnlKzDtun9a8zs6bFwfAAAY1acltPbrFGakSfjUxrEfydLNqQ5shb7LEX3wotaNIngJA24ptNCcCrGAbvbE7zzi5dGMe/aZHN5j32tVCzHZ+yzus8gFvJRhZaFK2rBrlud63WUhAbk9E02/ocMrDIt1xDRcOtPH6lyI3Id+7sG3Nu3g35AILcEezWFjru3Y0yEUUlkcMKwHjO7THL1TJJIw3xUhTR88nlaYRBY1kT/IVLSfp4ydy+r2ZevLFn1+tFAX3t0eNEWVWZYAJCPgZSHF2c8ffxN+/vib0jLx+uCpbSWlJpqKroRzMUKbNkH39cbGHdzr1YfqlfBic1cBnz/NUUYu4KUM1UcwahtYJhpDReCjkgENnk2QRxvWqymWdrOAp1fZ83MRPRc2d4+JiaYoAbvIj9Xu2Os3tvH9oCncHc+8ja47eWB3+M6HZ2j3qYJwWVocrDiZVduCE0/IIPtpFO0PaRbLzCwY3SvwO6rmaeP7e+Ab//qP8L6tUSTPuWzddvjkz/8duMf7BtABXZ5/mx8h0CaSPIh0XVf43bvqTy+VywhGXv9QRH7/pTXJ+WhhaVdZysTN+EftL0s8TZZo0UVchy66Jrf7AwThhXIkhdhNNK0mOq/056SvwbNqbkj9XYrg28LipTVb4U8V3634Pl548IJ4zB/VCx5+faN+v4Lxf/YtHNPmgj6T2SmIdCgyhQn5MRnMGdK2jY8SLwS5bP0XLEaJVUHn+VR7lu5YvStI88Drx/a2097JeSeVf60wIsg22IjAUfs++4dPhvyXadgaR5mpJ+/gcdxVd0NLXZntwO4VUfC1f+qZVmMgmv6/eOIt2LhdHlDH1rirTDp3tXfCno5OqOMEGOGaaCq0bbLvl4gX4F392WNyTWaSucyyGJQDbaIZLxmxIu4gKzl85Bq8lBG3Bs+uD57flqpZm4lKebAb8dD/GNVE8G1hceytD3OZ+izBVIiIOvyuqxFWvYI4NUMA/Gfy01xEn3BfWooP3uA4AMUYTiLFQVbwz/f2Zrmf3i7NsPvbBcFMCEkvUxHjrJto8nzwiAaPmhFxHwprv2vFMMiEOwD7Jpo8JMGEqobt9//Ga82xED3x86u3WPFhxQDjQ/nlvy2DYZcvRe3V0rx5hnnw2LnR2eXCv14VJ6aniyehhcmiPIA9CE5DSbV5x15YePN98FolSI0pohxe5cnM9ZALeCnDiguepBGb6nDPBy8LGryYWrOpwQv0kNF9yfhpIz5PWYOnK7CJ2sKdICt9SSQF0nh9NvM8qpAFXyUWLgAsWxcUVHTp/M/67bD6PX6SeAB+UnZe7sonVuKSCofmHKpW+F2r5m70A5aIDVQgFfASmL5p7Kum376tu9rheUHial1g/Bd/8ugq7nVezWg+eGb1dNqKAiEdMU+eOOd/3AfoPNy3/F14c9NO+M59r0dqJ/b0FLG2Xl3ITTRTho2TKlkbNk886G9KmlE0y9ofiyaarj9ONYb5pVRIWyAWwVSGsMFg6g6J6J2L5uKbTFCWKDQn/fociMdEU9RiFmdnl+vC7vau0DUdkIh5IvASnJNhp5noB17bgOrP1CyYPVhi65mYUctgi8mSuQAItcVWek4PpnvB2T98ApVSBwPbic6l9Q1piWJBYXPnE8p3FvvAYPV7O+GaP78M3zpjurBMRtkEALDI00XS4Mmj2AJALuFRyDV4KcPGopHxgTYFCy8PHjigWqVxblSuG5/GoRST1iSu4Yg6zqYmwlEFbBf0x0Q4lwWXl3zzYe/vNVt2CROiY5CGaUgcJpoiZNH05XdPrw5Hj7RMJy8oEFkTJlEew/Ti6rHrMIq2GQNb+6fs+5KgAjpRmA6dLeEOIFoE0qgHa6xJtThljl4/gbrmVTmN2aFP9zCeLX3TXcvg3mXvwr3L3hXWwZJUzXFE4guyQvOnOQByAS912PDBkzVhc8PQ0eDFqYaXmfe11pdgyZT+Bu2VEZcGL4P8MwCYa5B3REyI7Rqo8MQnsep2Pvfb55Vlnkkg6AMWjgNg0R1UiSzOz7+9uC60z9gMGiUC2ZNNDsfsmWjG+0KS8METfdt4ZrGmSMrnjUYWDkN08ubhUmqY3xeeu1my0IiKtN4W2y99QB71UaNwjavf2xmLbyoWUfa29FdedSEX8FKGjbMGmZBoM9cQ2YBfXLMV/vuPL0rLxsmIyQJ01BQLUKcppNFt1cTkgxcVZ88dyr0elRFM8yRQX4MnaAfRUFSGNq4Pi2z4bRz+hPoTmrdk89PJMn1Jmjqb7J0sfVh6dbW1kc3uLA2jILAtAIjnGs8stpqQAflOL1G9odmwoHqYFqFhhbimar+xaqIp/G4k+yK9qJ2yA3kkTVFce06+7VH43O+e15tDFKKOWlzDnoFlmTnkAl7KsKLBk9yzuZhohmeLImFzmgyjrhbOBdfbHUoxafCiom9rfSztpmVGZeSAH2Eym64zr1oK0zlJE80sBlkBCNOVBJ1k2E36Cvvg4eqxGryN2/cKStrB1Gv/YaWdTslJnogJTSLBeZzIgoDHye4hBEarLBXGDM2FZa/5tfXvwzV3vhSmK8GxjbsrNiUEnYhb6UcWIzYoUnmIoDJ9/O3Tq1EadU+TafB5w/AA1Wy+ahvZ5Gb3I1iZjI4DrfX8eDnYE2RMsfUaG0OsPniS9l0AqC3pTevtu32fgrh88KIiDm1OnO1iYCtNwtNvqhO4P7Zyk15nDJLm6RzHiSkPnsBsTodjTBBx++DxYNNEEyvMsALeum27tfpJC7w0EwTZ3EmjIwvabp25iSkrLyKvL7askNf7qSQnXqIRWJm+fvvU6lj6W1/J9+k42TgksEnCzr0dcNnvX4Azvv+4ul/Lz75rbyfs2tvpPdC+uu+YIBfwUoatICs9mmq597CLCVPsQWQkOZ1+TeC68o+srgbvC3e86LUXV5qEqIjrg5eWgOdW/tOqk+JHMZUgKwkeNmTVbC4uDV5DTTgBNAEviiYWpialuu86CwwiAD9RPEGah0dxIgsKSD0BL/ibV1XWmqqrHwmCV+mOk+q7bgqdROwAAJf94QXu9aiz+TkvRYYs6jmuLRv+2XFEWNfRDpqMJ4/i8VffDdOv/0cmDl6yhlzASxk20iQUHLHTbhrh+RtqijEHWZEnydbV4AFQ9vEZPf8RhrePOMzY6TdlULdoHTEwSZOQxlz+diXnT+IaPIjHRFMkR9gMfGETH2JOhG3NgYNGtgnvRYuiGfzNi9LJg67lQFaYGdkYZdQYIjKyEGTl1nvxuchMfa0IZBYzAABPruLniIwyTja/w4+t3AR7O8L7W1rvsbwuJCZICNgYH9On5w2bDjW+iaa9d0yn09lHz5WMkAt4KYP9CJpMzoIj/uCjNXgWN7vujTWxnnK6rnhzcl0XagVauIsOHQmv37BY2nZW89WZzIumWrGWggB7ym5zMwaQv0MR0jg5//WTZXOd2KaFZFzjiKIpet9Z1eCxsLU+pa1wEp2btvvXF9ai6sVjjhs/qmXeDOzeYK2t6nhiHyG/UM4TyL7/pj6TurXiOrR49q0tcNNdy4T3HXBg0/tmfmkmcCQH8raxdWc7vLfDjj+vLRYgUvoMSd2Msm6pIk90njLYkxh1hjl+G1E1eDbXRlmjGO9qkz2XTIOnSr6b1QAAJid2GKEMu2nb5j9VWlhunRR38MQ1Jk48GjxRk7wT7izC1hSQzSUyRDqh6AlMBVBtDV5GtimZ5jcjJFpHFjR4OkD54EnuLf7fh2LrNym8tn574DcdiXtvZxfM/NK/1I1Y2o6lQfGQqwb7aZh6nTiYUlqvJ65ufZfK6jwsiwO5gJcyrDDOEqddm0FWVFg8qR9s2dkOb2zcEb8GT9K+yAfPddV7dJY+SjRMeH1MFawGz7Y/jYm/RZqydxrTIg4fJrEGr0oEPEvsgawVmyaaWOhq8LIiZMiCrKSxl4oCWNgcr4wMPRqh95AQ/drjlOC40t+fPe3RcrrqwnFkFkjINizQkZaZt58PUB8YmnMTTR+5iWbaCJlo6s9OGW+QJFPcWl8Dw3o1QaebwNYh6MBxHGiQmCYKwxNX2uvRyA9WkzZUmkd+HUy7uP5ta/CeeOM9eHPjTq06LJPWUxBYKA6k8SlM0mxPxqhnCUkw11GiaJpCV1ubFUODDgkhadAoOsCwSUtGhh4NzLPHMdWNotDGNLgsR9JFafCSDgakE0VTRJoNlwnTseZV02kKkw/QBNV28JIEcgEvZfBMNE3aEEaKSnjWlwoOdHa5sfYri8Doui60NdUJ66o2xqmDu8MZBw6JRF8cMJoXiB00LR88ADqqGA40o9LWVAvdGmosU5QdxGVmIvLra89okBUW9kw0xffIVL/rxXV2OkNAN4pmViwNZOk10tF686/bPHLMyNCjEUo1wi8VQ7+a5am/42b+Xaq/OHydZZDt7VU2tTyQOYZ75+ZPiWk/1+D5yAW8lGHjkL62VJDmhUsKjlNmVDo6u+JPkyBpv61ZkDJC1iZ1d+4IcYS9tKDSPOrUoYGdf3Eok/ZqmgXSjIoLCTO51frlZVDtQVZsUSnXfJfH6EePvGGpNzW00yTERIcu2iXqoTTMSIWWDhZJyYpwjQUqTUIMj6Tb5gPLN8Dbm9WJsm3QQvMQiftsSYLisRCNYRSKyRKx+c51muqKadz9Mc0lPILcBy9lsB8kmcmLCM11JeGGkeTHyHF8DV6c/dKnbzy0RTDdcwBgeK8m4/pxQZwmQTwSWfbBA9AP7JGmWVrSTF1cp5CiZrOa6JyFLaGhU6CxbKgpphLeXz/ISjaEDJmfYhQKa0sFo8A/omG0aqKZjaFHIy2BVFdrSuefi3sJ0lZA6MAmlqiSpbVCr2sLpKSl1XZjksOqbV0mgVyDlzJsMBNLX1wL67fxw/wma3nlQLHoQEeXfoREHZQjYIk7aDUw3fsWlVdo0sBu8NBlhxrRFhdE/liyYcYIZVjTyziSbuto8Eb3aQ4wKg7Es6HfftZM7vW4prMoSXBcqHoNniUyRc9bKjqpmPjo+ltmxaJWJuBFESzqBIGyVBDveRaZ2czoT3Fg3wM3TYKlvu55dT3Vb/T2XNeF2+5fAe9siabZY59ZZQUUJ+RRNKO3oULU55bxXpi1Eff6yU00feQCXsrAnAq11psrWvdVDZ7o4+GCWBiRkbR26+7yH5Wqg3s2GtMXB0SzRDbONoOsxOGDp3NCX1cjNkO2iRG9m2Bcv5bQddFHTYcvr68Jb7dvbNzBLRvbN0rQ8L4YRVMmfAif100+6AKAvgavGswEoyTYNn0FiQRZyf7QB4Ch19YzvbhmK9Vm9Ebfem8nfOXuZXDez5/m3t/T0YmKdmsjf9rqzTth2+52XGEJdIKsiNtIPsiKtE+NtsjhlFEUzSpbe2kjF/BShoN4Aw9G0CYlvSCKhUICGjw5o6fLLFUFjHxLMEFWcN2nPaSuizuJjoqC43CZRFFPOh/aNPLzHDO5X+B31adJ0GEkJGVFUUNdSMeDQ1eorAY+JwqNphFkxb7K9kasGoRrGqF9M+Zvs99v9PaI8LZjDz+Vwdgr74aP//QpNV3s7wCdOEKXvrAWjr/1YVRZGRxwJEHisG1Eh81poPMtJmWtB9Kp/LsPcn/GiFXAcxznaMdxljuO87rjOJdz7l/iOM4rjuO84DjOPY7jDI2TnixCNRlb60vQPULo/kQ1eOALV7IEuJGhcMIrifLgYXKoZHR7iEuDl6YPng6SMqkpFQpQKnIEPAvO7o4DcP2Jk8wIM8QFC0cFhHOxD151MK06VJpo8LpcNxZttQr7ogYvConsftOruQ7OOWiYdj2PFnNSQshKigoscGkS4nioZAbqvuUb1IVc9qfv5qHz6Ks26aX24UGuCEP6A0bYovwgK2bvh1eLNJWktljUcG6i6SM2Ac9xnCIAfBsAFgPABAD4kOM4E5hizwLALNd1pwDA7wHgq3HRk1WoGOeoi4FlBFrqSlDDYWBtgZhHxu3TI2tdyCxV2YeZholrCYZnxM6E1DV4gDuJXjC6V6R+CgU9YVZH0+AAwFlzcGdYtj5SjhPUMq4R+LKI/CEXjulthxBL0NkPTQW8NOa6ro/rHc+sgU/9+tmYqLGDKEIoOxp//dR8uPiwUcp6wiArFqWyahCuaYQtH8KI44myLAin6oNnwURThLc27YTHV25CldUlwYbvIEC06KUyATjD0y01xKnBmw0Ar7uuu9J13b0A8BsAOIEu4Lrufa7rkiORxwFgUIz0ZBIqRk42aVvqSzCitzziI7uRDO3VGNsJNfHBA4jX5Kt8+sa/d+3xEyMFBMnq6Y/JyTRmA8XOhfQ1eOGtnTcH6krRtrRSoaClTdFNUJ02du7lmzqJNO7NddkKtKxjCiRjxFds4Ps+dqXkg1c0SMb1l+ffiYESe4gk4HHeQZSowFZDwleZgJcWuTaF6qhjHgqyAukJBNL9BW2iyW/j4Jvvgw/e/jiqjbTWRLUFKapmxCngDQSA1dTvtyvXRDgXAO6KkZ5MQsVMSD+SCGaErd2toSY2I0QHHE+48oKWxACZD94J0wZGYroxNXtGSMNgCgcAvnH6tNB1aZoExMNgheH0BTwcw1gbUcArFPS0cjqHCWn562Faau+ojo+uDlNiknIG3HQOeWRBI6NqpdNCNBPN4G9WEy2CMA+eOSkhZFkzxUMo0Tnnxdhi9ulmooyT509laTGyz3f4/9zvmxVaaR/fCvtEj76+EXa3d2rRYmVYkJ29t2Mv/POV9dIyRho8g2fADHNW3WzSQCaCrDiOcyYAzAKAmwX3z3Mc52nHcZ7esAFhb70PgTC1K248Bj4wK6zgVPGXrJnSI6/j1PcAZgswiQAnLsgXuklKAR3MHNoDegmSqceJE6cPhGOn9A9ck31EMW8CbaKZ8k5BtLaDejT41ziToMYwvDpB0XG05nDapqsqlBljdbnl67cLGrBLT1TorOEN2/mpY2RIywcv7elFVP0AACAASURBVAOUOIBhxr6weBz3OjseUU3JbWrd6G9qNQjf9Dfi9gdXCEw07UutWdJ0spSs37bHz4OXApmkz5Ubd8AZP3gCrvvrK6h6f3z2bRh2+VJ4f09HjNQFce5Pn4JP/OxpP4IoZ7z0gl9VfOUs0MajYR/cSo0RJ9u2BgAGU78HVa4F4DjOEQBwBQAc77ou94vsuu7truvOcl13Vu/e2fIJiQq1Bq/8b7HghMx4XFCfVvC0HtgFoMt0OE4yp5uuy0/D8NVTp0RuG8PcpWG/T95FyExR8mHGPAtWW5X2qRjR4PVqrpOWiyrglQoFLa2clgZPgw5rPnhZk9CiIuaF1+W6UBtxDpmAF9in2hHFRDO0rJyIJprGlIRRzT54N/5tGb9QDI8UpUnbQxyn1lIXZfPQYOevv/t++Z6CptvuXwEAEDkvIHBoEIGk8pGZ3OpF0TSHrK4bk+BYzYjzS/YUAIx2HGe44zi1APBBAPgzXcBxnOkA8D0oC3fvxkhLZqFkEKkZzeM7VIwguyivPnYCmunT1U44EHP0zApEGrwhyNx1iyb2tUBBwhBEvpJq8DBBVpDvOO1TMRfKjAq9XniPHlXAKxTka5LV3GZd8+I40YS8rD1d3Cuvy41u5muCrM8jE2DeleixuT54iCESBlmxyM1XmXwXfvaE6I8y5kn4abmcv4zb0mhC7nUjb4h870sWTGqwNHvlEL6DmCZ9TVs6e97OvR3w0H/2D0vA2L5krut2AMDFAPB3AHgVAH7ruu7LjuNc5zjO8ZViNwNAMwD8znGc5xzH+bOguX0WKgGP3iRZ3zIXYU7UzkgAB4/pHVtya8dxYo+eCQBw3s/4SU/VEUnLtI3s3Swsg4kw2rtFrkWKA54GL6zCEwIl4KGF/bQ1eGUTTXq50OaaBDaCrMh8OD+/aGzgt1a+rhSG0HGi9ZvWR1iEJJjrVDR4EoYta++ARUs9PxAPhsEX7T/scDiV/1QQrUfRQdgdFx6kbJMFbaJZDcIeKnR9DJ1laWy4pFQITNqnUhYkTgWypmy4TGBJwGjG9HzwzDVtMrNfjN9mR2cXTLj673DWD5+ENzfxA23tS4j1S+a67t9c1x3juu5I13VvqFy72nXdP1f+PsJ13b6u606r/O94eYv7H+iPJO/jpeIvO5holhh+tKGmCABmEQKTSJj8zFtbuBsklteWbUYYDdD/O2IMriOLII/GPrc0D57FROdRIpPaANHa0oLm986aFSoXNQWIKsgKO6ZxRdEkrT7534dHbCcafVkTLZLw66lJQYOXgkxpDa31NdzrmFfV2sAXDkM+eMiDCuFBlIAWk/lN77nVEBEwnCYhPnNFuplIGjzrJpqca969xCU84axhSWGnM7HIsvHdwT43KeW7iUSbP2mumHXb/OB/O/bwI0rvS6jiz8r+AXox8Ba1SrPCJjAuFuQs30nTB8JXKr5sKp6+hRNCPamEybxNxsZJN+b0vk9rfeRNau6INvj04aPR5b3kpJxwzyJgZDKsZi51JYJLcpQ5Hj28aKY2fPBkQVZY4S8uHzwClc8hjf85bWq4T6Tvkgipv3cGSZy2p5MHT6LBS5AOE0SxaOjWUAPj+7eGrvOCrEQx0RQJYibfDLqlLGmpREhSQxUUfrMDHi2EVBvjY+tZVe0QWlWWI5Ou+bvwnndYrEnUmi3iJO/e+sJoiz1VG5aAECmwp6PTizwaajeHh1zAyzjoSctjJlXfp/YuVoOnwZCqhEdmZ3SccH9RMGVQN+E9Ew2eFxZZshFgTe5MTv2mUs/zlVOmwCVHBjWBPJNDAvIq2I+R7JQU866xzKysraQip9I+eKLHjuyD58jnANt8bNFFKUEWgyuXjBem74gipPHeu6mP2gHDepgTUkESAS5kCdLjQhJrKC5ce/zECLUd6NsaFhB5czZKkBXRKzXS4FVZngT2W/W1f74WLmNJRKG7iqIZ43ki/PDhN2DY5UtDVknahHltuty+4kbZGsWsV7L/qQ4WMVE20T54lX+/fd8KXAUFbETRnHfTfTDuqrsD1zCPk3Vzd9vIBbwqAjs5Xc41FqxGDZNPyKHKysB+FOpKRasaPBkzx7ujei6bG7nJRtG3tV56X7bhEr1ryF9e9lAYHzx0onPxvSTMN8uRU9VzMiqj7CjSJLAMZNyJzrHvxxGo6qJSx6tvOsQ25okNAW9UH7EPrq0+dCE1C844T9Is8MHDwHFEh3WsiWY0SwMRQ20ytlUm34XG96U125RlTNEVEPCit0e/nq/9YzkAAOzusHOI7B/4JvtCXamJppwWcjvKd0f3aTHj4+cUxJc1Aam78X1xChyb++Wwy5fCV+8WRJ6tAuQCXgbw1BVHwJLJ/ZXlWO2B66oZOFbLVnDwXjkqhoxeqPU1Bfj04aOsnkTLlIE8JgzLmNk4rYyD55JpDvxNC097lBNvnXJRtWYYEB882Zy85bSpVjZ32ceT7Z8w5idNH6hsV2fW6T6GaFiiRtHkVTUNuGMj8psNF192rJoZU/M0NHhxHxTECdV8EAVhkdVlx6NsoomxSNDT4JmgM4FI0SzaBNp5DDDfRWsmhlRfkRKdWxa6ZK3xxue3T62Gz/zmOas0+LRIDq4VB7ie9svCdoHlg9j3KPNn1OnXtjbN+pyptPed++1oLtNALuBlAL1b6qBfN7l2B0Dkg6fXV0HDKUfFdNDL6XNHjYXG2hJcfNgoPYIqOHxcn9A1qQaPc0ulPfTq2DhZjOi7wavOCuO8/nT2MBxDhGtLpmFIIodXOfegK52T04d0t/LRkAmRbP+EoZw7sg1eunaRtN04D4odEC1rJxIzwBMOTYURG/PEhnaNfabvnTWT6SNyFwDA91EWgZZ9548KJs/Ouuin2kN+dM4BwnsO8Lfj5eu3c8sSzB7eU0CL3mhhDj+uXDI+8Pv8Xzyj1YcN/Oa8OcZ1kzyvoLvKUr5AeZCV8L1r//KyZvv4Zy1/y7Sa9+AfPlmR8JDFMFo5vecHMBRSEd3I1rQJndWMXMDLCDCTiWWyXXC1P2gYhp40qdM0Yaxb6mvgvINHaNEEANDWHD6hlI9J+KaRbb4hTDYn1TuWR8RUlxncswFOnDbA+63zrlWQMfXJ+OCVk9tL/eMsnQjKBDxWgCR9FhxHOd5xMjyO4xjnDpO3i7uGgY15YsP/iaW/sbZovQ8AgDkj2+CMA4egytLaTdvKvHH9Wuw2yED1DSJRmXnAp+xBpn2plMGOO65NcaERvZtQ/UTF6L7m7xClwbO0N3VZSiHx8jvb4NEVG6VCmA54QgoZlxSCaAJaumJgY2sisxnbFCrNhgZdcY+3rf1zH5DvcgEvK8CckvAYWN3J7GiYaCp92gQr1SRUPY+qTk0NHpvzT1gXTZUYZryqvGeciaYYDjhBLSHiTWM1XlKtViI+eOWPG+mKR7YtOnSeldBRcNSMro6Ap7uuhSaaEDGKJq8vw3G2kUvRBoMT8qNknqejy7WS7FznwEFm5RxVK82aoGIxeaA4yBUN1Xyw8d5DefAU8yBqLsNXrvO18SLqj5rQFz558MhI/WBw08mTI9VH+VBF6sFH0AfPvNXbH1wJZ3z/CWuCJ68ZIoymoWk07dKmGaKsqcdXboK5X74H1m7dBXss+Tx6/RITzQh1ufcsv8bE02fEgFzAywiMNHiu/se/4NgJrEH6J6CL1hbFJ7Yi8EjSDbKi0uDZzFlk4tek1ODJBDwSZEVGkyP/zYMN5suGb5UMJBCD68o11rZO7uQCHr9sWYOnEvAikyaG4OBGpNnTaDYEU02pbHw+jTTttmKiyZDB0tWlMAXGolDAMzF0mgQba5KGaXMYtwEA9XdC7cuNsrvSeg6Vtphobek26ajGjbW+UCzq98ARbYkcbg1ti6YlTNJE842N73t/2+g2TtIJu2CDj9fyQdM8uKYh2v/e2LgDhl2+VIMKOT/05b+9Cmu37oajvv4gikadMSTzMa6IlrxW93R0wt0vrdNqp/rFu1zAywwwHzlumgTNfgqO2ieHsIoqIUbkU1ZTsrNwZUPC1eBRPng/OiecBNuvG33pmnzXVb3KNJZkfOWRNuV1ecA+h6wNjG8VJmF3c10JDuT41pQKDnS5bjnRuSRNQrHgwIhe0U2mZAx2wXHgk5QJMp2XT/m90vGf1FzZBUH/UVciS0drfcn4wyw7B5DlgaNhQ8Bj3y87f+l0HFGg8w5pgYTtOiolpkOGFXJVAmncQhCv+5JCg8ej6IOzB6PLkutJxMaJ2gdqzVjiZu9bvkGvXwX4woQb+Ne0HUJf0ho8FyRRNBUvQiSs6wovAPJ9gfBS23er0y0A+HTjzDnFhY679WE464dPSOqq2+etl5vvXg7n/+Lf8NiKTeoGNPrKOnIBLyPAzCX2g+uC/mmvqjx9V9W0aGM0MY/R1eCx5oyTB3aDeaPavN+HjeurTYMO4jh9kgVZITyS1E+PjTxHhA9JnzaiaMpOy48Y3we+dOIk6KNIEQEA0FBbhLEcf6HaYgE6ulylZqXgOLB4cn84e+5QZV8yyJ6nWHDgC8f4QRdI0YLjKBniWH3wWBO2wL0I7TKVrzp2gnGaBJnAg90y4tDgse+ts8u1luwcu03Q6yucIiAZGlhgBTNV+7J2sK+T7YNmhOn3R/Y81k3gxpP4Zo70nBTNT5EJquPY17Zy+4lYH6PBs2nd4rVppUniseYyVzT9vjjXCA+ROB/vmo+NaP+z/f46NCLFuq4rTVsQLl/+lzevX1yzFR76z8bAteXrwgGXuO1KxuDtzbsAAGDrrnZUW2x7l/z2Ofjkz59G180KcgEvIzAx0Sxf0+vH0TAbUkFoomnkvxKmSjYm7Eb3l0/Nh5b6GlRPNj48ZkFWzH3wMG8tbHpGrkc3a5QVk5lo3njSZDhzTlDg+q+jxwn74DFMNaUCdHR2QZcrZxZJ3amDukuoVUMniiYZ24LjQKHgwB8umCusG6cPnqi84wB6wfN8Z9l2m+pKxhoZqSYZ2aaNOErsemD77uqypHXSMSmkxt5++HCzeth3ojrYsGHuKtOWcTV4zJ7UpyWcTJ2tK2xfQVfcEM2H8f1bUfV18pjZhG0NHivYRTWLJBYzPDp116CesIk30dy5twO+98AKz33Dv29hbCX3SERyzBbw26dXwym3PVau1+XCd+5/XVq+vbKJY/eXRd/wzURlNPvROTm8pMF40e9iw/Y9sGE7XojNCnIBLyPAbIY8Szh9Uy61Tw59e9bQHqh26TaT0OCZfDtMPgwiGAl4ivqYICs6Jpp0ABBxu9FP6aXMMOfWBYeMhDF9w8mmRX3UUBo8DB1RXQKlQiSbB88Tosv/tkoOGciru+fShYHrvBDouhFhxSaa+InKX7d+/ea6EswZ0WastZDVwwoBcZhXhzR4ros2GVUBO/702ISHIgkxIgxsrCzVfJANJfZtloODiTRp4eus2a2OcIgt5Hj/Fy943deVClBfk5xZc1rgUk6+4xrP9f6esKmhH2TFgLAIIP7k3HvM71vvfR2+fNcyuPvlsgkm712aBLUr0yF+8PaKBo93WM8KSw+/HjR7/PEjq6T9rt+2GwDEhy5JQeczVuY90tmHoyAX8DICsmQuOnQkXH3sBG6Z0ImHiz8FISgKgjHw4ABAtwacVoyGSeJrHk06GjwbGIAMKgBgZpoThWTSm+wkKmSiifClxPvgiQua5DcTjR/vcm2xAB2dbsAkmVfOE7Yicl06UTT9ICuVviXjRN7/yN5B4XbOiLZQ2Tc27cSQ6kHE/upM0xrOx5yu/9K1i6BnU62xyZ/xIQEFO3nwmN/Mhc4u10pKB50W6OdPIG4HCthvi2ovVAVhMjHTpOsETDQr/7KHFZg5KyoivC4ROm2C14OOhhljbVcNGjzvGoQFsz/8+21pkLK3N+8KHZp5B6ppRNHULL+7vRMA+GNaVypGOvDmgWjwZGt384698MbGHVrtAgC8vaVsLtnWrC/gSQPUVP61tSID2mM3rWO2aMgFvIyATKYB3RvgY/OHc8vwPqS6vDUqGARTXreciYmmtg9ehE2ZV/WTB4+AX34Cn0zWZLGrKB4pyalEBAfZx1rFuPKAFVRlpWTMsNCvhdOvyI+stlSAjq6uShRNMR2EIY3KWGDMQAnIYQZ5P7YCSui2InuN2LZ4Gjxe3Vg0eAmaaIZ83JintBVkBQC/f9JCCktfVFKMffCwe4Niu+fxiHRuPoz5lAPiecwbn5AGj6nt+yc7oWuhviXavyQO9fmHWXjREpUHT48kFOxEp2RNE/2/X35nq3ft0t89D6+s3SZti/VxJzyEjWfXMQGUB4+Tt8OTYU1TuqzeLD5EJGMlm99HfO0BOPSW+7X7XVPxh7N9kOVKJDydg5j7lr8Lb27aEfT7dJNZ67aRC3gZAVnY8kAEwXsu6DMiSubMCa4PE7V0nYmAx3luuYmmekNlI2mK6hQcgC8cMx6Ga0RgNNPg+f3zxvWceWXBfvqQ7vCJBUEhn7xmuQaP/e2ptNB1xOVkGjz9982NCCtgmPwgKzgzP7kvI4I2DUGECHiErqSDc/jlHf6HzcGvYZ7mXaYp1UVmNHihdRL83dnlRjbzLbeLHyi6qO0gK8ZRNC1p8HjriW4bGxlPNJ68/rF7UpRDMJnQaRe8wzA80rLQtGH6yNfglXHSdx4NXN/BMcOksZc5HUorD54L4edyoBwAZOfeTmndLk/w8meAyERTptEEADjj+094/nAsiLZTtrY37dgruFPu950tu+Dd7btDd9dUNHhGWkf9Ktr46I+fgoU338/4f7qJaOttIxfwMgLfQVRchveh1I+iCYD9POgkRafRXK+fWJcnuJwwbaCwPObjcdi4vtDCoYXty0gjEcNaJzxPc10JrlgSNNPF+eCxp9bBf7l1kM9O8kbxsHBMb0n7/OvCyHScazUlB1y3zHgTennjQN5jZA2eRC3OrkHycSV92oqqp63BA/4hiY6QwTuY4bVp+oxyU2FcmzZ88MLRZoP3u1w7gUEA8O+RFnjYrpOI1MgDdu4og6xw1jrR+mPfJ6vbF/kzk79rkLkmHHUR8Tt0ouWYxIJ08YtzD/SuySIus0Bp8GIQcuJOk8CCFeBYtDMJu0lWJY2AkVbgui6X35l67T/g2Fsfltbt8hQBPtZv2wM3/315qGw74sFuu38F97osyAr2tR50070w+4Z7AABgxYb3YdjlS+HZtzbDO0TAk9Tdvhsf7dKjCyH+mUZedV2oShvNXMDLCMjkxJigeXVcfZMwVB48yWmyCPTCkQWaEKG9I7jyjhjfBy4XRFsEUJ9O6cDkGx0H0yVjgKMkOpeRip0+PRrF7/TCQ0aKadLo1wE+rbRmSb4+yv9GNeOTpmJgdkxCm/dBtGbap7muC/yxE40pDzxTH64Gz/AZZdWwPm9RTLNFdLBj3dXlWnmPOi0EffCCNdMS8LDvREUe7xtlMzceV4BkffAEdXnCoawM22YSb8Y7qKM6a+/sQu8RmBUTS6ARiyaamGb3tCsEvM5gTZkGT/e9Rk3ZgIWfJFxdtqNT3dO6bWENG4AvHNraex6o5Ee887l3YMceuZYSAOD6v77CvS43by3/K+Oj9ExpKRNNqEr5LhfwsoIuxOTkWZ3oLkCBJZe0PAb0Jmkk4DFceWNtScpkoRk9N/xn2DxCf+maLHYeyXR+JulYexo8mYmmE/Cj8jV40TUn3Rprpf3qRvLimYY4ghNxWsCTBfAhzxJVCNAJskLo8UI/W/oKaJtoSg8HcOCNLW9+mD6jNIF8kmkSmBFhu+507QRZ0YFU0EiJs7BmosnV4PlzDW+iqe6f/Mm+v3AAKk4foiidwuidCeXBI/6CVFf7mwaPbuq3T6+Gxf/7UKisUoPHmmgiAnbEAdeN3sH6beqQ/Zg5Uio48OiKjaH3T4RDfsqBaMAkqt+2i29u29HVBf96Zb20fdmSNBbEcx+8HFEgcxAlYD8mLhj66mjARIPHM4tUQTcSI9asArWeDRauyWKnT49I9VF9mkPXeJtQY01ReI+uf8WS8Z6QJ4s4SSDi4diIojINHgDAc1cfxadJ0PlLa/gO8bzStOkgYRbZZqcP6e4xdVG1uzp58IhQRJgLcj+qhkL30EF0cKMzT7HO+sZBViTNY00ibWjuQ5puZuTKic4taPAc/H4rS3SenokmrpxqqnODgxETTS16ynVOmh403acPB8i7xEdyRjykUIOneVpqCNFBHbZrzJKJQ4MXl5D01buXw6ucgCp7OuSaIVYA9BKdJ+6jGEda+TAwqXaWvrAWzvj+E/C7p98O1u1SW5SJoBpPzLOLXEK+/s/X4OM/4yccJ+9TRrLOuOc+eDmsgSx52RTiB6Yw0D4pq/gFBvdsRLVJLxwTAY9lLlUL0aZjtMmytZUmAWMiBAAwe3jPchuKPro31sJ/HzMu0J5UMSgKIMBcV6XLaKrTf+f8jsOXaK2k6CDgjxfO82iOHGRFIw9eban8m5wOExq6NdTAi188Cno28TWfP/noAVIaTA5ueO/SAbyfEE8Ly9fgmX7oxPWwBzym6/66EyZ6f6uCmNiMoolFQAsVupcoKR6wQreRBo963zrs7gtfPApuPnVK4Bov+ms4iiYfAdKFgpwYScjepA/TeYBKdB6DyBGXD54IahNNvgavmvMEyoD5DpJAKW+9x4+oyZvfUYcLU7+xji/giegEAPjWfeIE60bzmxbwcg1ejkioTCadZMCu6xoJJ9iTCMcBuOTIMXD7WTOVZemPSKlYgK+fPhUmD+yGpkk3dx52Uw7YUbvhawBmDKuJYM0V8AJ/k1PtYMHaUoEKLiJ+bqIhCQeRkAgsPKGAU7y+RhxkRQadUSprocI1AiaaiPCGcaZJEGnwWKd013Whpb5GyJTNH9UrEo0sZAws9h3UlsLvmO+DhyYrWE/DOkEEU9ldlkic/Z1GHrzAPuA4cOK0AUbt2ATaRFNQ7vBxfcrtyDR4yPdJmmitrwn519GHg4SpZQMGyfzoVGVEJOq6O5iC7InsOKPdJxCLJhYNXkw+eCKog6wE2+pMK4qmm4zWUGSiqcO7GB1ks3R0dgWEL17qCxaNtfwDY7bO//u/57y/93aQQ1Y8rTIE0iRYbDdJ5AJeRuBFR5IxQYLQ8rrA1nGc8sfzqIn9PA0SFidNHwRD2nDaPwD+KawMBi54QhiNoX6VoImmE/wX26jsQ+wlNvfadpTN8u7xmFuT1Bcsfn7ubLjimPFiWhy+EEAn4MZoetJIk8Bq8FQU2I6+JwqepNNLQ016efBoIb6ptgjTBnfnljNlxug5HfbHCv6WBVn59GGjjPpXIWiiCXDjyZO595JE1EAzVx47AVbceAy3Hfp9oHzwmHdEH3SRJNAAALsrZnrNjEWB2I9O/YyiQzUHWT8qSBf1nAMYDDDbYRw+eDbatKnBC5lokgNfXaIi4oJfPgN/em5N4NrarfxgJ1Gg8x0kvMnejq7AerKx9/z1hbXwHpVSwcsvLxn5egG/wdb447NrQmWkQVZ0fPACGrzcRDNHBHgueJI5xGM8bU+5eSN7mfmXKbRTKrAavL0Ke3q8Bo9zrfLvmXOGAADAB2YNRrVFw2SMvnLKFM7VsGmWNFKUBk0YEnnamFKhEGqrzpC5oNtZMLo3fOLgEeKywBdSaNNBMk9kYxRnkBWWWSW+An4ELwj8NoVufaE2QWOeinITsjBOkyCpRjPk80f3gjaBaaupgEe/t3AUzeDvTollxCVHjdXqFzNUtcVCILVMSJOdEl/BdrvqpiXa9UVrSVcwkhXfvNNnHndX8og1SNK6eMSpLwGAeC0mpcEjaKj1N+uW+hKa4cQFWTEmS9ym5TZUNGoHWbHog6fbxu//HfR5k5kemkKkwaMFb9Ys/+j/fRDGXXW399vG+UXIN9KzpBLXqRNZDGEOKySF2OTl8naCf+cavBzGIJNNHmmOqWPYl2yenjJzEPf65xfJGRveR0SHEVw4NphLTRVKF3s6FVSzB+uM7tMCr153NFx97AS2mhImTO7QtnAi9aAPHsJGSBZFk/nXo1HTNK57Y01oM8MG4IgCkYkmrT3EROtMMsjK+QtHwrnzh8OZc4YCgP8+VafXqqfg1Z85tIewfMHhf4BEQjMWvDkZRxTNJsrnwnXFe5updrYUEPDkD9DZZU9rNoyz5lk8+oXDQmkS6O7T0uBF5XtlZNt8IvpwcFdF+8CaeOFMNPmFRFMu6trCwtPgUUzv3z97MLo+RviIw0zRRkAkHS3gnnY5z8CmDeioRGqzkSYhi+jkRKJ78LUNgfnMmkqv3LAjUJ6/90R7rxiz2+6KoG7S9mUH5LRWTkEHPfe63GS09baRC3gZAWaD5fmpmQVZwdWhme0DhslNNHnUY0lbceMxcMCwnnDLaVPhoJFtAACwYy8/TC4B9sSLnyjV/7uhtmhkihTVRcczp9SsJ9fgMaZnlZ+6DOL/nTc3dI0WshaMxvuPmUSDZEEza8XKKYfskchBrW7qBr8P/CFLU10Jrjp2gqcxCJtoijQYchp47/kPFxwkqSHrx3yy8mrGocHDBmaSbZMyv8ZAInFFm12uG4lxJ4F1HMeBsyqCvw7YdZxWkBUe7vrMAnRZ3NrHeVmF3hn1N1/AC2oARJRg3rOQQiehNAkV6hsoAW9A9wbhQ11y5JjAbwxvkdUomjpt7NHW4FX6sEDo7Q+ujN6IZbAavJUbd8DZP3oycE3l024WRVMlOAX/pcFaxMQJrWifhvEu0kYu4GUEvommeBqxkQxdN/pJE++kxKRN3mLBfvwI83XqzEFw5ZKyNm2nQoP3paWv4uji0OhFLI0yeJY+7PT7xrQo+1h7TRHfO4e5jsSQtkYY1681cI0W8H5+7oH4xgR9nzxjYOiaIyi+dVe793fPpvJ8/fCBYsaZmGheeIiZv5SOBk9Ut3dLnVHfBLon6lEFOSG9Nk00JfSxUVhFTIJsXL59xgzhvaLEB49l4Du7ovlbi228NAAAIABJREFU0H6mpodHAc1+xF3elFfiDfX4/q3hiwbwNd2AIhB7KLm74ocVMtEUavCC++81x00IHaSIAu4kxfCRR1eanVYwfUjQfzUtHzwbQqMoMJqsrAhhH7yKiaYFUfQnj74RuQ3bwCQ6Jz7topJxHGC43r/hXn0eTVQXMQ9k9zTmeVDbl5to5ogCxoeHh+4NQb+Uiw8dFauDsM6E5po5GCwI4ovz/h65Bg+NClnDezXB+QtHBm5Fku+ov0+ZwTdrxUTio2WyANMjgM53GMMYihinr58+LZCEnY1cFxXHTRkQuuY4Dpch/iTlt9dUW4I3vnwMfPaI0cK2iWmQaaj7fq31wnuq4W+uK8Etp02FX368LAQP7NHALadiWHX5LVmQFcw6fOS/DuNe580h0w+d7HWEBDxBOVMTTVowH9ideb8cDZ4N7t20iYLjBMbdNGppVIiYqRlD+AFwWGDnCYZpkzXFY9oakFF/gybyAB+dNzxkCt2/WwPcdPJk+PUn5jB18SaaUbSwoiAroiZ5GmkVYvHBs9Iovg2VSeieDn4ePGxOXRkSUDhpA7NXllQ+7SYaPPa3wXwUERShauieWoNHuffY+SQkjlzAywjIZJKdmHSjtG2rbloCn1s0VuhIKwPdRXuHhd1N1I/BkiC+OCoTTV386aJ5Xk4/7HdnmCQKKP3BdsGF/9ywOFym4MD/nRdkCo6bWhZsiDaWdpNDmQtxaP/Oh2dUaAqafdJtf5Ub4EW8aTXXlWBuxVw2CkTPxI0ICwDdOfn2Rvdt8f6uKRZAlPON4CMHDYODRrbBhw8cok0vAMCsYT3hC4vHce9hTAlPnTkI+ncrC3Y/OHsWnHPQMG0adFe12AQNtwprSwXP/DVYP1xWmspFI0ANDWyUVul2J3lQmq6zmffBNtnVFc0cR/fdsWs6pMGLeHRsmzH5zXlzpdFwefj4/OGWqeCjqaLlYt0ZMEnCxZE2AT44ewjMHdkGH5k7lCqP/8ZFeYeiNAkisPOPNU3kIRYfvISjaP7gYbkWbSdzaEzoW7NllzZdLLKYSg/DG6oOoXn3bQUQ4wbmq3QXRfuL1QwqD5YYf73cBy+HMcgpktRPhZNM2sSRme6jpZ5joqmYyCTgypwRvl8e77TO5NSyR2MtzB/VC2790HT9yhz4gjPnpuI5/3jhPPjLxfO59245bSrdCdc/suAAHDgiKCTdfOoUeOW6Rb7PFvl4U6f28ihQQdQWC96zsU/jpUlwHKhHmvcE6mvXwIP/PgB6NstNGzFpEnq31MGvPjEH2hRtycBL7N69sUY7mmjvljo4cXrYHFUFFXN0xPi+gd+iiH4677CZk1yWV18mxMkYBt5y++ABgyv9IJlXQ+6Cppk1syXaw4Hdy0J5Z0QfPA+GGix2rUYlxZjRFlSrLRWk0XB5U+CICcH52rOpvDax+xL7PljzKYKln17A/XY4DsCI3uqAN9y+aV90Kl0QbXWhbsMcwgAxyEbf2hT2Vx/XryXwOw4fPCsmmtGb8LB9d1DAi5pOh0YcJq5RgdPgyXkO1rICAxsprETjiWrakgUU695TfeJdLuBlBp5fmKRMoeDAxYeOgt9QWqEOiX3BgYLcdeSD9Y//d3Agel24HB9TBpUTmBcr9ADIT2N0UCg48IuPHwgLRvdWF0bAC19PEYNd4z2aamHyIH6y9hG9m+Grp5a1YoSBOnRs74AmgjCSlx091hMU62uKgaAhdCAUnAYvSD3te8XWd6h/xRoecV82mFxRE9wE6wDQs5EfHp+gpGmvdtzUAR7jrgPes+v2TWBknkW95iVT+sPljEbxtjOD/mYFgVZThwllc4eR+qprfSj/Pd5BBwFP+LvplCnwxpePYTTi4g+xaQoMWvvB0t9cV4KnrzwCvnj8xHIfXW4k3xMRc3LIWNye9pnDRzPRHeXlR/dp9kyCeTDlY7sr1qIIvHnIHphcuWQ8XHv8RDhkTG9cHjzk+xjWq8mzkgjUB4B7LlnIaZf/t6gMOy+wsyTKXkpX/d8PToO/fVoe6Iadfys2vB8qwwahseGHxsKGAKXyydLBq+u2BX5bFfCstWQPMt6QQBVkxTT3oghYQVjog2e4/3vuLzppEhhzzipU4OUCXlbACiIiE7HPLRoLcyitkMz6opWjhaDhAH8h6cxjf+GEkVZ4bx6iajd4IAIc+U78+KOz4U8XzfPuE6bywkNGCQVFAlozpeODF4wOyDAfjv+v6F3INCespub6EyZKGUkdiKaGKjyybmTMWz80HR65nO9fBgBw/YmTuNd542IaldNkHdAfom+fMSPkPxoSpIQaPEf6jmlwtfmcuuzzfO0D07y/ZRrW5jr+u2VNbmuKjvADL+XJJPdorR3vmXo113m0d1n6mLP90D6tMjTWlrTMgc6eOxTmSSKImjKfw9oa4U5qP8PCO1iiHmFcvxaYOMAP0NJUV4KPHDTMitkTZn2JzLq18/EF6kY3n0X1SXVxwrSBMKEyjqJ1zb7vHXvDActYumOJomlBq/WB7z1mgZIy/vzcO4HfUs227mvNoISH8i1UPKdtwT8wzzhNy8w3sZBrBuXl6DkbTLEFUI06vFzAywjIVCL77icZhk4E2SYl8hcK7O0R168XFt6SBs82CFk0E2DLmoIcftHNje/fCt84vczwYoJ8ELJa62tQzAK74RYpzR9Lj//MfpnFk/op+yBghYiz5g6TMpI8iJ6Jq8FzHGW+PdvBXk6YFj7tF/edoICnOUfpPgKRDiVd//zc2YHfvP2CR7qpiabMf5Gu1VAjLmeaW6sk0eARkDHUiaLJm68iCoXzgLd3Bv5W0KIM2GN66u3A1MG4gCo8cgIRgh0Hln56Abz4xaPg8S8cHqTPgDa6TqQAJpplglGP+W9GFqTJDJoPyAxoKNE0p8U4TAzf2brbeptRwPqkvbY+rNk0RQblO5QGjwppyQWviSjPKstLjOkD07dsLruKcqIgLK4ts/2EkQt4GYGnwdOsJ3OkHdm7mXudPmGVLRgRc86GlgbgC5pZMEsnizj4KLxr+iAMG/vspF1VSH0arQ0lbywxJ1BfqmieaNMzlvHmnaSz78RxylosXn4rmbkdFqIR4AkJDqiFIUxkUh0IW+PcUJmziGASzVM7TQKIzSlFvm/zR/WCb35ouhekZ+KAsJaZRzn7OHT7MjNWqYBHtdFYWzRKkyBjGEQmmoeN6+OXoa5jlu4Xj5sAPzh7lvA+24ZoaLhWFBpTRlXU1AeP0PDXT82Hey4NmzfS+MMFfu5MmUDaUl8D/brZFYAOHdtHWSZkvi4wZ+ZX5pcRra1rTyib+tJmkDoBx9h8jlF98PZyAqnJfBpt4VdPvGW/UUPU18TL6larDx7Br558C15+Z2vousneIRWwFM15FmExRdGEgIaOc1vwN0A16u9yAS8zIBNa97RfdqJ9piDJbsAfLWJ6A5mJZhyRuVj88COz4Mol4ohuUgE24pIljLtoM8JEPdtRyfdX1uCp+yRjSvouOJQgJ4oCB0AJj27o3llzhnLzW5lqrDCgh+a2ioBRNiWV17NNk/gQIww2DxVWu2EiJ+suHcfx3z9mhD584FBwHAeOnzoAjpncHwAAZg/vCfeyjDzCrI3+JXs/rRwTUF6brH8QDeM0CYI8eD865wDvb929d8GY3nyTYgGJOgc+OqZ/qqKm2zBpdtLAbsLDQoKZQyl/byfwT+y47Gi+OwMNoexGC2zC/TN8oOnX5x9UyfqUoaW+BJ9cGAxgo9sOu8fzBbxgq0l8q6MgKnmmh3NY0OQdMV594JAEMFE0SYntuztgyTcfDt23PS+CGjRJOc9UM9n+Ayaagb+zYZGmi1zAywhYE00siBr+xx89IHSvWHDg66dP9SLVhSH2dSnfVcP7+CE1eNMqTPE1x01AtC7HufOHw+Hj+8LHF4gjuhEaYjHRlJinAuAYum2VJN6tDTXUWIrL++aXlT4Kvm+J1x1Ho+gIXpOMRBsfRfHps39jWK9ydDsHHKW2S4dJjgKWATpkbG/47pkzvd+vfWkx/OH8uWw1VFsYYOSYXlSUUHp+B5lW/joWkTSCYeQxGjyaVJnWl7xnAIAPHzgEbj9rJrecLKGzVIMnGTOaZtEUoy9j3llLfUkqFLJ3hH6wiq6U9xU7NT0uw3vhI0maJ7TXgxETV6nzxwsPQvnGhjV4lX8R1DqBucM/KODXYxYiEiFLDM15ww4nm/+NR04cPni2oeMPxh76Fi0eDG7b3Q7/84/l0CEIgJAVWfn93dFTTWHmBbt+5Qo0hQaNCHaVu0Zbg7R/eUmRAOhCtMBbaUE/BmqOWMA3JVSD2Eg3chK7FhyAk6YPgpOmD4K5I9tgxYYd5T4C/ZpQ69cl9PI2AlnTWPO/7545E97evBO+tPTV0D2doaLH9fDxfeE3T632hE1TFLxnZwWq8g2Mad7MoT2gV3MtfObw0X4+Hlk1z5SXCHV+YdIfeRdBxsChq6NgGlQEA74PnpqpxOaCwkJ4ss/8/q+jx3l5FAH4vlcimAml6jf10GWHwvyv3AubduyVaCj4wSWwHyteMZavIdO/ua4kNaGlhYuz5g6Fcf3CWmMAeZJqGcOBNTcX5zvzr7OPcfL0gbBuW9CnqKWuBjY4ewCgHERk2brtFTrwGv0Tpw2APi12TBa/euoUmNC/FY69NXgST+9PbU218MbGHaj2VFPkpx+bDa+/K/Zjwk77KPyw46gPheT1+X+jyqvKGlEU3i+i7ng4E82MSCWWwO552qb9kuG46a5l8Ksn3grkZ417+Ew+IWu3qvP7qd473/WGEeg0np31a1OVY0tgupJqBhVRNEV1bQXeShq5Bi8j6GIYdyyIBo/v0+RfO2HaQLjkyDHkhhTYE2VVbhBpkCrkYx49qV/AT8akDYAgQ3vkhL7w+g2LvWhk5ggKVMGrYp8bGj2aauHpK4+EqYO7e/XYD3w4mpP/7MUAU1r+m5hmEBmaTsEQfifiQYzCOPmt89sIhMWnaEpagycS1EQn/iYwGUfMR7OhtgjNFb+2YEALv4yoZ6xylvf+OhnPe8IETBvcXXlwM7hnOWWFTMAs++Dx78lMNGUMg0jDGSzj/80WOXfBcPjVJ+YErtXXFLzUEkMo4V/UD6/fjyESgGP9Vj4wazBMGhj2o5TVH9i9AS46lB/QSzXnF47pDedy6NddKyx9bBAWFXDrSyDUK0sEr2PmEa+izpCENXii5vk3Dh4TTMfBM9Vj62bdRDMqbHzLCHZXopK2U4Jz3ONn0vxaRJAbVbOY5wodaCFML9VtkvJs2wb0CKqp3IpCQVaq0AsvF/AyAlMTzc5KxWLBgT9cMBeWftpPzC3+MPi9Ss0emPqj+jQHzMIA/FNp/qLifFg0TGO8Piww9WwLNqIxkm8GPzeduTAi+xiRDYiMSbHghPw3Oxmh34HgO+fRykOcIcADJrMUTaoPsU0ziZeuXSQUSELMeYTN3YRkLMNAmnYc/hoUCzNioo6d0p8qF77fyXRDaHUctdYXE0zq+GnixPCvvLNNeI/OL8kiwMiL9kWONpxAFPV1aFsTfP/sWXDLB6Z610WvjqdFwGiCVaZpqulFzyX2MQb2aBAmMzad874vqP39j4AeEZ1oxd5vbhm1ZpeuKFpDZB5+fL7vOoDeA1xesCy9cawpFqR+6Tx6MP5aaUI3XH/oe6/rboAYclfwd1bw3o69kdvABOJUlaHHJiBAccr6FmEut0zUcRZFyeSWZQ/Wq0++ywW8rMA30dSbRYMqSZxb6kswc2jPQCQ8FSPjunonQ/+6ZCE8feUR3HtYE02TNWJFkxTD4mRNIr2+Kk+pa07oCb+Sap5PYcH/1xf6yteICR1hQERmekkAI2B4TD+laRTBpq88L7G3CIlr8JDlvHcMtPBEaRmAP6Yykr75wekwfUjZfPmMA4eE7rMaPP9wSm0uR79rEbo11AgZur2SxJ8NtUV49qojYQTHzyygeUFoldlIj7LnOnJCX24AGbafxtoSHDWhb+AaJqS+ivdWzU1pdck3wHTOY/YxTH0ZZgzpAQAAPRtrUQdpwhKIvkQ+eCIBr7ZUgFU3LYHPHDFa3TgHWA2eLAy+6iCMvd3JntpUOdjns6nB88MOBJy0Mod2xDtV8X9pB1kxi+KJ7V+u6QvcVlirZRW5gJcRYE62ebjplMlw24dnwKg+LaF7qk3eBf5iUJ0Y8k7DVRGJQm1oPGgUv6u6ygl5HAIOe9rEXtfXNvlaOREI4+sJkY7jMYCkHqvBC9R3y2HPgz0mD56g5oBa62n1Qy2BTXMME60j+kCdzDVBGgBR17IT7ULBgT9eOA9W3bQE2hiNPQBAB8s4kEMHR/ysD3z+kCDZKqHEkK/o0VTLN1dHjAm9RwztGRQS6Sa/e+YMuOpYcZAoGekkYumiiX1h2fVHQ/fGWknpSnuVBj+/aCz3vmqumqdJMNXg6YGlDlP/iiXj4a7PLIAhbY3RfPAkETL55X0Ig/Vwrqve0c8+5uekxD6PbI/QtYRoz7gGLypsp9dhkUUTV0wevG2726X3MaaNOs+u1JopLDJtDjOvKZ47DPk7rUPyKMgFvIyATCxdZrClvgYWT+7PvSdqCduDqhwdWYhroslr02CRRPG7+sun5ivNVTA4Ynzf0DVRkndCrS7dGMHQ14D4fbBmm8Tcxtfg+TS5AAE/nbQ2LZo2+pmSNNGUAWPShYVZonN9kyRRDV73UZhi9oNOzz/eYUxTbRGGtgUFJlHvrAm4CfgaS7XmhSa9Z1NQ8KLXydGT+nN9zzB00Fr/ekkwmSDK49vaUAPPX30UXHv8RKYjee1jpwzw/h7bL3gQKNOIm84QL6qvYX0MaooFL7ULZg/DRKJUuzQEy4jWEO8qyY3Hw8kzBgZSrmA1eLKTBMyh6I/O8XM4iiJCVivYp7d5MEiEdR3Tw8h9GpCPSSmzZadcwMMIb2w3shqqKJq8csG2MVpJcRmViaYoCEzZB6/6kEfRzAhYxt0GVGG5yyaaMi0b3vSF14xsf9F5TBETgqFvTN8WGNM3rN3UwRtfPgY6ulwYfcVdQbocwqwJNHiGHxVZNTbtg+P4Gznpt5Mj4JExZN933CePYhPNyn2mrGrMbAl4qlcTyvUWods4tY6kZcfxfTHZ3njagyj5BFl/HT9AlHpcZfk+f3PeHM+80va0pPcQ4cEXRVNtqQDXnzARrrrz5XJ9jQkgo12VO5NFc13J83EpOg50a6yB1ga9z/ZnDx8Nn1gwHF5dux2mDu4Gv3jcT0BdoOYNC2MTS90KgijENhHlsDPogkcdFIgEPM7lD8waDJf9/gVu+SJlmu4CJ4qmYDxke7dKY+U4TiB6a+Z98DTJC0XRtOBz77cdvhb38Jnsh+0WhHYcf6ChwQv8UAtiJs8tFRwDGjq5UiKswdOnJW3kAl5GYGqiKYP4RFKsddMlwhcWefbM4Wsmz5dU7jMRHMfhMq5i4bZ8R/ebwgpvcpqg0ofj1fNNNN1Q/+Sdsx8i08TRUUH7BwaCrCRkoqka43CofvN+TUhGB1mhhHjqIu/PACJp8Jg5Q/sPY9vl0TVnRJsxTSroavDY4DuYPejmU6dAj8ZaeHd7OXWCTJOIWXbfPXMmTBzQCrfe+58yDVRUXBoqygoFB1rqa2D28J7he44jZKIiH6ZEqP6RuUPhp4+9Ga1/mhRWI895NrFg6V+n9yrx+Og9eLEQPIJhBUdRa7I9QjVfHQiOScjsOmMga8oUutvddkwOuWwPmZV3ivkMhc0oZYKbvEHf7aVS3vYgiyQ4ckkYRTM9d5YoyE00M4IuikmyBVVbrmu4R1EaQE9YRNhqB2nDdyfyF0pywfH6Epmn0uaTOmBNLXnwtTSOV5bV2PkCnuOVHdWnnMD66En9Au3ZFPB4ERTFAS0IbcHgIEmlSdAV8KJ0a6LJxZ5c8jShNERBVqIkse8MaYErfTka+fUirl7d9xF4BUKtsn+jrlRACco0Tps1GI6Y0FfKlLCHMDIcPakfDO7ZqEyhE+WbUSg4YtNe00a9OWnWggMA154wybR36xAekiDMPjFg94eQyb+gvSjf17LZvl+I+Gthgv5UA9jnf1kSfVe7bWstxQsbfpXsXg/AEeg02lPIV6FE5yHzTwOBU6f/YH9BbV/ug5fDGGQqJTGH6D74QVYU9SHM+HDXlNREE/+gNiMn2oSX6JyxhCBPprshEAFPHmQl2HcB6YM3uGcjLLv+aPjgAYMD7dkU8HS0QjRtw3uXzfIuOGSkmjGxNBdU/TTUMgJehL4wQs+kga0BoRIr4NGCPq9KmZELoxjFRDN0MkzmGy6wE6FLXk4+APr+rWphjb5eUyxItSrIXkNXiBbOKDABEZw0NXgyFBzJXDNsWLdaEoqQOHJYCV0HNNsJ5T1lTVYFLcq2btaHlAWrwSMRF0+dOUhar1qQBCtuXbtkgOGciMEENvwqUXnwDIOsYKJomiRVl70XkYaOqsy9n2vwckRDDCaayi5d+WLQoYXvg8cx0TR4QKHgkOBgcen2zAlYDV75hq4ZHK0JEZcJanqLBVrAK5chQtvwXk1w3NQB8O0zZgBAOagDyxxiBLyBlVQcKvByyqmYaQccaK2vgVU3LYFjJvdXm2impsEz7xdD818/tQBevf5o77d23ieKUUcoqyJFlaPn+4wh3b15W0CYaGJ9jVUfcl3zwYCwJtK8UKVYbbTOvJPR7mn9NV4vG4CLpSSSfyhjIk3D1ESTazasVd+sHovfnz/XSpuiqmINnl5n9JpxXTekNRFq8CST6LBxfeBrH5gKnz6cn6qh4AQ1+yTycpSI1fsbshA4c3DPRuE9G4e3mDx4Or0Eg9FwtIOVa673Wx+y90IPiax/tm/XhaqU8HIBLyOwaaJ51bEToFtDOC8TCxfcyJuUNIomVzvocfbafaQJ3nvxn50pW/lX20ST0bzx4I9ppWyBlyahfKG2VIBbPzQ9EDWTBc8Eg8ay64+G+z53iPB+nxY/6iFXwBPUKwhsC5UmmpYYEFU7jTY1eBq77E8r4dKx32YyVQJ53hz6Pj8HYpRxJPPrX5ccDHdcOC+Q6JzXbNAsRj3HMdDV6gfz4KnbZBOQ2+J7/Sia+qfevmVA8H4k4UXig2farC49cTHKs4aFfQ5DfSPaEX2TRcKQaq5ceMhIpnxwjTbWBEMjiMZTNoccx4GTZwyCplp+pFa2TaKV790SPYptJhAjz6Dam3UjIEcB6w9NI64gK+wVVRTN19ZvF94Lte0G/4hiDiptH3GfLZsFPlQXuYCXEdg00Tx3/nB4/pqjhPcDic4l91VwgTLR5DSk0kL87vy5ofxYPCSV+0wX/mk8/8RVlwnVMdH0A7KEDwc6utTtEKhO+epriiFml8afL/Zz6vF88EQwPf22tcdqm2hG6Ffnw1BPxtroS8bRmAOfUZflwVNh6qBySHeS3Jv2oUT74Kk0eIr6uocnIgFYVIY9rLDlf6Hjg0fgUgI0gF1zw4IjHuuoefCwtUM+zJWanzpslFH/POgGphGVpbd60Vzf2yFnrNmozuy52JC2RvjJRw+g+uf3g9GuiL8BTqBd4q91JCcdUDUiTo6B1TKlCVmuOxuRUW2YaP74kVXcsrK4DR7prICHoUdyrwvZf/lv/1dXlaZJyAW8jMAPHx5/X6IPVqgcghZShB9FU17vgGE9Q/mxeEg7iqYIhCx2HyXXdQVTNt0BD74TcqUPx6E0f6SdLu8etk9T9OvmO+XzhAZR66rgICIkZqIZ0uCZ9yuj+eAxvYN0aWp46OfgmmgKhRlU81zcePJk+MvF86FPJSBDUIOHFPAU46li7rH99Gis8WhT1aWv1pUKTB1Ud8H2OHXIXNDS4Hk0iOg2f5kF2raXbdewWVvC8KVH8RO7m0B2SGUKdn8/ZGx5LW/dpZdbrEjtm+TOIWP7eNdMNHgEPKsKXpvEXyujn9psIQuSXQWySJk2omiasAfYrU3mA+cHWdEnQO7bxzfB5N5ntHnVuDZyAS8jOH9h2WxjVJ9oOdv0ITHzEDAOvZrLDtwTB7R6DKlkrbKNaiOrfgGELJFTvK5KH5Mm4eunT4VZQ3tA94oJbjnISvkeYTh0NHg28+DRTBQJyS7OxWg2RvbSJMjv24yiKar7/DVHwQ/OnhUsW/kX+1Z4bYdzQIULRWHC62uKMHmQb/ZLz1ve++GZvai6XzC6Nzx02aHC+7pBYjB7CD0moTQJGvNuSMUvZiwn/yad6BwL1jc3qonm89ccBTefOgUAylYGqkOYuBHagmLotzZCHjTsIcmwNlwOR/Z+sSB/ZNE9zNaNTcae9Tx4uoiTGSffzCz44MkiZdow0URpzHT2MgVJ7NiaDbG4VsAHj0N4F+dbVW7RjSVQU9zI8+BlBEdN7AerbloSuPbTj82Gno3yaFgmkJlVAqi/r6P7tsAfLzwIJg7oBv/3VDlpLtdWmxdkxaMh+mJJe8GRZxAdlOkKL8QfTqbxWTC6NywY3RseXbGx3EchnNic/MYks7YZRfOrp06B0777GAAA3HLqVGiqKwoZjIKAWVXBtqmcCKKTbxOIaOb5yfprU++9CNey40B9KKefXZDTVsdRC1KeKTqmXckQYDW5vvbLv4Zh2FmNj868O3hMb7jzonkwZVDY95W0o+eDxx4gRUO3hhqoq8wJWR483Z7OnjsUtu/ugAdf2wAA5oqOOJjzmpJ5o6pULwSXLx4HI/s0w2HjfO3bM1cdGarHjgs9l+l3QZSrmETnT15xOMy+4Z5QGZHZvOMEx9nT4HFLVx/ocTxgWA94atVme21ba0mjT0Gn7RJzYDsmmjxaXKZM8LfMNScYZIXTNvuvZSla3b/L/zvX4OWwjYVjegdOym3BYyIjBFmZPqSH0uxFZaJZ7RD54LF56LDwBDWM5q3Lp4FNk+D3r17eNgW8A4b19PIo1ZQcaGsWO+yLIgImBe0ojIkRqqfhoYMciYSn+lLMAh6twVPnukhiAAAgAElEQVSMk9ZpryKIBAY8rbg40XlQg0cz9rrarKmDuwsCM5X/1Vl2rIkm26zK54sHOqCTiCHTnfPXnTAJvn76NOUBIoskNCGiAxtM3/Q40MXZ/b2+pghnzRka2L97NtWGUhaw87pQ4OeqdJh/WdCt9Gnh568T+doWnKDY6gkD+8KHGfwx7t+tHn53/kGW2y7/K1o3cUxn0V4o88GLK8gKQJBvMDE3BxC59cg1eJiusFE0VWZnQQ1eLuDlqBLQW7tsvaB88KiALSxsmv9lEQUBI9PJCFxYkM0NozzytH2SNAlJ+OCZIm2zW30BLxl6vTmFLE8z0yLzx7qaeLd5k0TnGEZSNgZYBSsboETWNV2mthj0wbNnGsw/FJIh/AxBWnabCHjU/mE7iiapmYU8YQThoDn+36P7NBu1Sc+JJVP6o+ux714VcCqKD57IioNt0/P/3kckPNaqxSaSjJLp9Sm4HrcPnog/oA+VdIZDVnbrrnZfeI5gBov3weMImNI2q29t5Caa+zHKTCHHjFJjHosCjQDwF4vIj6QaQT4e7Ie2y9Og6bVH5xOjwRWeqQ+YV8/ABy8t3wt/HqQzEXT59aSodGiJDVO+8q+sNPEn/Oi8YYGIZrbgBVkBB5GIHj/fZAysvommA1MHd4f5o9rEYe+p6411ReG9KGC17BjQUUoBwnvnnvZObTowOTfN8+BV/jDcWlwDxcOIXk0wSiKosT54Fx86Cr74l1egtaEEvzt/Lrz13k7tPskewrpWqMBO60LBgbqKlv2zR/h56woOQCeIhS62nVtOmxoqiY2Wa0MYyBJYN4VytGk7bXvapSSHTNDXXomWzsbhregZd1N7jl4v4tKf+vWzoVKhROeI3mSCmzKKpkCDB+BWJc+aC3j7IXwTTYDm+hJs3imP+iVtS8Ji8u23jbsK952RBcc+J61d04HOqSN9Ak9HMQQoh7r+5yvrYWw/dcCeuDR42EADab1CXcEyKW20Nm9MaYRcStCiQSKC8nzCrMA7mFDPXVZYkWFoz0Y4Ynwf+Ner74buod8fNc/uvGhehQb+6NJNyjQ+UUD4bd66O2hkG8wa2iN03aXGl4fdJgJewESTj6jPjJ3DITMsA8nwXkmuToCwL9o584bDOfOGAwBAXakI3SW+7mKfTbMBYp+uVCgHJ2IFxfIacYWbJLsnnTpzUKiM6BvUXFcKPFd7174VRZM95KRdGaIijTQJojUhE8zbMXk0FOCNWZfrwh7aaoAp4roAD1T8cFmIBSiAlRve9/5+Z8uu8jdNUl8ErIkmV8CT+eCpu84cchPN/RAeE+m68Mtz58AVx4w3bktkpkjaD10jNFTjamGg8sHTZQBYXzoZ/D7CfkanzRoEr1y3CIb3UqegMBXwPnzgEBjQLez3gX5kbyIYdR8ZOmngzjloGAzo1hAfMRREWmEVXKC+s8yYEh+83e3RP/g8BNIkIMcVM09KxQL84CMHcO/JDk94wmMwD55ag6dzTweEbt7r/dUn5sAlnNQA7AEOS4vJe/UOiCRBVkzN9fzvi1F1a5oWGlFMbEXjYNomGftZQ3tAwQFYPElg3qmwdsGlSeBX7tkU9I/2TTSj4UOzh0RsIRrIK2msHGqN79dqvY80PE9Efcp88GzQyRXwuoKHSrwyH/nRk8r2ZAc5f31hLfz4kVXWx1oZZEUgALpQnTxrLuDtj6Bm6pC2RvjEwSOCtzW2+WlDykmPD9dMkLov2PoTZpbdhDAJy3lQndQH+yBl/Tx4xGzNcRxorMUp501PNW84aTI8+oXDjeoCALTUl+CYyf1CaQLiAh3ZDkAvn94Xj5+YmM+gZ/KM5NllBywERINnounBYEhbOS3AxAHdYvF54QGztn5//lxlDjkabBH6p+38i2aBCZwQXQBm79XzEy6IGS3TR9at11If3Kvi0JZHMQUPBFmhaDPW4FWaGNOvBVZ+eYm3fkL9Mv+ywOwRJYGfQBsT+KXdgonmyN5NcEEl3VNaIPvCwO4N8MuPHwg3n1ZOB2JzTnltJSjpiQ49TAIsRe2X1eCFo2iKIb3H3Hx85SYjbT5b450tu+Cfr6wP9cFPk8AXAF23OtMk5ALefgzV0sF8FMf1a4XXb1gMR04IC3hcn4gUTr/iAglzP3Fg8JSQmMXrMoU+01Wud8mRY4RlaW2fH9RFqzsAADhx+kD9ShZQKDjwnQ/PhANHtCXS34/OCWqCMMwZyWeWJGjzaVR5769gRNxbTpsKUysmmSfPKL/jBaODSdVt4aCRvWDpp+fD2XOHcsc1aPZSRtRPpez1De5Z1rb2aq7zzVYRXzrCHB5aSVgdCMwSgeCHLjsU/lQxD/WjaGoIeMzBD0vL7o6ggDcVYYob8PcVafBMBTzNICvfOmM6XHHMePjicRMAICjw3XPpQnj+6qPMCIkZpoc+vim1on3qwE7WjgwlAY3l6Nz+PT/RuflE/8un5guF1aRAM+HzRvXyDjptsh1Y9wObEJpoxuxDz490ae6DJzPRZPHqum3wzpZdwfqafQAA3PL35d7fehq8YNlq1ODlPnj7IUQmNOMqPlu6E1l0SviFxePhyAl94YzvP6FJIQ5pr7f+3RrgzovmhXzdPP8WTQaANdG84JCR8LV/viYtWyw4MHtYOam4ibA0srdZBLmkMHGAPRObqYO7w/OrtwAAbo7fc+nCxM1x2iqmU3OR75KOYuvlo4OyPw7xyZkyqLt2IAhdTBxQFipUmjU/ImS01Ss7PPna6dPgkf9shGG9moSBi3jo01IPP/vYbJg9vLyeelB+WVHoHdyzEQZXDgv8PHj4+uyYqdIk3HHhPHBdF0ZdcZewTZQPnuEOe8rMgfDt+1ZAS304zyMPfVrqPSsS4hdHkOb+VFcqwJ6OLuFeYarVxbopqO5j5hBPwKsrFWDOiDZYQfk8dVgw0cyChkMUxM3mPu4l47bXpBJCE82Yg+PwXDieXPUebNvtx20I0SYhyRX8XW4neGX1e7vglNsek5bh9yEu8/7uDqotVTt0v/FEZI0buYC3H+LGkybDl+96FSZRmqf/3LDY+gSuLRXgoJG9rLZJIwvrberg7qFrtH+LDkguo4Hd+TmNaHg+Ew7AQaN6wUvXLoLmuvSXs80P6bNXHemZF9rAnRfNg+XrtsOibzyImus2k51j0a9bPTzw+UNgYHecz593WAM+M3zKjHCwBYKHLjsU3t/TIbwfFaphtTU9ZO+vtb4GFk/uX+lPT7t98Bhfy8mzSoiKoifg6Zto+iZ75b/mjmiDwT0b4POLxgX7KDigYtXp1Coipsk0zcGlR46Fiw8dbXXt2sIdFx6E9jturC2WBTxRonPD7YH1mRbBP4g1fz+8w9cxfcPBtzosBFnJwvc4CSacBH3qill7RkPUkyyKpg2IHvGaP7/s/a2nwYs2Zka1qSlxzzI6YBdfO8n7u1pTfqXPEeZIHBMGtMLPzz0wcI3HzIrMO6IgS7mRTIAxf6L9W3RwyoyB0K2hBg6v+IuRjxWP0Zw8sEzHcVMHAABkQrizhfMOHgGjejdDjyZxZDuCb35oOjRpMJKyJPQnTBuAJzJGDG0TB8dpqSvBdkpAG923BZ5+czO01tdA39Z6paZusIHZ6ZNXHA479+D8vIgA88EDBsOiif3goz95KvChnNC/FR5dsUkY/AELbIQ4naidLOJI4WHkgyfYT2pLBfjqqVON6FgwunzwduzUAfD3l9YZtSFCoeBkUrgDAJgxJBylVITG2nKE6YAPHnVfV5horivBxAGtVFoROTztvOC+qQaPh30lTUKSQmaiQ8bZLwb1aID2zi5Yv21PgoSUsXLDDv+Hxl4WTFPgQntnF4y+4i748smT7XGGyIZUUTQDDbnZOMDQxb7DFeawhh0VBrJ3S52ipD6q9CAEAADu/9wh0AsxJl2GUTQdxwkIc8WCA4994TDoyRF0RvRujmR295vz5kB/ThTMqLCxCf63RlTX46fqCWW8SKX3f+4QaG2o4Y5z1nDf5w+BzTv2er+vOW4CHDulPyolhin6tNQDIJtvrvhPTRjQCnM4ZqbfPWsmvPrONrT5HgDAny+eB6VCAY755kMAALBkcn94fOUmVF2sOVxS0A2iA0DlrPPCKpb/UW2lf7poHuwUaGtH9Wnx9o+7BQJeNe/VBF8/fSosW7vdqC4RUkXjoGuh8dK1iwAA4EcPvwEA6gOEhtoivL+nQ9g/ygdPcpBC3yFBVqKYWWbBhM3zW0zAXDRJDR6vq6uOnQATB7TCl+9aBktfWJsYLSxMh8EFgO0Vk8mv3L3My9eqrBS9CAAA3PKP5Z6lh1eXqnz1nUEtZRZMkHWRC3g5Qli/bTcAAPRttS8AZI3h0sEwRNoBALmWSBf9YwrPz2O+Pz5/OKzerJ/wt5rgmUdR2hDse80CejXXQa9m/5ChvqYI80bFZwati/MXjoSi48CHZg/hagVa62u0fUWnDAqaQV982Ci46yUkQxORB1s4prcwp5MJyJ5gFEUzKN8pGfxpHPNxbvtCAQJVPdM4afoggOlmdUmo/V1UQImelF+maZAVNu2FCL85bw7c9eJaL5hXuB11X9hE553kxCEFE81iwbGWj1VEw2/OmwMfvP1xK30QiNZwHMuGXet9Wupg0cR+AABw3JQBsQp4jiPfC1irLJmVFtsOHXAIs9+s3LhDWQZrBrpiww4YdvlSWP6lo6GuVITl67bDM29t9u6//M62QJvVyLPmAl6OEAZU/H/mx8A4Eu1gPea0hsLUQd3gtfXvBz62WT1RIXxtFk40dXDlsRPSJkGInk218B6luTJup7nMoMXpG7o/o76mCJ86fDQAAHR0xpOWob6miD41PnZKf7jj2TVcU7Xakpr5vf3smWjzVAzInqDD0E4c0AoPvrYB+lSsB2ybjooYsmo3p48KolHYudfXgtI+11EP8FTfh5G9m+Hiw0YL72MOCWQaPBo2TDRNR6NnUy1s2G5mZvjsVUfC9Ov/qaSBd6AZFZ0JnoDIeoo7gw8dqZuHl9ZsE95jETjccOkD//R4pd17u6CuVIRF33hQWKaswas+5AJejhAOH98X7r10IYyIIYLZ1l3l6EvdBaeSItx58XxwXRdOv/1xePKN96zTZRPkBMmGBq/aMHVQd1i7dR3O3EID93/+ECt53AZ2b9AKYpIje6ivKcDI3k2wYoP6NPcrp06BK5aMDwWb+O6ZM2B8f3WE1rpSEepK9uZyz6ZaqC0W4PLF49SFK7j0yDFw9MR+XqRSURRkU+wLmro4MKJ3EzzxxnshLVhtqQB7O7qMGeujJvSDLy191YtyawqMiWANR4PHE9zbrQRZMavcESFQSJERYD2tKoeUZdcfDeOuutu4LxZJrhu2L3qo4z5ILjoOdGoc9ki1fdTh98qNO+D7D63071k6UNJtRZYs3muzSn3w8jx4ObiIQ7gDANi8s6yF6d6o7+/kOA4sYWyms4gRvcsmfxMQDOS+hq+fPg3uvGgeKkCKDlrra7woo1ExtK1JmNojhz0Q3nJ0X7t7SV2pCL8//yBU2ZpiAdqaw36zR0/qLw1mExdqSwV47YbFcLIk0imLUrEQ0BzNHNoDJvRv1RISTbC/C37XHDcRvvaBqXDAMCYwS0QLjSFtjbDqpiWoAwYZMO+HFYBo0AJZJ5Um4ftnzzKix5T/3d1uLuCxfcreia7VkAq2zEoxYHuirZfiFjxsts9GBP7eAysDv630ofla2hHaaxfcVLWMpsg1eDlix5P/fTgcdNO90NHlept590Y9DR5B1DC7SeCwcX3h7s8ugLGccNT7Ohpqi9zUEfs7Zg/vCaP6ZDvnoG3UlYrwi3MPtJrLEKCswSMJjPdHNNWV4G+fWWCtPXEY/v0b9TVFriDup95Il+HDmGjWcNSMfmRZH14ePCbQlw5Mh4OE+q8tFrTD/rPvAENCn5Y6eNfQJJRGogIe866T1ODpti8z5yTPwc5dlZ+fDnSbaUfMOdetThPN/Bg7R+zo01rvBWw5qvLx6GGgwQMILt4sH6iM69dalSc+OeLBbz85F248aXLaZCSO+aN7WdPmzhhSPjiwaTKZQ4xqOExLA2fOGQoA6Zvgo4KscCwVePVsvGrT7x0RlOpr9NlRtktCg4iSRy4/DP55yULtfnhIVsAL/naEP+xDd5pjTDS5c1CvG0kfei2hBDyAqpTwcgEvRyIgp4JfOWUKvHLdIlSAAx7oeodW8sXlyJFj38ePPzob/nTRvNQZ630NInYoF+/4uPrYCfCfGxanPg8xGjwejZ0SfzvTJzpweE/hvds+PAMuO3qssg0TE0pWu6SyvB/YvUEYlVQXIm1jHAcjMv+0rGnwZBA/hb0+dJOSt3e6yne2t6Mrs0H9ZNh/7VxyJIorl4yHCw8ZGfk0/7SZg2Hd1t1wwSEj92szrRw59jd0a6hBh/7PgcfgHo3c67kCjw/HcaAGGZ0yTmDeD49OYo7ZyslFacrLyw5sCwUH6hFad5J3UAcsvTUJ+lbbCPqFRTjICuWDF3Pf2wW5NE0gEqRsmmju7dDX4GH88KrxXDHX4OVIBKViAfpYyKtXWyrApUeNzYW7HDlyAADAsDa+gJIDh4/NHw4/PucAeOTyw5g7uYSXZZhq8EhKhB5NtfDQZYdCmwUT6hOnDRTe6+qS5xBrrit/yycN7KbdL6tVIelQknCP2BMhOIwu/vnKeuG9tH1BdSCyau3scrU1byJgTC7Z8pg6VTTMHnIuOUeOHDlyVC3u/uzB2sEZcvgoFhw4dFwfDpNThRzNfgRckJXwGT7tOza4Z2PANNLEDG3qoG5wiiTlQ6frSls9akJf+Oi84bBxxx7thN2s/JqkBm9PR3IavKff3Ay/fXq195sWNqpJ8KBTSNHz0EaOWwJ9Ac/FCXhVuB/mAl6OHDly5Kg6/OGCufDK2u1QX1O0HgJ9f0RNsQBfP30qDG1rgnteXQ/Tc3PYTAOj7yjwNHhM3i9ay2ciLLBawiuOGQ83/O1V73dZOyNvY/KgbvDYik2h65ceOQaWr98OfxUIfqymLsn0N3s6kj1Uuuz3L3h/V62AV/m34ADEJR6zwtodz6yRll/6wjuwcUSbst1qGmeC3EQzR44cOXJUHWYO7QlnVSIa5rCDk6YPghlDesDnF43jCgc5sgNTizY2+mOJes8lg3fOmgh+4uARoTJrtuwKXfvumTOhWHDgkwtHAgBAS31Y3zC0VxPceLI4+jBLrmeiqaQ6OpIW8HQwsHtD2iRw0Uml44gLezXfy08fexMu/OUzynLVuBvmAl6OHDly5MiRI8d+gA5GwCMauNpiIaQB+9clC+HkGWL/OgC+ZuOuzyyAey9dCB+ZOxQWT+rPTSkwe3hPWHHjMTC2XzlfLC/oS8EBaJBo51lBIcngNyYmmsuuPxpW3HgMqqwsSistVHcwAUImDWyFn35sNtSWCjBxQGumfJTJPCjGKeBR42E1omkVqvByAS9Hjhw5cuTIkaOKMGeEODWBDJ2dfAGPF8VyVJ9mOGRsOB0RnWqAp40Z378VRvRuhmtPmAS1pQLs2hsWhthaPA2eA46WX12SJpqPvB42KWUxsndT4Hf9/2/v3oOkKu80jj+/mYaBGYa5wMDAcBVGCKIOMAICKggil43oRg1uVDRG3aiJ1ho3YlwlXkl23Y2pSmKZSNSsbsqKJmETNq6rsUxZGgRF8S4KKgRFQQWR68xv/+jTw5me0z3Xnp5pvp8qq7tPv+fM212v3f3w3nrkKz/PtO6GU5o9N11YDT+T3GNVEMvX6AF99OYt8/XHb5+g3hEL0qULzZlUH5qDlynhIZotWR2zpbpfvCPgAQAAdCsPfGNqm85L7sHbvT++DH74R//EYannX95x1rEa2Leg4XFLfvgm/kZYci7sExHwWpsDvj59pKR4wGyt02sGN1vmkojhp+nMCoXjp66Z1XC/tLCnvn/aUWnPLUiztUQ4VCcCTWKriuTesai3sK3/ONBeicCVyc6wxgGv44bRdsMOPAIeAABAd9KaXpCZYyq09vo5kprOwXt/R3x+XHgl2gcvnqrV35stSdqb1Ps2b3xlo5D4z/PGNvv3d0fspZa8KmFUT11rf1TPG1+pTcsXqqK4IG25ZV8eF3HuoLTn3PjlcfrO3DG6aVH6YBaWH+qFG5Y0VHLJtBEalyaIDi1PPY+uUQ9eUogpKeyYjdwzIdGTm9EevKBH82+f7tHadz/psOt2x1U0CXgAAAA5aMOt87ViyXENwxeTV9FMOBAa6terR74GFMf3rd2TtKF3UUFMX5sSX9zopWVzNWl4WbN12B0xRDNK8tDFdItxpAtAzblg+khtvH2BNt5+aD5cc5njwukj1TOWp/OPH6FBJS3b07dn8J5fc+qYyOcfvHhKynPnNxM4ExJDNBO3ZUkBL+otbG5V00xJtKVUe/e19H1NJxF4py1/QuevWN3u6yXQgwcAAIAuIZafp7w8a5jTlfzj/psz46tYHkgR/JIDniRdNGOkNi1fGLkwSpSLT2g6tNEjNnooLWy86XqqIPCHb83Qn648sUV/OxUzk5lpSFk8KA7s2/JwMTZYGCaKu3Tn4hqdXjNYl540Sl+bMkwXTBsRWba0sKfeuGVe5HOJekVX/tDd5B68ssLmN67/PKJHtTN8tueApI4PeNUD+jTc33+wvmMXVwl0w3xHwAMAAOhuHv7mNP3yguNaVDYWsem5JJ1YXSGp6WqMCV+0sPctnVPGDWzTeYkf1Uf0b7xYycC+vVRU0DHbOE8YFu+BzDPTyiumR5b563WzGz2+4+yatNdcVFOlHy2eoD4FMd16xtFp65pqrt2M0f1TnhMOG7PGDFB+nukn/zBRknRWbepN5xM+33so4I0OhaPOkmotnLYO3Txq8KGhrgfqXHsPdPwWFvTgAQAAIOMmDS/TrLFNV7mMkmpVxsTqlX17R/fG7YlYIKUt7lxcowHFBQ2LuaTqZDluxKEhn72CsnedN6lRmZ4duFrmD75ytH545jEaX9VXxwwp1V3nTmpSJrl3r7yop564+qQOq8OzS2frqjnVDY9vOX28+vUp0M0p5vuFh64OLu2tt29boIXHDNKm5Qs1ekBxUtmm54dXTE0XJDMlVQ9eWzveBoX2/dtzoE7/8vuX23ahNDK5d1+mEPAAAAByWKofqImAN/PIisjnO6IHT4r3aq3+3hwV9Ej/s/NXF03RM0tP1vULv6Tpo/tF1qFHrON+bBf2jOns2qEN78+88ZUtCpBDywtVPaCPVlxQq2eXzm62fDqVJb101ZwjGx6fOzU+x/G840dElm/Nqz/+iH5NjlWFhn8uXTBWt5w+vuHxtfMbL5rT3tc2c0zTdpWq17CtGSp5aOdv1m5u24XS6Ib5joAHAACQ6+aOG9ikh2p4vyL950VTdNvfHx15zjmThzXcrypt+8ImCdcvHKeCWF7ktghSvNduUElvfeOEIxpCV2VSD1qq4aYd5fWbo+fFhfXIz9Nj/3SSTh47UJUlvfToVfE5gacd2/x2C6lMG9VP355d3XzBVvjuvLENvXQ3/N04XXPqGN2y6FCgK4jlNwRKSYqFhkmWFfZQZZp5cY9cNk13Lk4/XLU0omc4Me8zWXOrn6aS6BWubuVw05IUvdZRuuMqmh0ziBkAAABd1t3n10Yen1Gdepje+KoSbVq+UKvWb9WENPvjtdSZk4bozEnNzxMLqyzppXuW1Oqi+9ZIajzcdNPyhdp7oK7JYiPtkRcKOekWVAkbU1mst29b0K4tAB68uOnehk9+Z6Zm/tuTjY6NSJqTmE4sP0/3f32ytu7c2yigP3LZNPUvahyovjJxiLbv3t/wOGp+4Pplc7Xm3U/08ubPNHFYmSYOK9ORA4t148pXtHrjDn1pUF+9tnVnQ/lFNVX63bq/Na5TXp4mDCvVC+99qgVHV2rV+g8kSUPLGm8l0VJzx1Xq2Yk7dNWcalWV9taDq9/T717YojVptkk4on+Rtu3a1+K/0R178CwTq800XNxsnqQ7JeVL+oW7L096vkDS/ZImSdou6avuvindNWtra33NmjWZqTAAAAC6lPp610+f3KBzpw5vstpmJmzYtktPb9iuJSlWwOxMb3/0ufbsr9PYymI9+cZHmnJEuYpbuIJpSx2oq1e+mbbt2qdf/OUdvfHhLl05u1q1I8r1x5e2Kj/PNLJ/kcakCLx19a53t+/WyP5F2rnnoEoKe2j/wXr1jOXp50+9o1tXvdZQ9g/fmqGxlcWqc1dBLF879x7Qnf/3li6YNkIn/PDPKet41OC+uuvcSepTEFNZUU9t/Hi36t01qiK65+7qh17Uw89HD9ccVVGkqrJCPfXmRy16f5bOH6tLT4ruecwmM1vr7pH/cpOxgGdm+ZLelHSKpM2SnpN0jru/GipzmaRj3P0fzWyxpDPc/avprkvAAwAAALqHfQfr9NzGT7Tx48917tThKeeEPr3hY9XVuyaPLNfOvQdUXy/9Zu37GlJWqEU1g1u12MnrH+zUvB/9JfK5H58zQbPGVOitbZ/r8dc+1NbP9uqR57ekvNb3TzuqS4T9ZNkKeMdLWubupwaPl0qSu98eKvNoUOYZM4tJ+kBShaepFAEPAAAAQEvsO1ine5/epIP1rstnjU5ZZtvOfXrm7e0aNaBIL7z3qSqKCxTLy9PMMRUdtjVHR0oX8DJZ2ypJ74ceb5Y0JVUZdz9oZp9J6ifp43AhM7tE0iWSNGzYMAEAAABAcwpi+c0OsSyI5WtoeaGGlsfnAk4aXt4ZVcuYbrGKprvf7e617l5bURG9lC8AAAAAHO4yGfC2SBoaejwkOBZZJhiiWaL4YisAAAAAgFbKZMB7TlK1mY00s56SFktamVRmpaQlwf0zJT2Rbv4dAAAAACC1jM3BC+bUXSHpUcW3SVjh7q+Y2U2S1rj7Skn3SPqVmW2QtEPxEAgAAAAAaIOMLgnj7qskrUo6dkPo/l5JZ2WyDgAAAEEU8hsAAAZjSURBVABwuOgWi6wAAAAAAJpHwAMAAACAHEHAAwAAAIAcQcADAAAAgBxBwAMAAACAHEHAAwAAAIAcQcADAAAAgBxBwAMAAACAHEHAAwAAAIAcQcADAAAAgBxBwAMAAACAHEHAAwAAAIAcQcADAAAAgBxh7p7tOrSKmX0k6d1s1yNCf0kfZ7sSgGiL6Bpoh+gqaIvoKmiL6EjD3b0i6oluF/C6KjNb4+612a4HQFtEV0A7RFdBW0RXQVtEZ2GIJgAAAADkCAIeAAAAAOQIAl7HuTvbFQACtEV0BbRDdBW0RXQVtEV0CubgAQAAAECOoAcPAAAAAHIEAa8DmNk8M3vDzDaY2bXZrg9ym5ltMrP1ZrbOzNYEx8rN7DEzeyu4LQuOm5n9OGibL5nZxOzWHt2Zma0ws21m9nLoWKvbnpktCcq/ZWZLsvFa0L2laIvLzGxL8Nm4zswWhJ5bGrTFN8zs1NBxvr/RZmY21Mz+bGavmtkrZnZlcJzPRWQVAa+dzCxf0k8kzZc0TtI5ZjYuu7XCYWCWu9eEllu+VtLj7l4t6fHgsRRvl9XBf5dI+lmn1xS55F5J85KOtartmVm5pBslTZE0WdKNiR8/QCvcq6ZtUZL+I/hsrHH3VZIUfCcvlnRUcM5PzSyf7290gIOSrnb3cZKmSro8aEN8LiKrCHjtN1nSBnd/x933S/q1pEVZrhMOP4sk3Rfcv0/S6aHj93vcs5JKzWxQNiqI7s/dn5K0I+lwa9veqZIec/cd7v6JpMcU/UMdSClFW0xlkaRfu/s+d98oaYPi3918f6Nd3H2ruz8f3N8l6TVJVeJzEVlGwGu/Kknvhx5vDo4BmeKS/tfM1prZJcGxge6+Nbj/gaSBwX3aJzKttW2PNolMuiIY+rYi1ANCW0TGmdkISRMk/VV8LiLLCHhA9zPD3ScqPtTjcjM7Mfykx5fGZXlcdDraHrLsZ5JGSaqRtFXSHdmtDg4XZtZH0sOSrnL3neHn+FxENhDw2m+LpKGhx0OCY0BGuPuW4HabpN8qPszow8TQy+B2W1Cc9olMa23bo00iI9z9Q3evc/d6ST9X/LNRoi0ig8ysh+Lh7gF3fyQ4zOcisoqA137PSao2s5Fm1lPxidwrs1wn5CgzKzKz4sR9SXMlvax4m0usurVE0u+D+yslnR+s3DVV0mehYSNAR2ht23tU0lwzKwuG0M0NjgHtkjS/+AzFPxuleFtcbGYFZjZS8QUuVovvb7STmZmkeyS95u7/HnqKz0VkVSzbFeju3P2gmV2h+P+I+ZJWuPsrWa4WctdASb+Nf6coJulBd/+TmT0n6SEzu0jSu5LODsqvkrRA8UUFvpB0YedXGbnCzP5L0kxJ/c1ss+Krvi1XK9qeu+8ws5sV/3EtSTe5e0sXywAkpWyLM82sRvHhcJskXSpJ7v6KmT0k6VXFVz283N3rguvw/Y32mC7pPEnrzWxdcOw68bmILLP40GAAAAAAQHfHEE0AAAAAyBEEPAAAAADIEQQ8AAAAAMgRBDwAAAAAyBEEPAAAAADIEQQ8AMBhy8zqzGydmb1oZs+b2bRmypea2WUtuO6TZlbbcTUFAKBlCHgAgMPZHnevcfdjJS2VdHsz5UslNRvwAADIFgIeAABxfSV9Iklm1sfMHg969dab2aKgzHJJo4Jev38Nyn43KPOimS0PXe8sM1ttZm+a2Qmd+1IAAIerWLYrAABAFvU2s3WSekkaJOnk4PheSWe4+04z6y/pWTNbKelaSePdvUaSzGy+pEWSprj7F2ZWHrp2zN0nm9kCSTdKmtNJrwkAcBgj4AEADmd7QmHteEn3m9l4SSbpNjM7UVK9pCpJAyPOnyPpl+7+hSS5+47Qc48Et2sljchM9QEAaIyABwCAJHd/Juitq5C0ILid5O4HzGyT4r18rbEvuK0T37cAgE7CHDwAACSZ2VhJ+ZK2SyqRtC0Id7MkDQ+K7ZJUHDrtMUkXmllhcI3wEE0AADod/6IIADicJebgSfFhmUvcvc7MHpD032a2XtIaSa9LkrtvN7OnzexlSf/j7teYWY2kNWa2X9IqSddl4XUAACBJMnfPdh0AAAAAAB2AIZoAAAAAkCMIeAAAAACQIwh4AAAAAJAjCHgAAAAAkCMIeAAAAACQIwh4AAAAAJAjCHgAAAAAkCMIeAAAAACQI/4f2FSee+TTrnIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}